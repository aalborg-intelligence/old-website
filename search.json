[
  {
    "objectID": "srp.html",
    "href": "srp.html",
    "title": "SRP",
    "section": "",
    "text": "I arbejdet med studieretningsprojektet kan matematik og AI indgå i et samarbejde med en lang række andre fag. Idéer til sådanne samarbejder findes herunder. Under nogle af emnerne er der også indsat konkrete forslag til problemformuleringer.\nHvis man ønsker, at inddrage kunstige neurale netværk kan noten om kunstige neurale netværk benyttes. En mulig fremgangsmåde er at bede eleven udlede opdateringsreglerne for et konkret, lille netværk med f.eks. ét skjult lag.\nEn anden mulighed er at bruge noten om perceptroner - eventuelt kombineret med noten om retningsafledede og gradientnedstigning."
  },
  {
    "objectID": "srp.html#samfundsfag-og-matematik",
    "href": "srp.html#samfundsfag-og-matematik",
    "title": "SRP",
    "section": "Samfundsfag og matematik",
    "text": "Samfundsfag og matematik\n\n\n\n\n\n\nKandidattest\n\n\n\n\n\nUdarbejdelse af kandidattest i forbindelse med valg. [samfundsfag A]\n\nMaterialer\nNoten om perceptroner.\n\n\n\n\n\n\n\n\n\n\nOvervågning\n\n\n\n\n\nBrugen af kunstig intelligens i forbindelse med ansigtsgenkendelse. Herunder kan emner som persondataloven, retssikkerhed og/eller partiernes holdning til overvågning behandles. [samfundsfag A]\n\nMaterialer\nNoten om kunstige neurale netværk."
  },
  {
    "objectID": "srp.html#dansk-og-matematik",
    "href": "srp.html#dansk-og-matematik",
    "title": "SRP",
    "section": "Dansk og matematik",
    "text": "Dansk og matematik\n\n\n\n\n\n\nAI og anvendelser\n\n\n\n\n\nFormidlingsopgave hvor AI metoder behandles og derefter formidles f.eks. som en populærvidenskabelig artikel. Eleverne skal skrive en danskfaglig meta-del, hvor de redegør for deres overvejelser og valg med hensyn til målgruppe, virkemidler med videre.\n\nMaterialer\nNoten om kunstige neurale netværk.\nNoten om perceptroner.\nNoten om naiv Bayes klassifier."
  },
  {
    "objectID": "srp.html#engelsk-og-matematik",
    "href": "srp.html#engelsk-og-matematik",
    "title": "SRP",
    "section": "Engelsk og matematik",
    "text": "Engelsk og matematik\n\n\n\n\n\n\nMachines like me\n\n\n\n\n\nRedegørelse for hvad et kunstigt neuralt netværk er. I engelsk perspektiveres der til Ian McEwans bog “Machines like me”. [engelsk A]"
  },
  {
    "objectID": "srp.html#idræt-og-matematik",
    "href": "srp.html#idræt-og-matematik",
    "title": "SRP",
    "section": "Idræt og matematik",
    "text": "Idræt og matematik\n\n\n\n\n\n\nBaseball og machine learning\n\n\n\n\n\nImplementering af et kunstig neuralt netværk, som kan forudsige baseball tegn (app til implementering af netværk er under udarbejdelse). [idræt C, evt. innovativ]\n\nMaterialer\nStealing Baseball Signs with a Phone (Machine Learning)."
  },
  {
    "objectID": "srp.html#biologi-og-matematik",
    "href": "srp.html#biologi-og-matematik",
    "title": "SRP",
    "section": "Biologi og matematik",
    "text": "Biologi og matematik\n\n\n\n\n\n\nDiagnosticering af sygdomme\n\n\n\n\n\nRedegørelse for hvordan et kunstigt neuralt netværk kan trænes, så det kan anvendes i forbindelse med diagnosticering af sygdomme - herunder kan opdateringsreglerne for et lille, simpelt netværk udledes. [biologi A]\n\nMaterialer\nMeet the computer diagnosing cancer.\n\n\n\n\n\n\n\n\n\n\nDiabetes type II og logistisk regression\n\n\n\n\n\nI biologi arbejdes der med diabetes type II og oral glukosetolerancetest (OGTT) som screeningstest. [biologi C]\nI matematik redegøres der for logistisk regression – herunder hvordan denne metode kan benyttes til at prædiktere sygdom ved en person ud fra information fra et større datasæt. Desuden forklares idéen bag maksimum likelihood, og hvordan parametrene i modellen estimeres.\nDer kan eventuelt konstrueres et OGTT-datasæt, hvorpå der udføres logistisk regression – herunder kan der redegøres for betydningen af odds, og der kan foretages en prædiktion for diabetes på en fiktiv person, der er testet.\n\nMaterialer\nDansk studie: 3 dages motion om ugen booster diabetes-patienters behandling.\nNoten om logistisk regression."
  },
  {
    "objectID": "srp.html#informatik-og-matematik",
    "href": "srp.html#informatik-og-matematik",
    "title": "SRP",
    "section": "Informatik og matematik",
    "text": "Informatik og matematik\n\n\n\n\n\n\nGenkendelse af håndskrevne tal\n\n\n\n\n\nImplementering af et kunstig neuralt netværk med ét skjult lag, som kan kende forskel på f.eks. håndskrevne 2- og 9-taller. [informatik B, innovativ opgave]\n\nProblemformulering\nUdarbejd et løsningsforslag til hvordan man oversætter håndskrevne tal, så de kan genkendes af en computer. I den forbindelse skal du:\n\nRedegør for hvad der forstås ved et kunstigt neuralt netværk, hvor du tager udgangspunkt i et netværk med ét skjult lag. Kom herunder ind på feedforward og backpropagation.\nImplementer et kunstig neuralt netværk med ét skjult lag, som kan bruges til at kende forskel på 2- og 9-taller (brug en passende delmængde af MNIST train-datasættet).\nVurder dit løsningsforslag i forhold til styrker og svagheder samt graden af innovation. Inddrag i den forbindelse en passende delmængde af MNIST test-datasættet.\n\n\n\nMaterialer\nNetværket kan trænes på en passende delmængde af MNIST datasættet.\n\n\n\n\n\n\n\n\n\n\nKunstig intelligens - muligheder og begrænsninger\n\n\n\n\n\nRedegørelse for hvordan et kunstigt neuralt netværk trænes. Diskussion af de etiske problemstillinger, som kan opstå i forbindelse med anvendelsen af kunstig intelligens og/eller diskussion af de muligheder og begrænsninger, der er ved brugen kunstig intelligens. [informatik C]\n\nProblemformulering 1\n\nRedegør kort for begrebet ”kunstig intelligens” - herunder ”deep learning”.\nForklar hvordan et kunstig neuralt netværk virker. Herunder ønskes en redegørelse for hvordan et kunstigt neuralt netværk lærer vha. backpropagation og hvordan kædereglen benyttes i den forbindelse.\nDiskuter de etiske problemstillinger som kan opstå i anvendelsen af kunstig intelligens.\n\n\n\nProblemformulering 2\n\nRedegør for udviklingen inden for kunstig intelligens. Inddrag begreberne machine learning, deep learning samt supervised og unsupervised learning.\nRedegør for teorien bag kunstige neurale netværk herunder hvordan kunstige neurale netværk lærer vha. backpropagation og costfunktionen. Forklar også hvordan kædereglen benyttes i den forbindelse.\nDiskuter hvilke muligheder og begrænsninger der er ved brugen af machine learning. Inddrag bilag 1.\n\nBilag 1"
  },
  {
    "objectID": "srp.html#psykologi-og-matematik",
    "href": "srp.html#psykologi-og-matematik",
    "title": "SRP",
    "section": "Psykologi og matematik",
    "text": "Psykologi og matematik\n\n\n\n\n\n\nPrædiktion af psykisk sygdom ved hjælp af deep learning\n\n\n\n\n\nForklare hvordan kunstige neurale netværk kan bruges til at prædiktere psykisk sygdom baseret på register og genetiske data.\n\nMaterialer\nNoten om kunstige neurale netværk.\nDeep Learning for Cross-Diagnostic Prediction of Mental Disorder Diagnosis and Prognosis Using Danish Nationwide Register and Genetic Data."
  },
  {
    "objectID": "apps/perceptron_app.html",
    "href": "apps/perceptron_app.html",
    "title": "ADALINE perceptron app",
    "section": "",
    "text": "Gør følgende\n\nUpload data (.xlsx eller .csv format).\nVælg den kolonne som angiver targetværdien (skal være kodet +/- 1).\nVælg de forklarende variable (feature-/input-værdier).\nÆndr eventuelt på startvægte, learning rate, stopkriterium og/eller det maksimale iterationer – eller behold default værdierne.\nVælg antal af fold i \\(k\\)-folds krydsvalidering (default er 5).\nTryk på \"Kør ADALINE!\"\n\n\n\nOutput fra algoritmen\n\nInformation om hvad du har valgt som features og targetværdi.\nVærdien af de estimerede vægte.\nEn figur, som viser, hvordan vægtene har ændret sig for hver iteration. Hvis graferne for alle vægtene er fladet ud, er det tegn på, at algoritmen er konvergeret.\nResultatet af krydsvalidering her angivet som klassifikationsnøjagtigheden (den gennemsnitlige andel som er klassificeret korrekt ved \\(k\\)-folds krydsvalidering).\nTil sidst en tabel med data."
  },
  {
    "objectID": "materialer.html",
    "href": "materialer.html",
    "title": "Materialer",
    "section": "",
    "text": "Perceptroner\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nKunstige neurale netværk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSimple neurale netværk\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSensitivitet, specificitet, ROC-kurver og AUC\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistisk regression\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFunktioner af flere variable\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nGradientnedstigning\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNaiv Bayes klassifier\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nClustering med K-means\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverfitting, modeludvælgelse og krydsvalidering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstande og feature-skalering\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\n\nVideoer\nTil en del af materialerne findes en række videoer, hvor teorien forklares. Der er linket til de relevante videoer under de respektive materialer, men en samlet liste findes også her."
  },
  {
    "objectID": "teacher.html",
    "href": "teacher.html",
    "title": "For lærerne",
    "section": "",
    "text": "Her kommer information om hvordan materialerne kan bruges i forskellige typer forløb i gymnasiet.\nVi har på nuværende tidspunkt erfaring med SRO i matematik og samfundsfag samt forskellige typer af SRP. Kontakt Ege Rubak for nærmere information."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/tangentplaner.html",
    "href": "materialer/funktioner_af_flere_variable/tangentplaner.html",
    "title": "Tangentplaner",
    "section": "",
    "text": "Vi vil her forklare, hvordan man bestemmer ligningen for en tangentplan til grafen for en funktion af to variable. Som eksempel vil vi igen bruge:\n\\[\nf(x,y)= 2x^2-y^2+3xy+1.\n\\]\nPå figuren herunder ses grafen for funktionen \\(f\\) sammen med grafen for snitfunktionen \\(g(x)=f(x,y_0)\\), hvor \\(y_0=-2\\). Derudover er tangenten til grafen for \\(g\\) i punktet \\(P(x_0, y_0, f(x_0,y_0))=P(1,-2,-7)\\) indtegnet (stiplet linje).\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nVi har tidligere beregnet, at denne tangent har en hældning på \\(-2\\), men helt generelt vil hældningen være \\(f_x(x_0,y_0)\\). Det betyder grafisk, at hvis vi står i punktet \\(P\\) og gerne vil bevæge os langs tangenten, så skal vi: Bevæge os \\(1\\) enheden i \\(x\\)-aksens retning, \\(0\\) enheder i \\(y\\)-aksens retning (husk på at snitkurven forløber i planen med ligning \\(y=y_0\\), hvor \\(y\\) er fastholdt, og dermed ikke ændrer sig) og \\(f_x(x_0,y_0)\\) enheder i \\(z\\)-aksens retning. Dermed vil en retningsvektor for denne tangent være\n\\[\n\\vec{r_1} =\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ f_x(x_0,y_0)\n\\end{pmatrix}.\n\\]\nPå helt tilsvarende vis vil grafen for snitfunktionen \\(h(y)=f(x_0,y)\\) have en tangent i punktet \\(P(x_0, y_0, f(x_0,y_0))\\) med hældning \\(f_y(x_0,y_0)\\). Dette er illustreret med eksemplet fra før herunder.\n\n\n\n\nI det konkrete eksempel er hældningen af denne tangent \\(7\\). Generelt vil en retningsvektor for tangenten være\n\\[\n\\vec{r_2} =\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ f_y(x_0,y_0)\n\\end{pmatrix}.\n\\]\nSom bekendt udspænder to vektorer en plan og den plan, som disse to retningsvektorer udspænder kaldes for tangentplanen1 til grafen for \\(f\\) i punktet \\(P(x_0, y_0, f(x_0,y_0))\\). Man kan igen tænke på grafen for \\(f\\) som en bakke. Hvis vi står i punktet \\(P\\) og placerer en bordplade i punktet, så vil denne bordplade svare til tangentplanen (eller rettere en del af den).\n1 Mere formelt er det faktisk sådan, at hvis alle tangentvektorer til alle snitkurver i et punkt \\(P\\) ligger i en plan, så kaldes denne plan for tangentplanen. Men her er det fint bare at tænke på, at de to retningsvektorer \\(\\vec{r_1}\\) og \\(\\vec{r_2}\\) udspænder en plan – og så vil det som regel være sådan for de \"pæne\" funktioner, vi beskæftiger os med, at denne plan også indeholder alle andre tangentvektorer og dermed formelt set vil være tangentplanen.Vi vil nu finde en ligning for tangentplanen. Vi minder om, at en plan gennem punktet \\((x_0,y_0,z_0)\\) med normalvektor\n\\[\n\\vec{n} = \\begin{pmatrix}\na \\\\ b \\\\ c\n\\end{pmatrix}\n\\]\nhar ligning\n\\[\na(x-x_0) + b(y-y_0) + c(z-z_0)=0.\n\\tag{1}\\]\nVi husker også på, at en normalvektor til en plan, kan fås ved at krydse to retningsvektorer til planen. Derfor vil en normalvektor til tangentplanen være:\n\\[\n\\vec{n} =\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ f_x(x_0,y_0)\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ f_y(x_0,y_0)\n\\end{pmatrix}\n\\]\nDet giver\n\\[\n\\begin{aligned}\n\\vec{n}&=\n\\begin{pmatrix}\n0 \\cdot f_y(x_0,y_0) - f_x(x_0,y_0) \\cdot 1\n\\\\\nf_x(x_0,y_0) \\cdot 0 - 1 \\cdot f_y(x_0,y_0)\n\\\\\n1 \\cdot 1 - 0 \\cdot 0\n\\end{pmatrix} =\n\\begin{pmatrix}\n- f_x(x_0,y_0)\n\\\\\n-f_y(x_0,y_0)\n\\\\\n1\n\\end{pmatrix}\n\\end{aligned}\n\\] Indsættes dette i planens ligning i (1) fås\n\\[\n- f_x(x_0,y_0)(x-x_0)-f_y(x_0,y_0)(y-y_0)+ (z-f(x_0,y_0))=0.\n\\] Hvilket efter lidt omrokeringer giver \\[\nz=f_x(x_0,y_0)(x-x_0)+f_y(x_0,y_0)(y-y_0)+f(x_0,y_0).\n\\tag{2}\\]\nDette er den generelle ligning for tangentplanen til grafen for \\(f\\) i punktet \\(P(x_0,y_0,f(x_0,y_0))\\).\nI eksemplet er\n\\[\nx_0=1, \\quad y_0=-2, \\quad f(1,-2)=-7, \\quad f_x(1,-2)=-2, \\quad \\textrm{og} \\quad f_y(1,-2)=7\n\\] Indsættes dette i (2) fås\n\\[\n\\begin{aligned}\nz &= -2(x-1)+7(y+2)-7 \\quad \\Leftrightarrow \\\\\nz &= -2x+7y+9\n\\end{aligned}\n\\] Denne tangentplan ses tegnet sammen med grafen for \\(f\\) herunder."
  },
  {
    "objectID": "materialer/ROC/ROC.html",
    "href": "materialer/ROC/ROC.html",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "",
    "text": "Langt de fleste algoritmer, som vi behandler her på siden, handler om, hvordan AI kan bruges til klassifikation. Det kan være alt fra at prædiktere, om man vil stemme på rød eller blå blok ved næste valg baseret på svarene af en række spørgsmål til at prædiktere, om en patient har kræft baseret på forskellige diagnostiske test.\nNår man skal vælge en god algoritme, som kan anvendes til den form for klassifikation, har man brug for at kunne sammenligne, hvor godt forskellige algoritmer prædikterer. Man er derfor nødt til at have et mål for, hvor god en algoritme er til at forudsige klasser (fx rød eller blå blok). Det mest oplagte er at tælle, hvor mange observationer algoritmen klassificerer forkert. Man kan så beregne, hvor stor en andel af alle observationerne, der klassificeres forkert. Denne andel kaldes fejlklassifikationsraten. Det er dog ikke altid det bedste mål at bruge. Det handler denne note om.\nSom eksempel ser vi på et lille dataeksempel med \\(20\\) datapunkter, der kan have klasserne rød og blå, hvor rød er meget sjældnere end blå. Desuden er der målt en inputvariabel \\(x\\). Vi ønsker at finde en algoritme, der kan prædiktere farven på en observation på baggrund af \\(x\\). Datapunkternes klasser og \\(x\\)-værdier er angivet på figur 1. Ud fra figuren kunne det godt se ud til, at sandsynligheden for den røde klasse stiger, når \\(x\\) stiger. Der er dog også flest blå med meget høje \\(x\\)-værdier.\nFigur 1: Et lille dataeksempel med 20 datapunkter.\nMange prædiktionsalgoritmer benytter en tærskelværdi \\(t\\), således at klassen prædikteres som rød, når \\(x&gt; t\\), og blå når \\(x\\leq t\\). På figur 2 ses et eksempel med \\(t=10\\). De første \\(10\\) observationer klassificeres korrekt til at være blå. De næste \\(10\\) observationer prædikteres røde, selv om kun \\(3\\) af dem faktisk er røde. Vi får altså \\(7\\) fejlklassifikationer i alt. Det giver en fejlklassifikationsrate på \\(7/20=0.35\\).\nFigur 2: Klassifikation med tærskelværdi \\(t=10\\). Observationer i det blå område prædikteres blå, mens observationer i det røde område prædikteres røde. Udfyldte cirkler angiver korrekte klassifikationer. Åbne cirkler angiver fejlklassifikationer.\nVi kan gøre det samme for forskellige værdier af \\(t\\)  og tælle antallet af fejlklassifikationer. Resultatet ses i tabel 1.\nDen laveste fejlklassifikationsrate får vi ved at vælge \\(t=20\\), sådan at alle observationer prædikteres til at være blå. Men hvis vi er ude på at identificere de sjældne røde, så er sådan en test jo ikke meget værd, fordi vi aldrig vil prædiktere nogle observationer som røde. I ovenstående eksempel kunne man i stedet have valgt at sætte \\(t=12\\). Så får man ganske vist \\(5\\) fejlklassifikationer i stedet for \\(3\\). Til gengæld finder man alle de røde. Det virker som et mere fornuftigt valg i vores eksempel.\nHvordan vælger man så den bedste tærskelværdi? Det vil sige, hvordan finder man en god balance mellem ikke at lave for mange fejl og samtidig fange så mange som muligt fra den sjældne klasse? Her får vi brug for et mål for, hvor godt algoritmen prædikterer hver af de to klasser. Sensitivitet og specificitet er sådanne mål."
  },
  {
    "objectID": "materialer/ROC/ROC.html#sensitivitet-og-specificitet",
    "href": "materialer/ROC/ROC.html#sensitivitet-og-specificitet",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "Sensitivitet og specificitet",
    "text": "Sensitivitet og specificitet\nLad os igen se på situationen, hvor vi har en prædiktionsalgoritme, der prædikterer klasserne rød og blå. For at få et overblik over, hvor godt algoritmen prædikterer, kan man lave en confusion matrix, som skitseret på figur 3, hvor et positivt resultat svarer til klassen rød1. Diagonalen (de grønne celler) svarer til observationer, der er klassificeret korrekt. En god algoritme skal have så mange observationer som muligt på diagonalen.\n1 Ordene positiv og negativ stammer fra medicin, hvor man bruger en test til at klassificere patienter som syge eller raske. En positiv test indikerer, at patienten er syg. I andre sammenhænge svarer et positivt resultat til, at man har prædikteret den sjældne klasse.\n\n\n\n\n\n\n\nFigur 3: Illustration af confusion matrix.\n\n\n\n\n\nHvis vi udelukkende er interesseret i, hvor god algoritmen er til at prædiktere den røde klasse, kan vi kigge på sensitiviteten. Dette er sandsynligheden for, at en observation, hvis sande farve er rød, faktisk bliver klassificeret som rød, altså\n\\[\n\\textrm{sensitivitet} = P(\\textrm{ en sand rød observation prædikteres som rød })\n\\tag{1}\\]\nTilsvarende kan man måle, hvor god en algoritme er til at prædiktere den blå klasse ved at se på specificiteten. Dette er sandsynligheden for, at en sand blå observation faktisk bliver klassificeret som blå. Det kan udtrykkes som\n\\[\n\\textrm{specificitet} = P(\\textrm{ en sand blå observation prædikteres som blå } ).\n\\]\nLad os se på eksemplet fra figur 1 igen, hvor vi sætter tærskelværdien til \\(t=15\\). Vi udfylder confusion matricen med antallet af observationer i hver celle.\n\n\n\n\n\n\n\n\nFigur 4: Confusion matrix med \\(t=15\\).\n\n\n\n\n\nSensitiviteten beregnes som andelen af det samlede antal sande røde, der bliver prædikteret røde. Ved at se på første søjle i figur 4 finder vi, at der er \\(2+1=3\\) sande røde, hvoraf \\(2\\) bliver prædikteret røde. Det giver sensitiviteten\n\\[\n\\textrm{sensitivitet} = \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal sande røde}} = \\frac{2}{3} = 0.667.\n\\tag{2}\\]\nTilsvarende kan vi beregne specificiteten ved at se på anden søjle.\n\\[\n\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal sande blå}} = \\frac{14}{3+14}= 0.824.\n\\]\nAlgoritmen er altså bedst til at finde blå, da specificiteten er højere end sensitiviteten. Lad os prøve, om vi kan få højere sensitivitet med en anden værdi af \\(t\\). Værdien \\(t=12\\) var den største værdi, der kunne finde alle de røde – se igen figur 1. Det giver os confusion matricen i figur 5.\n\n\n\n\n\n\n\n\nFigur 5: Confusion matrix med \\(t=12\\).\n\n\n\n\n\nVi beregner igen sensitiviteten og specificiteten \\[\\textrm{sensitivitet} = \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal sande røde}} = \\frac{3}{3} = 1\\] og \\[\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal sande blå}} = \\frac{12}{5+12}= 0.706.\\] Vi ser altså, at prisen for at få en højere sensitivitet er en lavere specificitet.\nEndelig kan vi prøve med værdien \\(t=20\\), som var den, der gav den laveste fejlklassifikationsrate. Denne værdi giver confusion matricen i figur 6.\n\n\n\n\n\n\n\n\nFigur 6: Confusion matrix med \\(t=20\\).\n\n\n\n\n\nVi finder sensitiviteten \\[\n\\textrm{sensitivitet} = \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal sande røde}} = \\frac{0}{3}= 0\n\\] og specificiteten \\[\n\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal sande blå}} = \\frac{17}{17}= 1.\n\\] Testen er altså rigtig god til at finde blå klasser, men elendig til at finde røde klasser.\n\n\n\n\n\n\nSensitivitet og specificitet som betingede sandsynligheder\n\n\n\n\n\nSensitivitet og specificitet kan beskrives ved hjælp af betingede sandsynligheder. Lad \\(A\\) og \\(B\\) være to hændelser, således at \\(B\\) har positiv sandsynlighed \\(P(B)&gt;0\\). Den betingede sandsynlighed for \\(A\\) givet \\(B\\) betegnes \\(P(A|B)\\) og er defineret som\n\\[\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}.\n\\tag{3}\\]\nHer er \\(A\\cap B\\) fælleshændelsen, det vil sige hændelsen, at \\(A\\) og \\(B\\) forekommer samtidig. Vi fortolker \\(P(A|B)\\) som sandsynligheden for, at hændelsen \\(A\\) indtræffer, hvis vi ved, at hændelsen \\(B\\) er indtruffet. Dette giver mening i forhold til definitionen (3), idet brøken angiver, hvor stor en andel af sandsynligheden for \\(B\\), der udgøres af sandsynligheden for, at \\(A\\) indtræffer samtidig med \\(B\\).\nLad os se på et eksempel, hvor vi slår to gange med en terning. Lad \\(A\\) være hændelsen, at vi slår to seksere, og lad \\(B\\) hændelsen, at den første terning viser seks. Da er\n\\[\nP(A)=P(\\textrm{to seksere})=1/36\n\\] og \\[\nP(B)=P(\\textrm{første terning viser seks})=1/6.\n\\] Intuitivt vil man forvente, at sandsynligheden for to seksere vokser, hvis den første terning viser en sekser. Det kan vi bekræfte ved hjælp at betingede sandsynligheder. \\[\nP(\\textrm{to seksere} | \\textrm{første terning viser seks}) = P(A|B) =  \\frac{P(A\\cap B)}{P(B)} = \\frac{1/36}{1/6} = \\frac{1}{6}.\n\\] Her har vi udnyttet, at \\(A\\cap B=A\\), da første terning er nødt til at vise seks for, at vi kan få to seksere. Vi ser altså, at \\[\nP(\\textrm{to seksere} | \\textrm{første terning viser seks}) = \\frac{1}{6} \\neq \\frac{1}{36} = P(\\textrm{to seksere}).\n\\]\nTerningeksemplet viser et eksempel, hvor \\(P(A)\\neq P(A|B)\\), altså hvor sandsynligheden for \\(A\\) ændrer sig, hvis vi ved, at \\(B\\) er indtruffet. Dette er ofte tilfældet. Nogle gange kan vi dog have at \\(P(A|B)=P(A)\\), altså at vi ikke får nogen ny viden om sandsynligheden for \\(A\\) ud fra vores viden om \\(B.\\) I dette tilfælde siger vi, at \\(A\\) og \\(B\\) er uafhængige.\nSensitiviteten kan defineres formelt ved hjælp af betingede sandsynligheder som sandsynligheden for at få en rød prædiktion, givet at den sande klasse er rød, altså \\[\n\\begin{aligned}\n\\textrm{sensitivitet} &= P(\\textrm{ prædiktionen er rød }|\\textrm{ den sande klasse er rød }) \\\\ \\\\\n&= \\frac{P(\\textrm{ den sande klasse er rød og prædiktionen er rød })}{P(\\textrm{ den sande klasse er rød })}.\n\\end{aligned}\n\\] I praksis estimerer vi sandsynligheden for en sand rød som antallet af sande røde divideret med det samlede antal observationer. Sandsynligheden for, at en observation både er rød og klassificeres som rød, estimeres som antallet, der både er røde og klassificeres røde, divideret med det samlede antal observationer. Vi kan derfor estimere sensitiviteten ved \\[\n\\begin{aligned}\n\\textrm{sensitivitet} &= \\frac{(\\textrm{antal røde der prædikteres røde})/(\\textrm{samlet antal})}{(\\textrm{antal røde})/(\\textrm{samlet antal})} \\\\ \\\\\n&= \\frac{\\textrm{antal røde der prædikteres røde}}{\\textrm{antal røde}}.\n\\end{aligned}\n\\] Det var netop den formel, vi brugte til at udregne sensitiviteten i (1).\nSpecificiteten kan tilsvarende defineres som \\[\n\\begin{aligned}\n\\textrm{specificitet} &= P(\\textrm{ prædiktionen er blå }|\\textrm{ den sande klasse er blå }) \\\\ \\\\\n&= \\frac{P(\\textrm{ den sande klasse er blå og prædiktionen er blå })}{P(\\textrm{ den sande klasse er blå })}.\n\\end{aligned}\n\\] Man kan som ovenfor regne sig frem til, at specificiteten kan estimeres ved \\[\n\\begin{aligned}\\textrm{specificitet} = \\frac{\\textrm{antal blå der prædikteres blå}}{\\textrm{antal blå}}.\n\\end{aligned}\n\\]"
  },
  {
    "objectID": "materialer/ROC/ROC.html#roc-kurver",
    "href": "materialer/ROC/ROC.html#roc-kurver",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "ROC-kurver",
    "text": "ROC-kurver\nI praksis har man brug for at finde en tærskelværdi \\(t\\), som giver en god afvejning mellem sensitivitet og specificitet. Det kan afhænge af anvendelsen, hvor højt man vægter de to. Hvis man er ude på at diagnosticere en sjælden sygdom, er det umiddelbart vigtigst, at sensitiviteten er høj, så man finder alle de syge. Dog er det problematisk, hvis specificiteten bliver for lav, da man så kommer til at diganosticere mange raske som syge, hvilket kan medføre unødvendige undersøgelser og behandlinger for patienten.\nSå hvordan vælger man en tærskelværdi, der giver en god afvejning mellem sensitivitet og specificitet? Som en hjælp kunne man udregne sensitivitet og specificitet for forskellige mulige værdier af \\(t\\). Det er for vores eksempel gjort i tabel 2.\n\n\n\nTabel 2: Sensitivitet og specificitet for forskellige tærskelværdier.\n\n\n\n\n\nTærskelværdi \\(t\\)\nSensitivitet\nSpecificitet\n\n\n\n\n1\n1\n0.059\n\n\n2\n1\n0.118\n\n\n3\n1\n0.176\n\n\n4\n1\n0.235\n\n\n5\n1\n0.294\n\n\n6\n1\n0.353\n\n\n7\n1\n0.412\n\n\n8\n1\n0.471\n\n\n9\n1\n0.529\n\n\n10\n1\n0.588\n\n\n11\n1\n0.647\n\n\n12\n1\n0.706\n\n\n13\n0.667\n0.706\n\n\n14\n0.667\n0.765\n\n\n15\n0.667\n0.824\n\n\n16\n0.333\n0.824\n\n\n17\n0.333\n0.882\n\n\n18\n0\n0.882\n\n\n19\n0\n0.941\n\n\n20\n0\n1\n\n\n\n\n\n\nMan kan så gå ind i tabel 2 og lede efter et godt \\(t\\), hvor både sensitivitet og specificitet er høj. En tabel som ovenfor bliver dog hurtigt uoverskuelig, hvis man har et stort datasæt. For at få overblik kan man i stedet vælge at tegne samhørende værdier af sensitivitet og specificitet ind i et koordinatsystem. Traditionelt vælger man at have \\(1-\\textrm{specificitet}\\) på \\(x\\)-aksen og \\(\\textrm{sensitivitet}\\) på \\(y\\)-aksen. Den kurve, der fremkommer, når punkterne forbindes, kaldes en ROC-kurve2. På figur 7 er ROC-kurven fra dataeksemplet i figur 1 indtegnet.\n2 ROC står for Receiver Operating Characteristic.\n\n\n\n\n\n\n\nFigur 7: ROC-kurve for dataeksemplet i figur 1.\n\n\n\n\n\nVi vil gerne have både sensitivitet og specificitet til at være så tæt på \\(1\\) som muligt. Det betyder derfor, at vi gerne vil have \\(1-\\textrm{specificitet}\\) så tæt på \\(0\\) som muligt. Vi søger derfor samlet set et punkt på ROC-kurven, der ligger tæt på punktet \\((0,1)\\). Ud fra ROC-kurven kunne punktet \\((0.176,0.667)\\) ligne et godt bud. Ifølge tabel 2 svarer det til en tærskelværdi på \\(t=15\\).\nTil sammenligning kunne vi forestille os en algoritme, der laver en hel tilfældig prædiktion, hvor hver observation bliver klassificeret som rød med sandsynlighed \\(p\\) og blå med sandsynlighed \\(1-p\\) uden at tage højde for værdien af \\(x\\). For sådan en algoritme er sandsynligheden for, at en sand rød prædikteres rød altså også \\(p\\), så\n\\[\\textrm{sensitivitet} = P(\\textrm{ en sand rød prædikteres rød }) = P(\\textrm{ rød prædiktion }) = p.\\] Tilsvarende kan vi beregne specificiteten \\[\n\\textrm{specificitet} = P(\\textrm{ en sand blå prædikteres blå }) = P(\\textrm{ blå prædiktion }) = 1- p\n\\] og derfor\n\\[1-\\textrm{specificitet} = 1-( 1- p) =  p.\\] For sådan en test får vi altså et punkt på den tilhørende ROC-kurve med koordinatsæt\n\\[\n(1-\\textrm{specificitet},\\textrm{sensitivitet}) = (p,p).\n\\] Alle punkter hvor første- og andenkoordinaten er ens ligger på identitetslinjen \\(y=x\\). Alt i alt viser dette, at punkterne på identitetslinjen svarer til helt tilfældig prædiktion. På figur 7 er identitetslinjen \\(y=x\\) også indtegnet. En prædiktionsalgoritme skal derfor helst give et punkt, der ligger over identitetslinjen. Ellers er den ikke bedre end et tilfældigt gæt."
  },
  {
    "objectID": "materialer/ROC/ROC.html#auc",
    "href": "materialer/ROC/ROC.html#auc",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "AUC",
    "text": "AUC\nHvis vi har brug for at sammenligne forskellige prædiktionsalgoritmer, kan det godt være svært at sammenligne deres fulde ROC-kurver. Det er nemmere at sammenligne et enkelt tal, der opsummerer, hvor god ROC-kuven er. Her kan AUC bruges.\nHusk på, at ROC-kurven gerne skulle ligge så tæt op mod punktet \\((0,1)\\) og så langt over identitetslinjen som muligt. Vi kan derfor bruge arealet under ROC-kurven, også kaldet AUC3, som mål for hvor meget ROC-kurven er strakt opad mod \\((0,1)\\).\n3 AUC står for Area Under Curve.Optimalt set skulle ROC-kurven stige lodret op til punktet \\((0,1)\\) og derefter fortsætte vandret over mod \\((1,1)\\) (den orange kurve på figur 8), svarende til, at der er en \\(t\\)-værdi, der giver perfekt prædiktion. I denne situation er \\(AUC=1\\). Omvendt så vi, at identitetslinjen (den grønne kurve på figur 8) svarer til fuldstændig tilfældig prædiktion uden brug af \\(x\\). Dette svarer til \\(AUC=1/2\\). En fornuftig algoritme skal således gerne have et \\(AUC\\) mellem \\(1/2\\) og \\(1\\), hvor høje tal er bedst. I vores dataeksempel (den sorte kurve på figur 8) kan man udregne \\(AUC=0.804\\).\n\n\n\n\n\n\n\n\nFigur 8: AUC for perfekt klassifikation (orange), tilfældig klassifikation (grøn) og vores dataeksempel (sort).\n\n\n\n\n\nMan kan vise, at AUC har en konkret fortolkning. Hvis man tager et vilkårligt element fra den blå klasse og et fra den røde klasse, så vil AUC-værdien være sandsynligheden for, at \\(x\\)-værdien for den røde klasse er højere end \\(x\\)-værdien for den blå klasse. Hvis man prøver at gætte, hvilken af de to klasser der er rød ud fra \\(x\\)-værdien, er AUC altså sandsynligheden for, at man gætter rigtigt."
  },
  {
    "objectID": "materialer/ROC/ROC.html#forskellige-overvejelser",
    "href": "materialer/ROC/ROC.html#forskellige-overvejelser",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "Forskellige overvejelser",
    "text": "Forskellige overvejelser\n\nHvornår skal man bruge sensitivitet og specificitet?\nVi så i dataeksemplet fra figur 1, at fejlklassifikationsraten ikke egner sig som mål for, hvor godt en algoritme prædikterer, når en af klasserne er meget små. Her er det ofte en fordel at tillade flere fejlklassifikationer for at opnå en højere sensitivitet. Desuden kan det være en fordel at kigge på sensitivitet og specificitet i en situation, hvor man er mere interesseret i den ene klasse end i den anden. Det kunne fx være i forbindelse med test for sygdom under en epidemi, hvor det er vigtigere at finde alle de syge, så de kan komme i karantæne, end at man undgår at sende raske i karantæne.\n\n\nFlere inputvariable\nOfte har man i praksis mere end én inputvariabel \\(x\\) at prædiktere ud fra. Lad os sige, at vi har målt variablene \\(x_1,x_2,\\ldots,x_p\\). Mange algoritmer (blandt andet perceptronen, simple neurale netværk, neurale netværk og logistisk regression) laver på en eller anden måde prædiktionerne ud fra en vægtet sum af variablene: \\[w_0+w_1x_1 + w_2x_2 + \\dotsm +w_p x_p\\] hvor \\(w_0, w_1, w_2,\\ldots,w_p \\in \\mathbb{R}\\) er konstanter. Man prædikterer så den ene klasse når \\[w_0+w_1x_1 + w_2x_2 + \\dotsm +w_p x_p &gt; t\\] og den anden klasse når \\[w_0+w_1x_1 + w_2x_2 + \\dotsm +w_p x_p \\leq t\\] hvor \\(t\\) er en passende tærskelværdi. Ofte bruger algoritmen som udgangspunkt \\(t=0\\). Som i tilfældet med én inputvariabel kan det dog give mening at vælge et andet \\(t\\) for at få bedre sensitivitet og specificitet. Igen kan man beregne confusion matricen, sensitivitet og specificitet for forskellige værdier af \\(t\\) og tegne ROC-kurven for at finde et godt \\(t\\). Vil man sammenligne flere algoritmer, kan man desuden beregne deres AUC ud fra ROC-kurven.\n\n\nOverfitting\nI eksemplet fra figur 1 fandt vi, at \\(t=15\\) virkede som et fornuftigt valg. Det var i hvert fald et \\(t\\), der passede godt på det datasæt, vi havde. Det betyder dog ikke, at det er det \\(t\\), der generaliserer bedst til nye data. Lad os sige, at vi får et nyt datasæt og gerne vil bruge prædiktionsalgoritmen på det. På figur 9 ses et eksempel på, hvordan et nyt datasæt kunne se ud.\n\n\n\n\n\n\n\n\nFigur 9: Det oprindelige data fra figur 1 og et nyt datasæt klassificeret ud fra tærskelværdien \\(t=15\\).\n\n\n\n\n\nMed \\(t=15\\) får vi fejlklassificeret \\(3\\) ud af \\(4\\) røde i det nye datasæt, så sensitiviteten er \\(1/4=0.25\\). Tilsvarende får vi fejlklassificeret \\(4\\) ud af \\(17\\) blå i det nye data, så specificiteten er \\(13/17 = 0.765\\). Da vi brugte det oprindelige data fik vi sensitiviteten \\(0.667\\) og specificiteten \\(0.824\\). Både sensitivitet og specificitet er altså markant lavere for det nye data. Det sker, fordi \\(t\\) er valgt til at give høj sensitivitet og specificitet på lige præcis det oprindelige data. Det garanterer imidlertid ikke, at det passer lige så godt til nye data. Vi siger, at algoritmen er overfittet til det oprindelige data. Sensitivitet og specificitet giver altså ikke et retvisende mål for, hvor godt algoritmen prædikterer på nye data. Du kan læse mere om overfitting her."
  },
  {
    "objectID": "materialer/ROC/ROC.html#ekstra-positiv-og-negativ-prædiktiv-værdi",
    "href": "materialer/ROC/ROC.html#ekstra-positiv-og-negativ-prædiktiv-værdi",
    "title": "Sensitivitet, specificitet, ROC-kurver og AUC",
    "section": "Ekstra: Positiv og negativ prædiktiv værdi",
    "text": "Ekstra: Positiv og negativ prædiktiv værdi\nSensitivitet og specificitet bruges til at afgøre, hvor god en prædiktionsalgoritme er til at ramme rigtigt inden for hver klasse. Hvis vi for eksempel er ude på at prædiktere sygdom, så måler sensitiviteten sandsynligheden for, at en syg erklæres syg, og specificiteten måler sandsynligheden for, at en rask erklæres rask. En patient vil dog ofte være mere interesseret i det omvendte spørgsmål: “Jeg har fået en positiv test. Hvad er sandsynligheden for, at jeg faktisk er syg?” Det kan lyde som næsten det samme, men det er faktisk et helt andet spørgsmål.\nLad os igen kigge på eksemplet med den røde og den blå klasse. Sensitiviteten var sandsynligheden for, at en sand rød observation bliver prædikteret som rød. Her tager vi altså udgangspunkt i, at den sande klasse er rød og kigger på sandsynligheden for, at observationen bliver klassificeret korrekt. I stedet kunne man kigge på sandsynligheden for, at en rød prædiktion faktisk betyder, at den sande klasse er rød. Her tager vi udgangspunkt i, at prædiktionen er rød og beregner sandsynligheden for, at den sande klasse er rød. Dette kaldes den positive prædiktive værdi, som altså er givet ved \\[\n\\textrm{positiv prædiktiv værdi} = P(\\textrm{ en rød prædiktion er faktisk rød } ).\n\\] I praksis beregnes den positive prædiktive værdi ved formlen \\[\n\\textrm{positiv prædiktiv værdi} = \\frac{\\textrm{antal røde prædiktioner som faktisk er røde}}{\\textrm{antal røde prædiktioner}}.\n\\] Bemærk, at tælleren er den samme, som når vi beregner sensitivitet (2), mens nævneren er forskellig. Generelt vil sensitivitet og positiv prædiktiv værdi altså være forskellige tal.\nLad os igen se på vores lille dataeksempel med tærsklen \\(t=15\\), der gav anledning til confusion matricen på figur 4. De røde prædiktioner findes i første række. Der er \\(5\\) røde prædiktioner i alt, hvoraf \\(2\\) faktisk er røde. Den positive prædiktive værdi kan udregnes til \\[\n\\textrm{positiv prædiktiv værdi} = \\frac{\\textrm{ antal røde prædiktioner som faktisk er røde }}{\\textrm{ antal røde prædiktioner }}\\] \\[= \\frac{2}{5} = 0.4.\n\\tag{4}\\] Det betyder altså, at hvis vi har en rød prædiktion, så er sandsynligheden for, at den sande klasse er rød kun \\(0.4\\). Det er tilfældet på trods af, at både sensitivitet og specificitet var høje. Kort fortalt er grunden, at den røde klasse er så sjælden, at det er usandsynligt, at den sande klasse er rød, uanset om prædiktionen er rød eller blå. En mere præcis forklaring kan du finde i boksen nederst på siden.\nMan kan selvfølgelig definere den negative prædiktive værdi tilsvarende. \\[\n\\textrm{negativ prædiktiv værdi} = P(\\textrm{ en blå prædiktion er faktisk blå } ).\n\\] Den negative prædiktive værdi kan beregnes ved \\[\n\\textrm{negativ prædiktiv værdi} = \\frac{\\textrm{antal blå prædiktioner som faktisk er blå}}{\\textrm{antal blå prædiktioner}}.\n\\]\nLad os igen se på vores lille dataeksempel med \\(t=15\\) svarende til confusion matricen på figur 4. For at finde den negative prædiktive værdi, bruger vi formlen \\[\n\\begin{aligned}\n\\textrm{negativ prædiktiv værdi} &= \\frac{\\textrm{ antal blå prædiktioner som faktisk er blå }}{\\textrm{ antal blå prædiktioner}}\\\\\n&= \\frac{14}{15} = 0.933\n\\end{aligned}\n\\] Får man en blå prædiktion, kan man altså være \\(93.3\\%\\) sikker på, at den er korrekt, mens man kun kunne være \\(40\\%\\) sikker på en rød prædiktion.\nBemærk, at når vi beregner sensitivitet og specificitet, er det henholdsvis første og anden søjle i confusion matricen, vi bruger, mens det er henholdsvis første og anden række i confusion matricen, vi bruger til at beregne positiv og negativ prædiktiv værdi.\nEn væsentlig forskel på sensitivitet/specificitet og positiv/negativ prædiktiv værdi er, at sensitivitet og specificitet er faste egenskaber ved prædiktionsalgoritmen. De kan beregnes ved at teste algoritmen på en gruppe blå og en gruppe røde observationer og se, hvor ofte vi rammer plet. Positiv og negativ prædiktiv værdi afhænger derimod af hyppigheden af klasserne4. Det betyder for eksempel, at hvis man forsøger at prædiktere sygdom under en epidemi, så ændrer sandsynligheden for sygdom sig hele tiden, og det gør den positive og negative prædiktive værdi derfor også.\n4 De matematiske detaljer er givet i boksen nedenfor.\n\n\n\n\n\nTeori om sammenhængen mellem sensitivitet og positiv prædiktiv værdi\n\n\n\n\n\nSensitiviteten var sandsynligheden for, at en sand rød blev klassificeret som rød. Udtrykt ved betingede sandsynligheder var det \\[\n\\textrm{sensitivitet} = P(\\textrm{ prædiktionen er rød }|\\textrm{ den sande klasse er rød }).\n\\] Den positive prædiktive værdi kan tilsvarende udtrykkes ved hjælp af betingede sandsynligheder som \\[\n\\textrm{positiv prædiktiv værdi} = P(\\textrm{ den sande klasse er rød }|\\textrm{ prædiktionen er rød }).\n\\] De to formler minder meget om hinanden. Der er bare byttet om på de to hændelser i den betingede sandsynlighed.\nHvis \\(A\\) og \\(B\\) er to hændelser med \\(P(A)&gt;0\\) og \\(P(B)&gt;0\\), så er \\(P(A|B)\\) og \\(P(B|A)\\) relateret via Bayes’ formel \\[P(A|B) = P(B|A)\\cdot\\frac{P(A)}{P(B)}\\] For at se, hvorfor det gælder, bruger vi først definitionen af \\(P(A|B)\\) \\[P(A|B) = \\frac{P(A\\cap B)}{P(B)}\\] Vi forlænger brøken med \\(P(A)\\) og bruger en brøkregneregel \\[P(A|B) = \\frac{P(A\\cap B)\\cdot P(A)}{P(B)\\cdot P(A)} =\\frac{P(A\\cap B)}{P(A)}\\cdot \\frac{P(A)}{P(B)}\\] Endelig bruger vi, at \\(P(B|A)=\\frac{P(A\\cap B)}{P(A)}\\). Det giver \\[P(A|B) = P(B|A)\\cdot\\frac{P(A)}{P(B)}.\\] Vi har hermed bevist Bayes’ formel.\nLader vi \\(A=\\{\\textrm{sand rød}\\}\\) og \\(B=\\{\\textrm{rød prædiktion}\\}\\) i Bayes’ formel, får vi følgende sammenhæng mellem positiv prædiktiv værdi og sensitivitet \\[\n\\textrm{positiv prædiktiv værdi} = P(\\textrm{ sand rød }| \\textrm{ rød prædiktion })\\] \\[= P( \\textrm{ rød prædiktion }| \\textrm{ sand rød })\\cdot \\frac{P(\\textrm{ sand rød })}{P(\\textrm{ rød prædiktion })}\\] \\[= \\textrm{sensitivitet}\\cdot \\frac{P(\\textrm{ sand rød })}{P(\\textrm{ rød prædiktion })}.\n\\tag{5}\\] Formlen (5) viser, at hvis sandsynligheden for at tilhøre den røde klasse er meget lav i forhold til sandsynligheden for at lave en rød prædiktion, vil den positive prædiktive værdi være meget lavere end sensitiviteten.\nLad os se lidt nærmere på nævneren i (5), det vil sige \\(P(B)=P(\\textrm{rød prædiktion})\\). Husk på at \\(A=\\{\\textrm{sand rød}\\}\\). Komplementærhændelsen til \\(A\\) er hændelsen, at \\(A\\) ikke indtræffer, og betegnes \\(A^c\\). I vores tilfælde er \\(A^c=\\{\\textrm{ikke sand rød}\\}=\\{\\textrm{sand blå}\\}\\). Hændelsen \\(B\\), at prædiktionen er rød, kan opnås ved, at prædiktionen er rød, og den underliggende klasse er rød, svarende til \\(B \\cap A\\), eller ved at prædiktionen er rød, og den sande klasse er blå, svarende til \\(B\\cap A^c\\). Vi kan derfor beregne sandsynligheden for \\(B\\) som summen \\[P(B) = P(B\\cap A) + P(B\\cap A^c) \\tag{6}\\] Vi bemærker nu, at definitionen af betinget sandsynlighed \\[P(B|A)=\\frac{P(B\\cap A)}{P(A)}\\] kan omskrives til \\[P(B|A)P(A) = P(B\\cap A)\\] På samme vis fås \\(P(B|A^c)P(A^c) = P(B \\cap A^c)\\). Dette kan vi indsætte i (6) og få \\[P(B) = P(B\\cap A) + P(B\\cap A^c) = P(B | A)P(A) + P(B|A^c)P(A^c).\\] Denne formel kaldes loven om den totale sandsynlighed.\nBruger vi loven om den totale sandsynlighed på formlen for positiv prædiktiv værdi (5), får vi \\[\\textrm{positiv prædiktiv værdi} = \\textrm{sensitivitet}\\cdot \\frac{P(\\textrm{sand rød})}{P(\\textrm{rød prædiktion})}\\] \\[\n\\begin{aligned}\n= &\\textrm{sensitivitet}\\cdot \\\\ &\\frac{P(\\textrm{sand rød})}{P(\\textrm{rød prædiktion} |\\textrm{sand rød})P(\\textrm{sand rød}) + P(\\textrm{rød prædiktion}|\\textrm{sand blå})P(\\textrm{sand blå}) }\n\\end{aligned}\n\\]\n\\[= \\textrm{sensitivitet}\\cdot \\frac{P(\\textrm{sand rød})}{\\textrm{sensitivitet}\\cdot P(\\textrm{sand rød}) + (1-\\textrm{specificitet})\\cdot P(\\textrm{sand blå}) }\n\\tag{7}\\] Vi ser, at hvis specificiteten ikke er meget høj, og sandsynligheden for sand rød er lav (og dermed sandsynligheden for sand blå høj), så er tælleren i (7) lille i forhold til nævneren. Den positive prædiktive værdi vil derfor være væsentligt lavere end sensitiviteten. Det var det, der skete i eksemplet (4).\nFormlen (7) viser desuden, at den positive prædiktive værdi afhænger af ikke bare sensitivitet og specificitet, men også af fordelingen mellem de to klasser (altså sandsynligheden for sand rød og sand blå). Hvis fordelingen ændrer sig, så den røde klasse for eksempel bliver mere sandsynlig, så ændrer den positive prædiktive værdi sig også. Dette er illustreret i figuren herunder. Her er det vist, hvordan den positive prædiktive værdi ændrer sig som en funktion af \\(P(\\textrm{ sand rød })\\) i et eksempel hvor sensitiviteten er \\(0.9\\) og specificiteten er \\(0.6\\). Her ses det tydeligt, at jo større sandsynligheden for sand rød er, desto større bliver også den positive prædiktive værdi."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html",
    "href": "materialer/logistisk/log-reg.html",
    "title": "Logistisk regression",
    "section": "",
    "text": "I denne note skal vi se på logistisk regression. Måske har du allerede hørt begrebet \"logistisk\" i gymnasieundervisningen i forbindelse med logistisk vækst. Det er et helt andet emne end logistisk regression. Det eneste, de to emner umiddelbart har til fælles, er, at den logistiske funktion spiller en rolle begge steder. I slutningen af noten vil vi dog se et eksempel, hvor der alligevel er en sammenhæng mellem logistisk regression og logistisk vækst."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#logistisk-regression-og-hjerte-kar-sygdom",
    "href": "materialer/logistisk/log-reg.html#logistisk-regression-og-hjerte-kar-sygdom",
    "title": "Logistisk regression",
    "section": "Logistisk regression og hjerte-kar-sygdom",
    "text": "Logistisk regression og hjerte-kar-sygdom\nEn helt central tankegang i mange metoder inden for kunstig intelligens er, at man på baggrund af en masse træningsdata for eksempel gerne vil afgøre om en patient er syg eller ej. En populær metode til det er at bruge et kunstigt neuralt netværk, som er en slags black-box-metode, og som du kan læse mere om her. Men hvis man lige præcis bruger et særligt slags neuralt netværk med et enkelt lag, er det faktisk ækvivalent med den meget ældre metode \"logistisk regression\", som vi gennemgår her, og som har den store fordel, at man kan forstå og fortolke modellen.\nLogistisk regression, i den betydning vi betragter i denne note, bruges, når man gerne vil modellere, hvordan en sandsynlighed afhænger af en variabel. Som et eksempel forestiller vi os, at vi vil undersøge, hvordan sandsynligheden for at lide af hjerte-kar-sygdom afhænger af det systoliske blodtryk. Vi kigger derfor på et datasæt bestående af 2000 mennesker, som har fået målt deres blodtryk. Desuden har de fået undersøgt, om de lider af hjerte-kar-sygdom. Datasættet er fiktivt, men det er lavet til at ligne virkelige data1. Vi kalder blodtrykket for \\(x\\), mens vi lader \\(y\\) være en variabel, der er \\(1\\) hvis personen lider af hjertekarsygdom og \\(0\\) ellers. På figur 1 har vi tegnet samhørende \\(x\\)- og \\(y\\)-værdier ind i et koordinatsystem for de første 200 personer i datasættet.\n1 De fleste mennesker har et systolisk blodtryk mellem 100 og 180 mmHg. I datasættet har vi genereret en masse mennesker med ekstremt højt eller lavt blodtryk for illustrationens skyld, selv om det er urealistisk i praksis.\n\n\n\n\n\n\n\nFigur 1: Her ses et plot af data med blodtryk på \\(x\\)-aksen og sygdomsstatus på \\(y\\)-aksen.\n\n\n\n\n\nDet ses på figur 1, at der er flest personer med \\(y\\)-værdien 0, altså raske personer, blandt folk med lavt blodtryk, mens der er flest med \\(y\\)-værdien 1, svarende til syge, blandt folk med højt blodtryk. Ved de fleste blodtryksværdier er der dog både syge og raske, og det er svært at få et præcist overblik ud fra figuren.\nSå hvordan kan man beskrive sammenhængen mellem \\(x\\) og \\(y\\)? I stedet for at se direkte på sammenhængen mellem \\(x\\) og \\(y\\), vil vi se på hvordan sandsynligheden for hjerte-kar-sygdom afhænger af blodtrykket. Vi vil betragte denne sandsynlighed som en funktion \\(p(x)\\) af blodtrykket \\(x\\). Vi vil nu se på, hvordan man kan modellere denne funktion.\nFor at få en idé om, hvordan \\(p(x)\\) kunne se ud, kigger vi på datasættet fra før. Vi inddeler blodtrykket i intervaller af længde 25 og tæller op, hvor mange syge og raske der er inden for hvert interval.\n\n\n\n\n\n\n\n\nBlodtryk\nRask\nSyg\nAndel syge\n\n\n\n\n(75,100]\n168\n29\n0.147\n\n\n(100,125]\n195\n45\n0.188\n\n\n(125,150]\n143\n63\n0.306\n\n\n(150,175]\n152\n105\n0.409\n\n\n(175,200]\n93\n135\n0.592\n\n\n(200,225]\n57\n136\n0.705\n\n\n(225,250]\n46\n179\n0.796\n\n\n(250,275]\n25\n204\n0.891\n\n\n(275,300]\n19\n206\n0.916\n\n\n\n\n\n\nTabel 1: Tabel over syge og raske inden for forskellige blodtryksintervaller.\n\n\n\n\nDesuden har vi beregnet, hvor stor en andel af patienterne inden for hvert interval, der lider af hjerte-kar-sygdom. Dette bruges som et estimat for sandsynligheden for hjerte-kar-sygdom i den gruppe. For eksempel er der 195 raske og 45 syge personer med et blodtryk i intervallet (100,125]. Sammenlagt er der \\(195+45 = 240\\) personer i dette interval. Andelen af syge i denne gruppe er derfor \\[\n\\frac{45}{240} \\approx 0.188.\n\\] På figur 2 har vi tegnet disse andele ind i et koordinatsystem. For hvert blodtryksinterval er midtpunktet for intervallet indtegnet som \\(x\\)-værdien, og andelen af syge er indtegnet som den tilhørende \\(y\\)-værdi2.\n2 Det er klart, at vælger man nogle andre intervaller, så vil man få et lidt andet resultat. Bemærk også, at vi her bruger midtpunktet af intervallet i figur 2. Det er i modsætning til, når vi tegner sumkurver, hvor højre intervalendepunkt benyttes.\n\n\n\n\n\n\n\nFigur 2: Andel syge inden for hvert blodtryksinterval.\n\n\n\n\n\nUmiddelbart kunne det være fristende at lave lineær regression. Vi forestiller os altså en forskrift \\[\n    p(x) = ax + b.\n\\] På figur 3 har vi indtegnet den bedste rette linje i figur 2.\n\n\n\n\n\n\n\n\nFigur 3: Grafen for \\(p(x)\\) tilnærmet med en ret linje.\n\n\n\n\n\nDer er et problem her: En sandsynlighed ligger altid mellem 0 og 1, men regressionslinjen ovenfor skærer \\(x\\)-aksen ved blodtryksværdier omkring 70. Det betyder, at sandsynligheden er negativ for blodtryk under 70. Tilsvarende får vi sandsynligheder, der er større end 1 ved blodtryk over 300. Det giver selvfølgelig ikke mening.\nHvis vi kigger på figur 3 igen, ser sammenhængen da heller ikke lineær ud, men snarere S-formet. I stedet for en ret linje, ville det give mening at lade \\(p\\) være en funktion med en S-formet graf som indtegnet i figur 4.\n\n\n\n\n\n\n\n\nFigur 4: Graf for \\(p(x)\\) tilnærmet med en S-formet kurve.\n\n\n\n\n\nFor at komme nærmere hvordan funktionsforskriften for \\(p\\) skal se ud, viser det sig, at være smart at se på oddsene for sygdom i stedet for sandsynligheden3.\n3 Du kender måske begrebet odds fra sportsgambling. Det er dog en anden betydning af ordet, end det vi bruger her. Inden for gambling angiver odds, hvor mange gange man får pengene igen, hvis en bestemt hændelse indtræffer(for eksempel at et bestemt hold vinder). Gambling odds er naturligvis også udregnet ud fra sandsynligheden for hændelsen, men de er altid justeret for at sikre, at bookmakeren vinder i det lange løb."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#odds",
    "href": "materialer/logistisk/log-reg.html#odds",
    "title": "Logistisk regression",
    "section": "Odds",
    "text": "Odds\nOddsene \\(O\\) for en hændelse er defineret som sandsynligheden \\(p\\) for hændelsen divideret med sandsynligheden for, at hændelsen ikke indtræffer (det kaldes også for komplementærhændelsen), som er \\(1-p\\). Altså er \\[\n    O=\\frac{p}{1-p}.\n\\] Odds måler således, hvor mange gange mere sandsynlig en hændelse er i forhold til komplementærhændelsen. Hvis for eksempel sandsynligheden for hjerte-kar-sygdom er \\(p=\\frac{4}{5}\\), så er odds for sygdom \\[\n    O=\\frac{\\frac{4}{5}}{\\frac{1}{5}} = 4.\n\\] Det er altså fire gange så sandsynligt at være syg som at være rask.\nFor at få en lidt bedre fornemmelse for, hvordan odds fungerer, kan vi lave en tabel, der viser odds svarende til forskellige værdier af \\(p\\):\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(p\\)\n\\(\\frac{1}{5}\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{2}\\)\n\\(\\frac{2}{3}\\)\n\\(\\frac{3}{4}\\)\n\\(\\frac{4}{5}\\)\n\n\n\n\n\\(O\\)\n\\(\\frac{1}{4}\\)\n\\(\\frac{1}{3}\\)\n\\(\\frac{1}{2}\\)\n1\n2\n3\n4\n\n\n\nLæg her mærke til at jo større \\(p\\) bliver, desto større bliver odds \\(O\\) også.\nFunktionen, der omdanner sandsynligheder til odds, har forskriften \\[\nO(p) = \\frac{p}{1-p}.\n\\] Definitionsmængden for \\(O\\) er \\(]0,1[\\). Bemærk, at \\(1\\) ikke er med i definitionsmængden, fordi vi så vil komme til at dividere med \\(0\\) i ovenstående udtryk. Vi tillader heller ikke, at \\(0\\) er med i definitionsmængden. Der er ikke noget i vejen for at udregne odds til \\(0\\) (det vil bare give \\(0\\)), men det hænger sammen med, at vi senere gerne vil tage logaritmen til odds, og logaritmen er som bekendt kun defineret for positive tal og altså ikke for \\(0\\).\nGrafen for \\(O\\) er vist på figur 5.\n\n\n\n\n\n\n\n\nFigur 5: Grafen for odds-funktionen.\n\n\n\n\n\nVi kan se på figur 5, at odds-funktionen \\(O\\) er voksende. Det kan også bevises ved at vise, at \\(O'(p)&gt;0\\) for alle værdier af \\(p\\) (bonus spørgsmål i opgave 1). Vi ser desuden, at \\(O(p)\\) altid er positiv, da både tæller og nævner er positive. Når \\(p\\) nærmer sig \\(0\\), nærmer tælleren sig \\(0\\), mens nævneren nærmer sig \\(1\\), så \\(O(p)\\) går mod \\(0\\). Når \\(p\\) nærmer sig \\(1\\), nærmer tælleren sig \\(1\\), og nævneren nærmer sig \\(0\\), så hele brøken \\(O(p)\\) går mod uendelig. Værdimængden for \\(O\\) består derfor af alle de positive reelle tal.\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\n\nLad \\(p=4/7\\). Hvad er de tilhørende odds?\nAntag at oddsene er \\(O=3/2\\). Hvad er den tilsvarende sandsynlighed?\n\nFodboldholdene AFC og BFC spiller mod hinanden. Der spilles med forlænget spilletid og straffesparkskonkurrence indtil, der er fundet en vinder. Det er dobbelt så sandsynligt, at AFC vinder som, at BFC vinder.\n\nHvad er (de matematiske) odds for at AFC vinder?\nHvad er sandsynligheden for at AFC vinder?\n(Bonus) Vis at oddsfunktionen \\(O(p)\\) er voksende ved at differentiere og indse at \\(O'(p)&gt;0\\)."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#den-logistiske-regressionsmodel",
    "href": "materialer/logistisk/log-reg.html#den-logistiske-regressionsmodel",
    "title": "Logistisk regression",
    "section": "Den logistiske regressionsmodel",
    "text": "Den logistiske regressionsmodel\nI vores dataeksempel, hvor sandsynligheden for hjerte-kar-sygdom er en funktion \\(p(x)\\), bliver oddsene for hjerte-kar-sygdom også en funktion af \\(x\\) \\[\nO(p(x)) = \\frac{p(x)}{1-p(x)},\n\\] hvor \\(x\\) er blodtrykket.\nPå figur 6 vises dataeksemplet fra før, men nu har vi oddsene \\(O(p(x))\\) på \\(y\\)-aksen.\n\n\n\n\n\n\n\n\nFigur 6: Odds for hjerte-kar-sygdom inden for de forskellige blodtryksintervaller.\n\n\n\n\n\nVi ser, at oddsene for sygdom stiger med blodtrykket. Det betyder derfor også, at sandsynligheden for sygdom stiger med blodtrykket. Kigger vi på grafen, ser tendensen ikke lineær ud. Det kunne derimod ligne en eksponentiel vækst. For at bekræfte dette, laver vi samme plot på figur 7, men nu med den naturlige logaritme til oddsene \\(\\ln (O(p(x)))\\) på \\(y\\)-aksen4.\n4 Man kan nemlig vise, at hvis \\(y\\) afhænger eksponentielt af \\(x\\), så vil \\(\\ln(y)\\) afhænge lineært af \\(x\\).\n\n\n\n\n\n\n\nFigur 7: Den naturlige logaritme til odds for hjerte-kar-sygdom inden for de forskellige blodtryksintervaller.\n\n\n\n\n\nDer ser nu ud til at være en lineær sammenhæng! Det kunne altså tyde på, at ln-oddsene afhænger lineært af \\(x\\). Det leder os frem til følgende model for ln-oddsene: \\[\n\\ln (O(p(x))) = ax  + b.\n\\tag{1}\\] Denne model kaldes den logistiske regressionsmodel. Virkelige data følger ofte en logistisk regressionsmodel.\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nI denne opgave ser vi på sandsynligheden \\(p(x)\\) for at lide af forhøjet blodtryk5 som funktion af kolestreroltallet \\(x\\). Vi kigger derfor på datasættet nedenfor, som er en udvalgt del af et virkeligt datasæt. I tabellen angiver \\(y=1\\) forhøjet blodtryk, mens \\(y=0\\) angiver normalt blodtryk.\n\nLav en tabel, hvor du beregner sandsynligheden for forhøjet blodtryk, odds og ln(odds) inden for hvert interval.\nIndtegn punkter i et koordinatsystem, hvor \\(x\\)-værdien er midtpunkterne for intervallerne, og \\(y\\)-værdien er de tilhørende ln(odds).\nSer sammenhængen lineær ud?\nVil det give mening at bruge en logistisk regression?\n\n\n\n\n\\(x\\)\n\\(y=0\\)\n\\(y=1\\)\n\n\n\n\n]100,150]\n27\n6\n\n\n]150,200]\n693\n202\n\n\n]200,250]\n1354\n571\n\n\n]250,300]\n716\n471\n\n\n]300,350]\n156\n132\n\n\n]350,400]\n20\n23\n\n\n]400,450]\n2\n5\n\n\n\n\n\n\n5 Forhøjet blodtryk er defineret som systolisk blodtryk højere end 140mmHg eller diastolisk blodtryk højere end 90mmHg.I næste afsnit ser vi på, hvordan man kan finde et funktionsudtryk for \\(p(x)\\) i den logistiske regressionsmodel."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#logit-funktionen-og-den-logistiske-funktion",
    "href": "materialer/logistisk/log-reg.html#logit-funktionen-og-den-logistiske-funktion",
    "title": "Logistisk regression",
    "section": "Logit-funktionen og den logistiske funktion",
    "text": "Logit-funktionen og den logistiske funktion\nNår vi tager den naturlige logaritme til oddsene, får vi \\[\n\\ln (O(p)) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\] Funktionen på højresiden kaldes \\(\\text{logit}\\) og er altså givet ved \\[\n\\text{logit}(p) = \\ln\\left(\\frac{p}{1-p}\\right).\n\\] Definitionsmængden for \\(\\text{logit}\\)-funktionen er ligesom for oddsene \\(]0,1[\\). Vi fandt tidligere, at værdimængden for oddsene består af alle de positive reelle tal. Dette er netop definitionsmængden for \\(\\ln\\). Værdimængden for \\(\\text{logit}\\) bliver derfor den samme som for \\(\\ln\\), nemlig alle de reelle tal. Grafen for \\(\\text{logit}\\) er vist på figur 8.\n\n\n\n\n\n\n\n\nFigur 8: Grafen for logit-funktionen.\n\n\n\n\n\nDen logistiske regressionsmodel i (1) kan skrives ved hjælp at \\(\\text{logit}\\)-funtionen som \\[\n\\text{logit}(p(x)) = \\ln (O(p(x))) = ax  + b.\n\\tag{2}\\] Egentlig var vi jo ude på at finde et udtryk for sandsynligheden \\(p(x)\\) som funktion af \\(x\\). Vi prøver derfor at isolere \\(p(x)\\) i (2). For at gøre det, finder vi først den omvendte (eller inverse) funktion til \\(\\text{logit}\\). Vi antager derfor, at \\[\ny = \\text{logit(p)} = \\ln\\left( \\frac{p}{1-p} \\right).\n\\] Vi skal så isolere \\(p\\) for at udtrykke \\(p\\) som funktion af \\(y\\). Vi tager først eksponentialfunktionen på begge sider af udtrykket og får \\[\ne^y =  \\frac{p}{1-p}.\n\\] Så ganger vi med \\((1-p)\\) på begge sider. Det giver \\[\ne^y(1-p) =p.\n\\] Hvis parentesen ophæves, får vi \\[\ne^y - p\\cdot e^y =p.\n\\]\nVi kan så lægge \\(p\\cdot e^y\\) til på begge sider og sætte \\(p\\) uden for parantes. Det giver \\[\\begin{align*}\ne^y &= p \\cdot e^y+p  \\\\\ne^y &= p\\cdot (e^y+1).\n\\end{align*}\\] Endelig kan vi isolere \\(p\\) og få \\[\n\\frac{e^y}{e^y+1} =p.\n\\] Her er \\(p\\) egentlig isoleret, men vi kan vælge at forkorte brøken med \\(e^y\\) for at få et andet udtryk for \\(p\\) \\[\np=\\frac{\\frac{e^y}{e^y}}{\\frac{e^y+1}{e^y}}=\\frac{\\frac{e^y}{e^y}}{\\frac{e^y}{e^y}+\\frac{1}{e^y}}    =\\frac{1}{1+e^{-y}} .\n\\]\nSammenlagt har vi vist, at den inverse funktion til logit er den standard logistiske funktion (også nogle gange kaldet sigmoid-funktionen) \\[\nf(y) = \\frac{1}{1+e^{-y}}.\n\\] Grafen for den standard logistiske funktion er indtegnet i figur 9. Vi ser, at grafen har en karakteristisk S-form, som vokser fra \\(0\\) mod \\(1\\).\n\n\n\n\n\n\n\n\nFigur 9: Grafen for den standard logistiske funktion\n\n\n\n\n\nBruger vi den inverse til \\(\\text{logit}\\) på begge sider af lighedstegnet i den logistiske regressionsmodel i (2), får vi isoleret \\(p(x)\\) \\[\np(x) = \\frac{1}{1+e^{-(ax+b)}}.\n\\tag{3}\\] Det ligner altså den standard logistiske funktion, men med \\((ax+b)\\) indsat på \\(y\\)’s plads. Denne funktion kaldes den generelle logistiske funktion."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#fortolkning-af-parametrene-i-den-logistiske-regressionsmodel",
    "href": "materialer/logistisk/log-reg.html#fortolkning-af-parametrene-i-den-logistiske-regressionsmodel",
    "title": "Logistisk regression",
    "section": "Fortolkning af parametrene i den logistiske regressionsmodel",
    "text": "Fortolkning af parametrene i den logistiske regressionsmodel\nHvordan skal vi forstå betydningen af konstanterne \\(a\\) og \\(b\\) i den logistiske regressionsmodel? Hvis man har en funktion \\(f\\), så svarer funktionen \\(f(ax)\\) til, at væksthastigheden er blevet sat op med en faktor \\(a\\). Alternativt kan man forestille sig, at \\(x\\)-aksen er blevet skaleret med en faktor \\(1/a\\). Grafen for \\(f(x-k)\\) svarer til, at man har forskudt grafen med \\(k\\) enheder i \\(x\\)-aksens retning. Hvis man kombinerer disse, kan man indse, at \\(f(ax+b)\\) svarer til først at øge væksthastigheden med en faktor \\(a\\) og derefter forskyde grafen med \\(k=\\frac{-b}{a}\\) i \\(x\\)-aksens retning, idet \\[\nf(ax+b)=f\\Big(a\\cdot \\Big(x-\\Big(\\frac{-b}{a}\\Big)\\Big)\\Big).\n\\]\nHvis man gør dette for den standard logistiske funktion, får man netop den generelle logistiske funktion \\[\nf(ax+b)= \\frac{1}{1+e^{-(ax+b)}}.\n\\] Sammenlignet med den standard logistiske funktion får man altså en \\(S\\)-formet kurve, der vokser \\(a\\) gange så hurtigt og er forskudt med \\(\\frac{-b}{a}\\).\nI app’en herunder ser du grafen for \\(f(x)=\\frac{1}{1+e^{-(ax+b)}}\\). Hvis du trækker i skyderne for \\(a\\) og \\(b\\), kan du se, hvordan kurven ændrer form. Den stiplede linje har ligning \\(x=\\frac{-b}{a}\\) og svarer altså til den vandrette forskydning af grafen for den standard logistiske funktion. På figuren er der desuden 9 punkter, som du kan få grafen til at passe bedst muligt med.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 10: Eksperimenter med a og b for at forstå deres betydning for grafen. Når du har klikket på en skyder med musen, kan værdien også ændres med piletasterne, hvilket kan ske mere præcist.\n\n\n\nI den logistiske regressionsmodel (3) er \\(p(x)\\) givet ved en generel logistisk funktion. Det var en generel logistisk funktion, der blev brugt til at lave den S-formede kurve på figur 4.\nEn anden måde at fortolke konstanterne \\(a\\) og \\(b\\) på er ved at gå tilbage til at se på oddsene. For at få et udtryk for oddsene i den logistiske regressionsmodel, kan vi anvende eksponentialfunktionen på begge sider i (1) og få \\[\nO(x) = e^{ax + b} = e^b \\cdot e^{ax}=e^b \\cdot (e^{a})^x.\n\\] Hvis \\(e^b\\) kaldes \\(b_{ny}\\), og \\(e^{a}\\) kaldes \\(a_{ny}\\), ses at \\[\nO(x)=b_{ny}\\cdot a_{ny}^x\n\\] er en eksponentiel udvikling med fremskrivningsfaktor \\(a_{ny}=e^a\\). Derved vil odds for sygdom stige med \\(r=e^a-1\\) procent, hver gang blodtrykket stiger med \\(1\\)mmHg. Hvis \\(a\\) er positiv, er \\(e^a&gt;1\\), og oddsene vokser altså eksponentielt. Hvis derimod \\(a\\) er negativ, er \\(e^a&lt;1\\), og dermed aftager oddsene eksponentielt.\nHar vi f.eks. en logit model \\[\n\\text{logit}(p(x))= -2 + 0.2x.\n\\] så er den procentvist vækst i odds, når x vokser med 1 \\[\nr = e^a-1 = e^{0.2}-1 \\approx 0.2214028.\n\\] Altså vokser odds med ca. 22%, når x vokser med 1 i modellen.\nI forbindelse med logistisk regression kaldes \\(e^a\\) også for odds-ratioen. For at forstå hvorfor, kan vi forestille os to patienter, en med blodtryk \\(x_1\\) og en med blodtryk \\(x_2\\). De har dermed oddsene \\[\\begin{align*}\nO(x_1) &= e^b \\cdot e^{ax_1}\\\\\nO(x_2) &= e^b \\cdot e^{ax_2}.\n\\end{align*}\\] Lad os se på forholdet (ratioen) mellem de to personers odds: \\[\n\\frac{O(x_1)}{O(x_2)} = \\frac{e^b \\cdot e^{ax_1}}{ e^b \\cdot e^{ax_2}} = \\frac{e^{ax_1}}{e^{ax_2}} = e^{ax_1 - ax_2} = e^{a(x_1 - x_2)} = (e^{a} )^{x_1-x_2}.\n\\] Forholdet mellem oddsene afhænger altså kun af forskellen \\(x_1 - x_2\\) mellem de to personers blodtryk. Hvis person 1 er har et blodtryk, der er 1mmHg højere end person 2, bliver forholdet (ratioen) mellem oddsene lige præcis \\(e^a\\).\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\nI et (fiktivt) dataeksempel ser vi på sandsynligheden \\(p(x)\\) for, at en kunde i et supermarked vælger at købe den økologiske mælk frem for den konventionelle som funktion af kundens årlige indtægt \\(x\\) (i 100.000 kr). Vi kommer frem til følgende logistiske regressionsmodel \\[\n\\text{logit}(p(x))= -1.3+0.5x.\n\\]\n\nHvor mange procent stiger odds for at vælge økologisk, når årsindtægten stiger med 100.000 kr (x vokser med 1)?\nTegn grafen for \\(p(x)\\).\nIndse vha. figur 10, at grafen for den generelle logistiske funktion med forskrift \\[\nf(x)=\\frac{1}{1+e^{-(ax+b)}}\n\\] er stejlest, når funktionsværdien er \\(f(x)=1/2\\).\nHvilken værdi af \\(x\\) svarer til en funktionsværdi på \\(1/2\\) (isoler \\(x\\) udtrykt ved hjælp af \\(a\\) og \\(b\\))?\n\n\n\n\nHvordan man bestemmer \\(a\\) og \\(b\\) ud fra data forklares i det følgende."
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#maksimum-likelihood-estimation",
    "href": "materialer/logistisk/log-reg.html#maksimum-likelihood-estimation",
    "title": "Logistisk regression",
    "section": "Maksimum likelihood estimation",
    "text": "Maksimum likelihood estimation\nI den logistiske regressionsmodel \\[\n\\ln (O(x)) = \\text{logit}(p(x)) = ax  + b.\n\\] indgår to ukendte konstanter \\(a\\) og \\(b\\). Hvis vi har et datasæt, hvordan finder vi så de værdier af \\(a\\) og \\(b\\), der passer bedst til vores data?\nVed at se på figur 7 kunne man fristes til at benytte lineær regression til at finde \\(a\\) og \\(b\\). Bemærk dog, at hvert punkt egentlig er beregnet ud fra fra flere observationer, som ikke har samme \\(x\\)-værdi. Med et lille datasæt ville det slet ikke være muligt at lave en intervalinddeling som i tabel 1, uden at der kommer meget få personer i nogle grupper. Begge dele gør, at de beregnede værdier af \\(\\ln(O(x))\\) bliver meget upræcise, og det samme gør estimaterne for \\(a\\) og \\(b\\) derfor.\nI stedet benytter man som regel maksimum likelihood metoden, som er en teknik, der stammer fra statistikken. Kort fortalt er idéen at vælge de værdier af \\(a\\) og \\(b\\), der gør vores data så sandsynligt som muligt.\nLad os kalde punkterne i vores datasæt \\((x_i,y_i)\\), hvor \\(i=1,\\ldots,n\\) er en nummerering af datapunkterne. Her angiver \\(x_i\\) altså blodtrykket hos den \\(i\\)’te person, og \\(y_i\\) er en variabel, der antager værdien \\(1\\) hvis \\(i\\)’te person har hjerte-kar-sygdom og er \\(0\\) ellers. For hvert par \\((x_i,y_i)\\) kan vi nu forsøge at beregne sandsynligheden \\(p_i\\) for at \\(i\\)’te person faktisk har den sygsomsstatus \\(y_i\\), som vi observerer. Hvis den \\(i\\)’te person er syg, dvs. \\(y_i=1\\), er \\(p_i\\) altså sandsynligheden for at være syg, når blodtrykket er \\(x_i\\), så \\[\np_i= p(x_i)  = \\frac{ 1}{1 + e^{-(ax_i  + b)}}.\n\\tag{4}\\] Hvis patienten er rask, altså \\(y_i=0\\), er \\(p_i\\) sandsynligheden for at være rask, når blodtrykket er \\(x_i\\), det vil sige \\[\np_i=1-  p(x_i)  = 1- \\frac{ 1}{1 + e^{-(ax_i  + b)}}.\n\\tag{5}\\] Vi kan opskrive et samlet udtryk for \\(p_i\\) uden at opdele efter værdien af \\(y_i\\), nemlig \\[\np_i= p_i(x_i)^{y_i}(1-p(x_i))^{1-y_i}.\n\\tag{6}\\] For at indse dette, ser vi først på tilfældet \\(y_i=1\\), hvor (6) giver \\[\np_i = p(x_i)^{1} (1-p(x_i))^{0} = p(x_i),\n\\] da \\(a^0=1\\) for alle værdier af \\(a\\).\nFor \\(y_i=0\\) giver (6)\n\\[\np_i = p(x_i)^{0} (1-p(x_i))^{1} = 1-p(x_i).\n\\] Det passer altså med formlerne i henholdsvis (4) og (5). Bemærk at \\(p_i\\) afhænger af de ukendte værdier \\(a\\) og \\(b\\). Vi kan altså opfatte \\(p_i\\) som en funktion af to variable \\(p_i(a,b)\\).\nNu kigger vi på den samlede sandsynlighed for at observere netop de værdier \\(y_1,\\ldots,y_n\\), som vi faktisk har observeret, når vi ved at patienternes blodtryk er givet ved \\(x_1,\\ldots,x_n\\). Til det formål antager vi, at personerne i datasættet er uafhængige af hinanden6.\n6 Afhængigheder kan for eksempel opstå, hvis mange af personerne er i familie med hinanden, går i klasse sammen eller bor i samme by. I så fald kan de have noget til fælles, der gør at deres \\(y\\)-værdier er mere ens end ellers. Familiemedlemmer kan fx have samme arvelige tendens til hjerte-kar-sygdom. Som regel forsøger man at undgå sådanne afhængigheder, når man indsamler data.For at komme videre, er vi nødt til at vide lidt om uafhængighed af hændelser: Husk på at to hændelser \\(A\\) og \\(B\\) er uafhængige, hvis man kan finde sandsynligheden for fælleshændelsen \\(A\\cap B\\) (at \\(A\\) og \\(B\\) indtræffer på en gang) ved at gange de enkelte sandsynligheder sammen: \\[\n    P(A\\cap B) = P(A)\\cdot P(B).\n\\]\nUafhængighed af \\(n\\) hændelser \\(A_1,\\ldots,A_n\\) betyder tilsvarende, at sandsynligheden for, at alle \\(n\\) hændelser indtræffer på samme tid \\(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n\\), kan findes som et produkt af sandsynlighederne for de enkelte hændelser7 \\[\n    P(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n) = P(A_1)\\cdot P(A_2) \\cdot \\dotsm \\cdot P(A_n).\n\\]\n7 Desuden skal der gælde, at hver gang vi udtager \\(m\\) ud af de \\(n\\) hændelser, skal sandsynligheden for, at de \\(m\\) hændelser indtræffer samtidig, kunne findes ved en tilsvarende produktformel, men dette skal vi ikke bruge i det følgende.Vi vender nu tilbage til vores data og lader \\(A_1\\) være hændelsen at første patient har sygdomsstatus \\(y_1\\), \\(A_2\\) være hændelsen at anden patient har sygdomsstatus \\(y_2\\) og så videre. Bemærk, at \\(P(A_i)\\) er det samme, som det vi tidligere kaldte \\(p_i(a,b)\\). Hændelsen at vi observerer \\(y_1,\\ldots,y_n\\) på samme tid, er fælleshændelsen \\(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n\\). Da vi antog, at de \\(n\\) personer er udvalgt uafhængigt af hinanden, kan vi bruge produktformlen: \\[\nP(A_1 \\cap A_2 \\cap \\dotsm \\cap A_n) = P(A_1) \\cdot \\dotsm \\cdot P(A_n) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Bemærk, at sandsynligheden for vores udfald \\(y_1,\\ldots,y_n\\) afhænger af \\(a\\) og \\(b\\). Den kan derfor betragtes som en funktion af to variable \\[\nL(a,b) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\] Denne funktion kaldes likelihoodfunktionen. Idéen med maksimum likelihood metoden er at vælge de værdier af \\(a\\) og \\(b\\), der gør sandsynligheden \\(L(a,b)\\) for det, vi har observeret så stor som mulig. Vi søger altså de \\(a\\) og \\(b\\), der maksimerer funktionen \\(L(a,b)\\). I praksis vælger man som regel at maksimere \\(\\log(L(a,b))\\), som kaldes for log-likelihoodfunktionen. Det kommer vi mere ind på i det følgende afsnit. På figur 11 er det vist, hvordan grafen for en log-likelihoodfunktion kunne se ud. Den viser altså logaritmen af sandsynligheden for vores observationer som funktion af \\(a\\) og \\(b\\). Det sorte punkt angiver, hvor funktionsværdien er størst. De tilhørende \\(a\\)- og \\(b\\)-koordinater er altså dem, der gør vores observationer mest sandsynlige.\n\n\n\n\n\n\n\n\nFigur 11: Graf for en log-likelihoodfunktion. Det sorte punkt angiver, hvor funktionsværdien er størst.\n\n\n\n\nMaksimum for \\(L(a,b)\\) kan ikke beregnes eksakt. I stedet kan man bruge numeriske metoder, for eksempel gradient nedstigning, som du kan læse mere om her. Man kan også forsøge at finde kritiske punkter, altså punkter, hvor de partielt afledte er nul, ved hjælp af numeriske metoder. Det kan du læse mere om her. I praksis kan optimeringen foretages ved hjælp af Excel som forklaret nedenfor.\nFinder man \\(a\\) og \\(b\\) ved hjælp af maksimum likelihood metoden i vores dataeksempel, fås følgende funktionsudtryk for sandsynlighederne og oddsene \\[\n    p(x) = \\frac{1}{1+e^{-0.022 x +3.9}}, \\qquad O(x)=e^{0.022 x - 3.9}.\n\\]\nGrafen for \\(p\\) er vist på figur 4. Vi får en odds-ratio på \\(e^{0.022} \\approx 1.022\\). Odds for hjerte-kar-sygdom stiger derfor med en faktor 1.022 (altså 2.2%), for hver gang blodtrykket stiger med \\(1\\) mmHg.\n\nYderligere omskrivning af likelihoodfunktionen\nVi ser nu lidt nærmere på, hvordan man selv kan finde \\(a\\) og \\(b\\), der maksimerer værdien af likelihoodfunktionen \\(L(a,b)\\). Til det formål omskriver vi først likelihoodfunktionen til noget, der er lidt nemmere at regne på. Vi havde \\[\nL(a,b) = p_1(a,b) \\cdot p_2(a,b)\\cdot \\dotsm \\cdot p_n(a,b).\n\\tag{7}\\] Da \\(\\ln(x)\\) er en voksende funktion, vil \\(L(a,b)\\) have maksimum for de samme værdier af \\(a\\) og \\(b\\) som den sammensatte funktion \\(l(a,b)=\\ln(L(a,b))\\). Det er altså nok at finde de værdier af \\(a\\) og \\(b\\), der maksimerer \\(l(a,b)\\).\nTager vi logaritmen i (7) og bruger logaritmeregnereglen \\(\\ln(a\\cdot b) = \\ln(a) + \\ln(b)\\), får vi \\[\nl(a,b)=\\sum_{i=1}^n \\ln(p_i(a,b)).\n\\tag{8}\\] Vi ser her, at logaritmen laver produktet i likelihoodfunktionen om til en sum – og summer er nemmere at regne på end produkter (for eksempel når vi senere skal differentiere).\nVi fandt i (6), at \\[\np_i(a,b)=p(x_i)^{y_i}\\cdot (1-p(x_i))^{1-y_i}.\n\\] Vi kan nu finde \\(\\ln(p_i(a,b))\\) ved først at benytte regnereglen \\(\\ln(a\\cdot b) = \\ln(a) + \\ln(b)\\) og dernæst regnereglen \\(\\ln(a^k)=k\\cdot \\ln(a)\\). Det giver \\[\\begin{align*}\n\\ln(p_i(a,b)) &=  \\ln\\big(p(x_i)^{y_i}\\big) + \\ln\\big((1-p(x_i))^{1-y_i}\\big) \\\\\n&= {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i))\n\\end{align*}\\] Samlet set får vi \\[\n\\begin{aligned}\nl(a,b) &=\\sum_{i=1}^n \\ln(p_i(a,b)) \\\\  &= \\sum_{i=1}^n\\big( {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)) \\big).\n\\end{aligned}\n\\tag{9}\\] Dette udtryk kan man nemt selv udregne og maksimere ved hjælp af Excel.\n\n\nBestemmelse af \\(a\\) og \\(b\\) med Excels problemløser-værktøj\nFor at finde estimater for \\(a\\) og \\(b\\) ved hjælp af Excel, skal man først og fremmest sørge for, at man har aktiveret problemløser-værktøjet. Det gøres på følgende måde: Gå op under filer og vælg indstillinger. Derefter vælges tilføjelsesprogrammer. Nederst kan man vælge Excel-tilføjelsesprogrammer og trykke udfør. Til sidst kan man vælge tilføjelsesprogrammet problemløser fra en liste.\n\n\n\nIllustration af Excel ark til bestemmelse af a og b samt brug af problemløser.\n\n\nPå billedet ses, hvordan man kan lave et lille regneark til at beregne de relevante størrelser. Der er lavet et par celler til de ukendte parametre \\(a\\) og \\(b\\), som med fordel kan sættes til 0 fra starten for at undgå numeriske problemer i Excel. Det oprindelige datasæt indsættes i søjlerne \\(x_i\\) og \\(y_i\\). I de næste søjler beregnes odds, \\(p(x_i)\\) og \\(\\ln(p_i)\\) med formlerne8 \\[\\begin{align*}\nodds &= e^{ax_i + b}\\\\\np(x_i) &= \\frac{e^{ax_i + b}}{1+e^{ax_i +b}} = \\frac{odds}{1+odds}\\\\\n\\ln(p_i)&= {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)).\n\\end{align*}\\]\n8 I Excel på dansk fås eksponentialfunktionen ved at skrive EKSP (og EXP i den engelske version) og for at få den naturlige logaritmen skriver man LN i begge tilfælde.Her er det vigtigt, at cellerne, der indeholder værdien af \\(a\\) og \\(b\\), benyttes når oddsene beregnes (det vil være smart med fastlåsning af referencerne, hvor man har $ foran både tal og bogstav ved reference). Til sidst finder man \\(l(a,b)\\) i det blå felt ved at beregne summen af alle \\(\\ln(p_i)\\), som i formlen (9).\nNu mangler man bare at benytte problemløseren til at finde de værdier af \\(a\\) og \\(b\\), der gør værdien i det blå felt maksimal. På billedet er der vist med rød, hvor man finder problemløseren, og hvad der skal justeres. Målsætningen er den blå celle, der indeholder summen. Variabelcellerne er de to, der indeholder \\(a\\) og \\(b\\). Sørg for ikke at sætte flueben i boksen “Gør variabler uden begrænsninger ikke-negative”. Tryk på løs.\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\nAntag, at vi har tre observationer nedenfor.\n\nOpskriv et udtryk for likelihoodfunktionen \\(L(a,b)\\).\n\n\n\n\n\\(x\\)\n1\n2\n3\n\n\n\n\n\\(y\\)\n1\n1\n0\n\n\n\nEn nyhedshjemmeside ønsker at målrette en biografreklame til brugerne. De har derfor registreret om 10 af hjemmesidens brugere har klikket på reklamen (\\(y=1\\) hvis de har klikket, \\(y=0\\) ellers) og hvor mange gange \\(x\\), de har læst kulturnyheder den sidste måned. Datasættet er givet i nedenstående tabel. Firmaet bag hjemmesiden ønsker at modellere sandsynligheden \\(p(x)\\) for at klikke på reklamen som funktion af \\(x\\), så de kan målrette reklamen mod de brugere, der har størst sandsynlighed for at klikke på den.\n\nBrug Excel til at finde \\(a\\) og \\(b\\).\nTegn grafen for \\(p(x)\\).\nSkal firmaet vælge at vise reklamen til brugere, der ofte eller sjældent læser kulturnyheder?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nx\n0\n1\n2\n3\n4\n5\n6\n7\n8\n9\n\n\n\n\ny\n0\n0\n1\n0\n0\n1\n1\n1\n1\n1"
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#multipel-logistisk-regression",
    "href": "materialer/logistisk/log-reg.html#multipel-logistisk-regression",
    "title": "Logistisk regression",
    "section": "Multipel logistisk regression",
    "text": "Multipel logistisk regression\nI praksis er der selvfølgelig flere faktorer end blodtryk, der afgør ens risiko for hjerte-kar-sygdom. For eksempel stiger risikoen med alderen, ligesom rygning øger risikoen. Vi kan opstille en model, der inddrager alle tre variable på en gang. Lader vi \\(x_1\\) betegne blodtryk, \\(x_2\\) betegne alder, og \\(x_3\\) betegne antal cigaretter, man ryger pr. dag, kan vi lave en model, hvor logaritmen til oddsene afhænger af alle tre variable: \\[\n    \\ln \\left ( O(x_1,x_2,x_3)  \\right) = a_1x_1 + a_2x_2 +a_3x_3 + b.\n\\] Nu er der fire ukendte konstanter \\(a_1\\), \\(a_2\\), \\(a_3\\) og \\(b\\) i modellen, som skal bestemmes ud fra data. Dette kaldes den multiple regressionsmodel. Ved at tage eksponentialfunktionen får vi en formel for oddsene \\[\n     O(x_1,x_2,x_3) = e^{a_1x_1 + a_2x_2 +a_3x_3 + b}.\n\\] Man kan også bruge den standard logistiske funktion og få en formel for sandsynligheden \\[\n    p(x_1,x_2,x_3) = \\frac{1}{1+e^{-(a_1x_1 + a_2x_2 +a_3x_3 + b)}}.\n\\]\nHvordan skal vi forstå denne model? Jo, lad os forestille os en patient med alder \\(x_1\\) og blodtryk \\(x_2\\), som ryger \\(x_3\\) cigaretter om dagen. Hvis vedkommende begynder at ryge \\(1\\) cigaret mere om dagen (og vi forestiller os at alder og blodtryk er uændret) så vil odds-ratioen være \\[\n\\begin{aligned}\n    \\frac{O(x_1,x_2,x_3+1)}{O(x_1,x_2,x_3)} &= \\frac{ e^{a_1x_1 + a_2x_2 +a_3(x_3+1) + b}}{e^{a_1x_1 + a_2x_2 +a_3x_3 + b}} \\\\\n    &=\\frac{e^{a_1x_1} \\cdot e^{a_2x_2} \\cdot e^{a_3x_3} \\cdot e^{a_3} \\cdot e^b}{e^{a_1x_1} \\cdot e^{a_2x_2} \\cdot e^{a_3x_3}\\cdot e^b} \\\\ &=e^{a_3}.\n\\end{aligned}\n\\] Den ekstra daglige cigaret vil altså øge odds for sygdom med en faktor \\(e^{a_3}\\). Tilsvarende har \\(e^{a_1}\\) og \\(e^{a_2}\\) fortolkninger som odds-ratioer, når henholdsvis blodtryk og alder stiger med 1, mens alle andre variable fastholdes. Selv om modellen tager alle tre variable i betragtning, giver odds-ratioerne et mål for den individuelle effekt af hver af de tre variable.\nMaximum likelihood metoden kan igen benyttes til at estimere parametrene \\(a_1,a_2,a_3\\) og \\(b\\). Likelihoodfunktionen, som skal maksimeres, bliver nu til en funktion af fire variable. Vi vil ikke gå i detaljer med, hvordan denne maksimering finder sted.\nFramingham datasættet er et rigtigt datasæt, der indeholder data for hjerte-kar-sygdom og de tre risikofaktorer \\(x_1\\), \\(x_2\\) og \\(x_3\\). Estimerer man \\(a_1,a_2,a_3\\) og \\(b\\) på en udvalgt del af dette datasæt, får man \\[\n    O(x_1,x_2,x_3) = e^{0.06x_1 + 0.02x_2 + 0.02x_3 -6.77 }.\n\\] Odds for hjerte-kar-sygdom stiger således med en faktor \\(e^{0.02}\\approx 1.02\\) (altså med 2%), for hver cigaret man ryger om dagen. Tilsvarende stiger odds for sygdom med en faktor \\(e^{0.06}\\approx 1.06\\), for hvert år ældre man bliver, og med en faktor \\(e^{0.02}\\approx 1.02\\), for hver gang blodtrykket stiger med 1 mmHg.\n\n\n\n\n\n\nOpgave 5\n\n\n\n\n\nI en multipel regression har man fundet følgende model for odds \\(O(x_1,x_2)\\) for, at en bruger af en hjemmeside klikker på en given reklame, hvor \\(x_1\\) og \\(x_2\\) er antal gange kunden har læst henholdsvis kulturnyheder og sportsnyheder inden for den sidste måned \\[\nO(x_1,x_2) = e^{-2+0.5x_1-0.1x_2 }.\n\\]\n\nEn bruger har læst kulturnyheder 4 gange og sportsnyheder 7 gange inden for den sidste måned. Hvad er odds for, at brugeren klikker på reklamen?\nHvad er odds ratioen for kulturnyheder?\nEr sandsynligheden for at klikke på reklamen højere eller lavere blandt brugere, der læser mange kulturnyheder?"
  },
  {
    "objectID": "materialer/logistisk/log-reg.html#prædiktion",
    "href": "materialer/logistisk/log-reg.html#prædiktion",
    "title": "Logistisk regression",
    "section": "Prædiktion",
    "text": "Prædiktion\nNår vi har fundet en god model for sammenhængen mellem sygdom og forskellige risikofaktorer, kan vi bruge den til at forudsige (prædiktere), om en ny patient er syg. Som eksempel kan vi se på den multiple regressionsmodel, hvor risikoen for hjerte-kar-sygdom var givet ved \\[\n    p(x_1,x_2,x_3) = \\frac{1}{1+e^{-(0.06x_1 + 0.02x_2 +0.02x_3 -6.77)}},\n\\] hvor \\(x_1\\) var alderen, \\(x_2\\) var blodtrykket, og \\(x_3\\) var antal cigaretter.\nForestil dig nu, at vi får en ny patient med alderen \\(x_1\\) og blodtrykket \\(x_2\\), som ryger \\(x_3\\) cigaretter om dagen. Vi kan beregne sandsynligheden \\(p(x_1,x_2,x_3)\\) for, at patienten er syg ud fra vores model. Den mest oplagte prædiktionsregel er at prædiktere det mest sandsynlige:\n\nHvis \\(p(x_1,x_2,x_3)&gt;1/2\\): Patienten er syg.\nHvis \\(p(x_1,x_2,x_3)\\leq 1/2\\): Patienten er rask.\n\nLad os for eksempel sige, at vores patient er 30 år gammel, har et blodtryk på \\(145\\) mmHg og ryger 7 cigaretter om dagen. Ifølge vores model vil hans risiko for hjerte-kar-sygdom være \\[\n    p(30,145,7) = \\frac{1}{1+e^{-(0.06\\cdot 30 + 0.02\\cdot 145 +0.02\\cdot 7 -6.77)}}\\approx 0.127.\n\\] Hans risiko er på 12.7%. Hvis vi skal lave en prædiktion, vil vi sige, at han er rask, da dette vil være det mest sandsynlige.\nI praksis kan der være et problem med altid at vælge det mest sandsynlige. Hvis man gerne vil kunne forudsige en meget sjælden sygdom, vil det ofte være sådan, at \\(p(x)\\leq 1/2\\) for alle patienter. Ingen ville blive diagnosticeret med sygdommen på denne måde - og så er prædiktionsalgoritmen jo ikke meget værd. Derfor vælger man ofte et lavere delepunkt end \\(p(x)=1/2\\). Dermed kommer man til at fejldiagnosticere en hel del patienter. Til gengæld får man fanget flere af dem, der faktisk er syge.\nHer på siden har vi flere eksempler på algoritmer, som vil kunne bruges til at prædiktere om patienter er syge eller raske, fx neurale netværk9 og Bayes klassifikation. Fordelen ved at bruge logistisk regression er, at man ikke bare får en prædiktion, men også en model for, hvordan sandsynligheden \\(p(x)\\) afhænger af variablen \\(x\\). Dermed opnår man en indsigt i, hvordan sammenhængen mellem for eksempel blodtryk og hjerte-kar-sygdom er. Ved hjælp af odds-ratioer kan vi endda sætte tal på, hvordan odds for sygdom ændrer sig, når blodtrykket vokser. Dette er i modsætning til mange andre prædiktionsalgoritmer, der blot giver en prædiktion, uden at brugeren af algoritmen ved, hvor den kommer fra. Inden for medicin er det ofte vigtigt at kende baggrunden for en given prædiktion, så man kan forholde sig kritisk til resultatet og rådgive patienten om, hvordan man sænker risikoen for sygdom (for eksempel med blodtrykssænkende medicin). Til gengæld har de mere avancerede algoritmer, så som neurale netværk, mulighed for at give en mere præcis prædiktion.\n9 Logistisk regression er i øvrigt et meget simpelt eksempel på et neuralt netværk, hvis man vælger af bruge cross-entropy funktionen som tabsfunktion.\nAndre eksempler på anvendelser\nLogistisk regression kan bruges til at modellere meget andet end sygdom. Forestil dig for eksempel en nyhedshjemmeside, der benytter cookies til at målrette reklamer. Hjemmesiden registrerer, hvor mange gange du har læst kulturnyheder, \\(x_1\\), og hvor mange gange du har læst sportsnyheder, \\(x_2\\), inden for den sidste måned. Desuden registrerer den, om du har klikket på en bestemt reklame for en ny biograffilm. Man kan bruge disse data til at finde en logistisk regressionsmodel for sandsynligheden \\(p(x_1,x_2)\\) for, at en ny bruger klikker på reklamen. Med sådan en model kan man så prædiktere, om en ny bruger vil klikke på reklamen ud fra indsamlet data om brugerens forbrug af sports- og kulturnyheder. Reklamen vil så kun blive vist til brugeren, hvis det prædikteres, at brugeren rent faktisk vil klikke på reklamen.\nEt andet eksempel kunne være en meningsmåling. Et mindre antal vælgere spørges, om de har tænkt sig at stemme på rød eller blå blok. Desuden noteres deres alder \\(x_1\\) og årsindtægt \\(x_2\\). Ud fra dette datasæt laves en model for sandsynligheden \\(p(x_1,x_2)\\) for at stemme på rød blok som funktion af alder og årsindtægt. Ud fra modellen kan man så prædiktere, hvad resten af befolkningen har tænkt sig at stemme.\n\n\n\n\n\n\nOpgave 6\n\n\n\n\n\nVi kigger igen på en multipel regressionsmodel for odds \\(O(x_1,x_2)\\) for, at en bruger af en hjemmeside klikker på en given reklame, hvor \\(x_1\\) og \\(x_2\\) er antal gange kunden har læst henholdsvis kulturnyheder og sportsnyheder inden for den sidste måned. Modellen for odds er fundet til \\[\nO(x_1,x_2) = e^{-2+0.5x_1-0.1x_2 }.\n\\] Vi vil gerne prædiktere, om en bruger klikker på reklamen, så vi kan beslutte, om det er relevant at vise ham den.\n\nEn bruger har læst kulturnyheder 5 gange og sportsnyheder 8 gange inden for den sidste måned. Vil du prædiktere, at brugeren klikker på reklamen?\n\n\n\n\nHvis du vil læse mere om sammenhæng mellem logistisk regression og logistisk vækst, kan du folde boksen nedenfor ud.\n\n\n\n\n\n\nSammenhæng mellem logistisk regression og logistisk vækst\n\n\n\n\n\nHvis du har hørt om logistisk vækst og logistisk regression, spekulerer du måske over, om der er en sammenhæng mellem de to begreber. Vi skal nu se, at der i nogle anvendelser faktisk er en sammenhæng.\nLad os se på et eksempel med en smitsom sygdom, hvor infektionen aldrig forlader kroppen igen, og man kan fortsætte med at smitte andre resten af livet, når først man er blevet smittet. HIV og herpes er eksempler på sådanne sygdomme. Lad \\(I(x)\\) betegne antallet af smittede efter \\(x\\) dage (\\(I\\) står for inficeret). Ifølge den klassiske SI-model, er væksthastigheden for \\(I\\) proportional med både antallet af smittede \\(I(x)\\) og antallet af raske \\(M-I(x)\\), hvor \\(M\\) er det samlede befolkningstal. Det vil sige \\[\nI'(x) = k I(x)(M-I(x)),\n\\] hvor \\(k&gt;0\\) er en konstant. Denne ligning kaldes den logistiske differentialligning, og løsningen er givet ved \\[\nI(x)=\\frac{M}{1+c\\cdot e^{-M\\cdot k\\cdot x}},\n\\] hvor \\(c&gt;0\\) igen er en konstant, som kan bestemmes, hvis man kender antallet af smittede \\(I(0)\\) til tiden \\(x=0\\). Sætter vi \\(c=\\exp(-b)\\) og \\(a=Mk\\), får vi \\[\nI(x)=\\frac{M}{1+e^{-b}\\cdot e^{-a\\cdot x}} = \\frac{M}{1+e^{-(a\\cdot x+b)}}.\n\\] På dag \\(x\\) vil en tilfældigt udvalgt person have en sandsynlighed på \\(p(x)=I(x)/M\\) for at være smittet. Denne sandsynlighed vil være beskrevet af en logistisk funktion \\[\np(x)=\\frac{I(x)}{M} = \\frac{1}{1+e^{-(a\\cdot x+b)}}.\n\\] Dette genkender vi som en logistisk regressionsmodel for sandsynligheden \\(p(x)\\).\nFor at bestemme \\(a\\) og \\(b\\), kunne man derfor lave et datasæt, hvor vi hver dag tager en test af en tilfældig person og ser, om personen er smittet eller rask. Derved får vi et datasæt med punkter \\((x,y)\\), hvor \\(x\\) er antal dage, og \\(y\\) er \\(0\\) hvis personen er rask, eller \\(1\\) hvis personen er smittet. Vi kan nu finde \\(a\\) og \\(b\\) ved at lave logistisk regression på dette datasæt og finde et udtryk for \\(p(x)\\). Hvis vi gerne vil vide, hvor mange der faktisk er syge efter \\(x\\) dage, ganger vi bare sandsynligheden for at være syg op med befolkningstallet \\[\nI(x)=M\\cdot p(x)=\\frac{M}{1+e^{-(a\\cdot x+b)}}.\n\\] Det er dog ikke ved alle eksempler, det er muligt at lave denne kobling mellem de to emner. Logistisk vækst vedrører en udvikling i tid, dvs. \\(x\\)-variablen skal angive tid. Desuden skal udviklingen foregå i en population af fast størrelse \\(M\\)."
  },
  {
    "objectID": "materialer/logistisk/max_likelihood.html",
    "href": "materialer/logistisk/max_likelihood.html",
    "title": "Maksimering af log-likelihoodfunktionen ved brug af partielt afledte",
    "section": "",
    "text": "Når \\(l(a,b)\\) skal maksimeres, kan det gøres ved hjælp af partielt afledede. Husk på, at i et maksimumspunkt, vil begge de partielt afledte være lig 0, dvs. \\[\\begin{align*}\n\\frac{\\partial l(a,b)}{\\partial a} &=0 \\\\\n\\frac{\\partial l(a,b)}{\\partial b} &=0.\n\\end{align*}\\] Vi finder derfor først et mere eksplicit udtryk for \\(l(a,b)\\) som funktion af \\(a\\) og \\(b\\).\n\nEksplicit udtryk for \\(l(a,b)\\)\nVi ved, at log-likelihoodfunktionen er givet ved \\[\n\\begin{aligned}\nl(a,b) &=\\sum_{i=1}^n \\ln(p_i(a,b)) \\\\  \n&= \\sum_{i=1}^n\\big( {y_i}\\cdot \\ln(p(x_i))+(1-y_i)\\cdot \\ln(1-p(x_i)) \\big).\n\\end{aligned}\n\\tag{1}\\]\nVed at ophæve parentesen \\((1-y_i)\\) i (1) fås \\[ l(a,b)=\\sum_{i=1}^n \\big({y_i}\\cdot \\ln(p(x_i))+\\ln(1-p(x_i))- y_i\\cdot \\ln(1-p(x_i))\\big).\\] I to af leddene inden for sumtegnet har vi \\(y_i\\) som en faktor. Vi kan derfor sætte \\(y_i\\) uden for parentes \\[ l(a,b)=\\sum_{i=1}^n \\big(\\ln(1-p(x_i))+{y_i}\\cdot (\\ln(p(x_i))-\\ln(1-p(x_i)))\\big).\\] Ved hjælp af logaritmeregnereglen \\(ln(a/b)=ln(a)-ln(b)\\) får vi \\[ l(a,b)=\\sum_{i=1}^n \\left(\\ln(1-p(x_i))+y_i\\cdot \\ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right)\\right).\\] Her opsplitter vi til to summer, hvor den ene ikke afhænger af \\(y_i\\). \\[ l(a,b)=\\sum_{i=1}^n \\ln(1-p(x_i))+\\sum_{i=1}^n y_i\\cdot \\ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right). \\tag{2}\\] Nu har vi fået styr på udtrykket for \\(l(a,b)\\), som dog afhænger af \\(p(x_i)\\). Vi udnytter nu, at vi havde udtrykket \\[p(x_i) = \\frac{1}{1+e^{-(a\\cdot x_i+b)}}\\] og \\[\\ln\\left(\\frac{p(x_i)}{1-p(x_i)}\\right)=ax_i + b.\\] Indsættes dette i (2), får vi \\[l(a,b)=\\sum_{i=1}^n \\ln\\left(1-\\frac{1}{1+e^{-(a\\cdot x_i+b)}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Udtrykket i logaritmen sættes på fælles brøkstreg, og brøken forlænges med \\(e^{a\\cdot x_i+b}\\)\n\\[\n\\begin{aligned}\nl(a,b)&=\\sum_{i=1}^n \\ln\\left(\\frac{e^{-(a\\cdot x_i+b)}}{1+e^{-(a\\cdot x_i+b)}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b) \\\\ &=\\sum_{i=1}^n \\ln\\left(\\frac{1}{1+e^{a\\cdot x_i+b}}\\right)+\\sum_{i=1}^n y_i\\cdot (ax_i+b)\n\\end{aligned}\n\\] Her benytter vi igen regnereglen \\(\\ln(a/b)=\\ln(a)-\\ln(b)\\). \\[ l(a,b)=\\sum_{i=1}^n\\big(\\ln(1)-\\ln(1+e^{a\\cdot x_i+b})\\big)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\\] Da \\(\\ln(1)=0\\), har vi endelig \\[\nl(a,b)=\\sum_{i=1}^n \\big(-\\ln(1+e^{a\\cdot x_i+b})\\big)+\\sum_{i=1}^n y_i\\cdot (ax_i+b).\n\\tag{3}\\]\n\n\nPartielt afledede\nVi finder nu de partielt afledte af \\(l(a,b)\\) ved at differentiere (3). Lad os først se på \\(\\frac{\\partial l(a,b)}{\\partial b}\\). I den første sum i (3) skal vi se hvert led som en sammensat funktion, hvor den indre funktion har et led, som også er en sammensat funktion. Så får vi \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(0+1) +\\sum_{i=1}^n y_i\\cdot (0+1).\\] Ved at reducere fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}} +\\sum_{i=1}^n y_i\\] Ved at bruge at \\[\np(x) = \\frac{1}{1+e^{-(ax+b)}}= \\frac{e^{(ax+b)}}{1+e^{(ax+b)}}\n\\tag{4}\\] i forbindelse med den første sum og efterfølgende samle leddene i en sum, fås \\[\\frac{\\partial l(a,b)}{\\partial b}= \\sum_{i=1}^n -p(x_i) +\\sum_{i=1}^n y_i=\\sum_{i=1}^n (y_i-p(x_i)).\\]\nNu ser vi på \\(\\frac{\\partial l(a,b)}{\\partial a}\\) på tilsvarende måde. \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -\\frac{1}{1+e^{a\\cdot x_i+b}}\\cdot (0+e^{a\\cdot x_i+b})\\cdot(1\\cdot x_i+0) +\\sum_{i=1}^n y_i\\cdot (1\\cdot x_i+0)\\] Der reduceres \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -\\frac{e^{a\\cdot x_i+b}}{1+e^{a\\cdot x_i+b}}\\cdot x_i +\\sum_{i=1}^n y_i\\cdot x_i.\\] Igen bruges (4) til at få \\[\\frac{\\partial l(a,b)}{\\partial a}= \\sum_{i=1}^n -p(x_i)\\cdot x_i +\\sum_{i=1}^n y_i\\cdot x_i=\\sum_{i=1}^n (y_i\\cdot x_i-p(x_i)\\cdot x_i).\\]\nEndelig kan \\(x_i\\) sættes udenfor parentes, hvorved vi har \\[\\frac{\\partial l(a,b)}{\\partial a}=\\sum_{i=1}^n (y_i-p(x_i))\\cdot x_i.\\]\nFor at lave optimering og finde maksimum, skal vi undersøger, hvornår de partielt afledte er nul. Vi skal således løse følgende to ligninger med to ubekendte \\[\\begin{align*}\n0=\\frac{\\partial l(a,b)}{\\partial a}=\\sum_{i=0}^n (y_i-p(x_i))\\cdot x_i \\quad \\text{og} \\quad 0=\\frac{\\partial l(a,b)}{\\partial b}=\\sum_{i=1}^n (y_i-p(x_i)) .\n\\end{align*}\\] Dette ligningssystem er dog ikke bare lige til at løse, så her bliver man nødt til at benytte sig af numeriske metoder til løsning af ligningssytemer."
  },
  {
    "objectID": "materialer/afstande/afstand.html",
    "href": "materialer/afstande/afstand.html",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "",
    "text": "Når vi adskiller eller samler data bygger vi på en form for afstand. De \\(k\\) nærmeste naboer er dem, der ligger tættest på i én eller anden forstand. Hvis det drejer sig om dem, hvis højder er tætte på hinanden eller måske dem, der vejer nogenlunde det samme, er det klart, hvad man mener. Der er tal, man umiddelbart kan sammenligne. Men hvad med at sammenligne både vægt og højde? Hvad betyder så mest? Er der lige langt mellem en person A, der vejer 80 kg og er 1,80 m høj og en anden, B, der vejer 90 kg og er 2,00 m eller mellem A og C, der vejer 70 kg og er 1,60 m? Det er ikke klart, selvom vi da kan plotte de tre punkter i et (vægt, højde) koordinatsystem og endda bruge Pythagoras og få den samme afstand.1 Udregner man BMI, er \\(A\\) tættere på \\(B\\) end på \\(C\\). Det kommer nok også an på, hvad vi gerne vil udtale os om: Er de nogenlunde lige gode til at løbe langt? Eller hurtigt? Mere kompliceret bliver det, hvis vi også vil inddrage øjenfarve, skostørrelse eller måske, om de køber rigtig meget mælk. Der er mange eksempler på afstande, som ikke umiddelbart er fysisk afstand. For eksempel mellem ord (LINK) eller mellem DNA (Link)"
  },
  {
    "objectID": "materialer/afstande/afstand.html#hierarkisk-clustering",
    "href": "materialer/afstande/afstand.html#hierarkisk-clustering",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "Hierarkisk clustering",
    "text": "Hierarkisk clustering\nHer kender vi alle parvise afstande. Og ikke andet.\nUdfra den information laver vi et dendogram, hvor i første omgang par af datapunkter \"mødes\" i den højde, der svarer til deres afstand. Men der er mere: Hvornår skal datapunktet \\(p\\) mødes med \\(qr\\), som mødtes tidligere? Hvornår skal \\(pqr\\) mødes med \\(ab\\)? Det er linkage-reglerne.\n\nSingle linkage: \\(pqr\\) mødes med \\(ab\\) i den højde, hvor minimumsafstanden mellem de to grupper af punkter nås:\nMinimum af \\(d(a,p),d(a,q), d(a,r), d(b,p), d(b,q), d(p,r)\\)\nComplete linkage: \\(pqr\\) mødes med \\(ab\\), når den maksimale afstand mellem punkter i de to grupper er nået.\nMaksimum af \\(d(a,p),d(a,q), d(a,r), d(b,p), d(b,q), d(p,r)\\)\nMiddelafstand- average linkage: Når den gennemsnitlige afstand er nået. \\(\\frac{1}{2\\cdot 3}(d(a,p)+d(a,q)+ d(a,r)+ d(b,p)+ d(b,q)+ d(p,r))\\)\n\n(OBS: Her skal være tegninger og diagrammer -dendrogrammer. Og eksempler på, hvad forskellen er på de forskellige linkagekrav)\nKlyngeanalyse af DNA eller for eksempel mRNA giver anledning til dendrogrammer, som kaldes de phylogenetiske træer for de arter/sygdomme,... der svarer til den analyserede DNA.\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC2859286/\nhttps://www.ncbi.nlm.nih.gov/pmc/articles/PMC6130602/"
  },
  {
    "objectID": "materialer/afstande/afstand.html#k-means-clustering",
    "href": "materialer/afstande/afstand.html#k-means-clustering",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "k-means clustering",
    "text": "k-means clustering\nVores data er punkter med \\(d\\) koordinater. Afstanden er Euklidisk. Vi vælger \\(k\\), det antal clusters, det skal ende med. Målet er at opdele data i \\(k\\) dele, \\(S_1, S_2,\\ldots , S_k\\) så den samlede gennemsnitlige kvadratiske afstand \\[\\Sigma_{i=1}^{k}\\Sigma_{p,q\\in S_i}\\frac{1}{2|S_i|}\\|p-q\\|^2\\] indenfor de \\(k\\) clusters er mindst mulig."
  },
  {
    "objectID": "materialer/afstande/afstand.html#footnotes",
    "href": "materialer/afstande/afstand.html#footnotes",
    "title": "Afstande, nærmest, størst, mindst",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nAfstanden bliver \\(10^2+0,2^2\\). Bemærk, at det er udregnet udfra vægt i kg og højde i meter. Med højde i cm ville det være \\(10^2+20^2\\), men stadig samme afstand fra A til B som fra A til C. Se Afstand udfra Data for mere info om effekten af at skifte enheder. Det kan godt lave om på, hvilke punkter, der ligger nærmest.↩︎"
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemDNA.html",
    "href": "materialer/afstande/AfstandeMellemDNA.html",
    "title": "Afstand mellem DNA- og RNA-strenge",
    "section": "",
    "text": "RNA er strenge med bogstaverne U (uracil), G (guanin), C (cytosin), A, (adenin). DNA har ikke U, men i stedet T (thymin) og DNA er dobbelt. Bogstaverne U, G, C, A og T kaldes for nukleotider.\nVi ser her på afstande mellem DNA (eller RNA), som bygger på antallet af mutationer for at nå fra den ene til den anden og desuden, hvor hyppige disse mutationer er - hvis man ved, en mutation sker ofte, er afstanden mellem en streng uden mutationen og en med mutationen ikke så lang, som hvis mutationen er meget sjælden. Udover regler for, hvilke ændringer, man tillader, giver man derfor en omkostning ved ændringen – afstanden er ikke bare antal ændringer, men summen af, hvor \"dyre\" disse ændringer er.\nAfstand mellem DNA bruges til at analysere slægtskab og hvilke dyr, herunder mennesket, der nedstammer fra hvilke andre dyr – det kaldes for fylogenetiske træer – se mere her.\nI den sammenhæng kalder man skift mellem A og G eller mellem C og T for transitioner1. De fire andre mulige skift mellem A og C, mellem A og T, mellem G og T, mellem G og C, kaldes for transversioner. Transitioner er hyppigere mutationer end transversioner, så afstanden mellem \\(GATTACA\\) og \\(GATTACG\\) er mindre end afstanden mellem \\(GATTACA\\) og \\(GATTACC\\). Den slags udskiftning af et bogstav (et basepar) kaldes en punktmutation.\n1 A og G er puriner, mens C og T er pyrimediner. Transition bytter en purin med en purin eller en pyrimedin med en pyrimedin.Indel mutationer er indsætning (\"In\") eller fjernelse (\"Del\" for delete\") af et eller flere basepar. Det er mindre hyppigt og svarer til længere afstand. I kilden ovenfor bruges følgende omkostninger og altså afstande mellem DNA-strenge. Bemærk, at det er et valg - der er mange andre muligheder:\n\nTransition: 1\nTransversion: 2\nGap åbning: 9 (indsæt eller fjern præcis en base - altså et bogstav)\nGap forlængelse: 4 (indsæt eller fjern en base på samme sted, som er åbnet)\n\nMan kan samle de to sidste og sige, at det koster \\(5+4L\\) at indsætte eller fjerne en delstreng med \\(L\\) bogstaver midt i et ord (overvej, at I forstår, at det er samme regel).\nVi tilføjer forlængelse/forkortelse: Det koster \\(4L\\) at indsætte eller fjerne \\(L\\) bogstaver i start eller slut af et ord. Alt i alt:\n\nTransition: 1\nTransversion: 2\nIndsæt eller fjern delord med \\(L\\) bogstaver midt i et ord: \\(5+4L\\)\nForlæng/forkort: Indsæt eller fjern \\(L\\) bogstaver i start eller slut af et ord: \\(4L\\)\n\nAfstand mellem to strenge er så den kortest mulige måde, man kan komme fra den ene til den anden med de tilladte moves vægtet som her.\n\n\n\n\n\n\n\nI det følgende bruger vi meget korte strenge. Det er naturligvis ikke realistisk. Vi vil finde afstanden fra \\(AGT\\) til \\(ATG\\). Der er mange muligheder for, hvordan man kan komme fra \\(AGT\\) til \\(ATG\\), altså hvordan mutationerne kunne have set ud. For eksempel kunne det være:\n\\[AGT \\to ATGT \\to ATG\\] Det vil sige, indsæt \\(T\\) mellem \\(A\\) og \\(G\\) og fjern så det sidste \\(T\\). Det koster \\(9+4 =13\\). Altså er længden af denne vej \\(13\\). En anden mulighed er\n\\[AGT\\to ATT \\to ATG\\]\nHer er der to punktmutationer og begge er transversioner (fra \\(T\\) til \\(G\\) eller omvendt), så det koster \\(2+2=4\\). Det er den korteste vej, så afstanden er \\(4\\). At denne vej faktisk er den kortest, kræver mere eftertanke.\nHavde vi brugt samme omkostning/vægt for alle tilladte ændringer, ville begge de to veje have samme længde.\nHvad med fra \\(AGT\\) til \\(TGA\\)? Jo, det er faktisk nemmere. Det er i virkeligheden samme DNA-sekvens – man har bare læst den fra den anden ende...\nMed lange strenge, som er ens på lange stykker, finder man afstande ved først at \"aligne\". Det vil sige, at man anbringer strengene, så de passer sammen på flest mulige pladser. Og derefter udregner man afstande, men det er stadig ikke nemt – der skal algoritmer til. Her er et eksempel.\nStreng 1: \\(TCGTAGG\\)\nStreng 2: \\(TCTGTATCGA\\)\nFørste alignment: \\[\\begin{matrix}T&C&G&-&-&-&T&A&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] Det koster:\n\nIndsættelse af \\(GTA\\): \\(5+4\\cdot 3=17\\)\nTo transversioner \\(G\\leftrightarrow T\\) og \\(A\\leftrightarrow C\\) samt en transition \\(G\\leftrightarrow A\\).\nI alt \\(17+4+1=22\\).\n\nHvis man i stedet vælger denne alignment \\[\\begin{matrix}T&C&-&-&-&G&T&A&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] er transversionen mellem \\(G\\) og \\(T\\) erstattet med en transition \\(G\\leftrightarrow A\\) og omkostningen falder med \\(1\\) til \\(21.\\)\nMan indser ret let, at prisen for at klippe gør, at man ikke vil klippe to gange og bruge \\[\\begin{matrix}T&C&-&G&-&-&T&A&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] hvor man kun sparer en enkelt transition.\nMen hvad med: \\[\\begin{matrix}T&C&-&G&T&A&-&-&G&G\\\\T&C&T&G&T&A&T&C&G&A\\end{matrix}\\] Her er omkostningen \\(9\\) for det første gap og \\(13\\) for det andet. Og der er en transition i sidste plads \\(G\\leftrightarrow A,\\) så omkostningen er \\(23\\), men det er ikke helt så klart, at det er for dyrt at klippe to gange. I kan nok finde på eksempler, hvor det kan svare sig at klippe flere steder."
  },
  {
    "objectID": "materialer/afstande/MetrikDetAbstrakteAfstandsBegreb.html",
    "href": "materialer/afstande/MetrikDetAbstrakteAfstandsBegreb.html",
    "title": "Definition af en metrik – det abstrakte afstandsbegreb",
    "section": "",
    "text": "Man har ikke frit valg til at bestemme, hvad man vil bruge som afstandsmål. Hvis det skal give mening, skal man have en metrik – det betyder, at afstanden skal opfylde nogle betingelser:\nEn metrik på en mængde \\(M\\) er en funktion \\(d\\) fra \\(M\\times M\\) til \\(\\mathbb{R}\\) – altså en funktion, som tager to elementer i \\(M\\) og giver et reelt tal.\nHvis en funktion \\(d\\) skal være en metrik, så vil vi kræve, at den opfylder følgende fire betingelser:\nFor alle \\(p,q,r\\) i \\(M\\) skal der gælde, at\n\n\\(d(p,q)\\geq 0\\). Med ord: Alle afstande er positive eller \\(0\\).\n\\(d(p,p)=0\\) og \\(d(p,q)=0\\) hvis og kun hvis \\(p=q\\). Med ord: Afstanden fra et punkt til sig selv er \\(0\\), og ingen andre afstande er \\(0\\).\n\\(d(p,q)=d(q,p)\\). Det vil sige, at afstanden er symmetrisk. Med ord: Der er lige så langt fra \\(p\\) til \\(q\\) som fra \\(q\\) til \\(p\\).\n\\(d(p,q)+d(q,r)\\geq d(p,r)\\). Det kaldes for trekantsuligheden. Med ord: Der er mindst lige så langt fra \\(p\\) til \\(r\\) via \\(q\\), som direkte fra \\(p\\) til \\(r\\).\n\nLad os tage et velkendt eksempel.\n\nEksempel 1 (Euklidisk afstand som metrik) Lad \\(M\\) være alle punkter i planen og lad metrikken være den euklidiske afstand, som vi kender. Funktionen \\(d\\) vil så tage to punkter \\(P(x_1,y_1)\\) og \\(Q(x_2,y_2)\\) i planen og give et reelt tal som output svarende til den euklidiske afstand mellem \\(P\\) og \\(Q\\). Det vil sige, at \\[ d(P,Q) = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\\] Vi vil senere vise, at denne funktion opfylder betingelserne for en metrik, som defineret ovenfor.\n\nDet er en meget kort definition. Og meget, meget generel. \\(M\\) er en mængde - der er en strengt logisk måde at gå til mængder på, men lad os her sige en samling af objekter, som vi også kalder elementer af mængden. Læg mærke til, at vi her bare graver problemet lidt længere ned i sandet – fejer det ind under gulvtæppet – for hvad er \"objekter\"? Det kommer vi ikke nærmere her.\nDet er ret nemt at acceptere, at de tre krav er rimelige. Men er det nok? Og er det nu alligevel rimeligt? Hvad med symmetrien? Der er vel længere \\(10\\) km op ad bakke end \\(10\\) km ned ad bakke, hvis man tænker på arbejdsindsats. Så måske giver det ikke altid mening?1\n1 Hvis funktionen \\(d\\) opfylder 1,2,4, er det en quasimetrik. Opfylder den 1,2,3, er det en semimetrik. Opfylder den 1, 3 og 4, og første del af 2 (\\(d(p,p)=0\\), men der kan være andre afstande, der er \\(0\\)) er det en pseudometrik. Der findes såmænd også præmetrikker, metametrikker, pseudoquasimetrikker og sikkert andre – \"falske metrikker\".2 Ordet \"rum\" skal man ikke lægge for meget i. Der er ikke anden information i det end definitionen. Intuition skal man være varsom med.Definitionen af metrik som her, er den, vi bruger i matematik. Den har vist sig nyttig. Der er en skov af artikler og bøger, hvor man kan se, hvad man ved, når man har en metrik. En mængde med en metrik kaldes et metrisk rum.2\n\nEksempel 2 (Den diskrete metrik) På en mængde \\(M\\) er funktionen \\(d\\) givet ved.\n\n\\(d(p,p)=0\\)\nHvis \\(p\\neq q\\) er \\(d(p,q)=1\\).\n\nDet er en metrik – den opfylder definitionen ovenfor. Men det er ikke nogen specielt nyttig metrik. Alle elementer ligger lige tæt på alle andre, så der er ikke ny information – udover, om to elementer er ens eller ej.\n\n\nEksempel 3 (Euklidisk afstand som metrik, fortsat) Vi vil vise, at den euklidiske afstand mellem to punkter rent faktisk opfylder betingelserne for en metrik, som vi definerede dem ovenfor:\n\nDen første betingelse er opfyldt, da \\[d(P,Q)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2} \\geq 0\\]\nI den anden betingelse er der to ting at vise. For det første ses det nemt, at \\[d(P,P)=\\sqrt{(x_1-x_1)^2+(y_1-y_1)^2} = \\sqrt{0}=0\\] For det andet – hvis \\[d(P,Q)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=0\\] så kan det kun lade sig gøre, hvis både \\[(x_2-x_1)^2=0 \\quad \\textrm{og} \\quad (y_2-y_1)^2=0\\] Det kan igen kun lade sig gøre3, hvis \\[x_1=x_2 \\quad \\textrm{og} \\quad y_1=y_2\\] Det vil sige, at \\(P=Q\\), og den anden betingelse er således også opfyldt.\nDa \\((a-b)^2=(b-a)^2\\) får vi, at \\[d(P,Q)=\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}=\\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}=d(Q,P)\\] og den tredje betingelse er opfyldt.\nDet kræver lidt mere at bevise trekantsuligheden, men intuitivt virker det fornuftigt nok. Hvis du i trekant \\(PQR\\), skal fra \\(P\\) til \\(R\\), så bliver turen dertil ikke kortere, hvis du først går om \\(Q\\).\n\n3 Brug nulreglen.\n\n\n\n\n\n\nOpgave: Levenshteinafstanden\n\n\n\n\n\nVis, at Levenshteinafstanden giver en metrik.\n\nHvilken mængde er det mon en metrik på? Her kan man vælge – hvilke bogstaver må bruges? Vil I begrænse længden på de ord, der kan optræde?\nOvervej, at afstanden mellem to ord er længden af den (eller rettere en - der kan være flere veje, som er lige lange) korteste mulige vej fra det ene til det andet i et netværk (en graf). \n\nNu skulle det være til at indse, at de fire betingelser er opfyldt.\n\n\n\n\nEksempel 4 (Ikke-metrik) En elev er træt af kvadratrødder og tænker, at man vel kan droppe den euklidiske afstand og i stedet definere en afstand mellem to punkter \\(p(x_1,y_1)\\) og \\(q(x_2,y_2)\\) i planen som følger:\n\\[D(p,q)=(x_2-x_1)^2+(y_2-y_1)^2 \\tag{1}\\]\nDer er bare et lille problem: \\(D\\) er ikke en metrik! Den opfylder nemlig ikke trekantsuligheden. Men hvordan kan man se det? Husk på, at vi bare skal finde ét eksempel – det vil sige tre punkter \\(p,q,r\\), hvor trekantsuligheden ikke holder. Så har vi vist, at \\(D\\) ikke er en metrik.\nEt konkret eksempel: \\(p=(0,0)\\), \\(q=(2,0)\\), \\(r=(4,0)\\). Se figur 1.\n\n\n\n\n\n\nFigur 1: Koordinatsystem med punkterne \\(p=(0,0)\\), \\(q=(2,0)\\) og \\(r=(4,0)\\).\n\n\n\nAfstanden fra \\(p\\) til \\(r\\) er \\(D(p,r)=4^2+0^2=16\\), mens afstanden fra \\(p\\) til \\(q\\) er \\(D(p,q)=2^2+0^2=4\\) og det samme gælder afstanden fra \\(q\\) til \\(r\\): \\(D(q,r)=2^2+0^2=4\\) så \\[D(p,q)+D(q,r)=8\\] mens \\[D(p,r)=16\\] Altså er \\[ D(p,q)+D(q,r) \\ngeq D(p,r) \\]\nEt andet eksempel, som ligner en rigtig trekant: \\(p=(0,0)\\) \\(q=(2,1)\\), \\(r=(4,0)\\). Se figur 2.\n\n\n\n\n\n\nFigur 2: Koordinatsystem med punkterne \\(p=(0,0)\\), \\(q=(2,1)\\) og \\(r=(4,0)\\).\n\n\n\nHer er \\(D(p,q)=2^2+1^2=5\\) og \\(D(q,r)=(4-2)^2+1^2=5\\) så \\[D(p,q)+D(q,r)=10\\] mens \\[D(p,r)=4^2+0^2=16\\] Igen er det med dette afstandsmål kortere at gå fra \\(p\\) til \\(r\\) via \\(q\\) end at gå direkte. Og det er altså derfor ikke en metrik.\n\n\n\n\n\n\n\nOpgave: Ikke-metrik\n\n\n\n\n\nBrug funktionen\n\\[D(p,q)=(x_2-x_1)^2+(y_2-y_1)^2\\]\nfra eksempel 4. Vi vil undersøge, hvornår \\(D(p,q)+D(q,r) \\geq D(p,r)\\), således at trekantsuligheden er opfyldt.\nHer regner vi på trekanter \\(pqr\\) med: \\(p=(0,0)\\), \\(q=(2,y)\\) og \\(r=(4,0)\\), hvor midterpunktet \\(q\\) flyttes længere væk fra førsteaksen. Brug app’en nedenfor og find det \\(y\\), hvor \\(D(p,q)+D(q,r)=D(p,r)\\).\n\nHvad er \\(\\angle pqr\\), når denne ligning er opfyldt?\nKunne man have indset det uden at regne?\nHvad skal \\(\\angle pqr\\) være for at trekantsuligheden er opfyldt: \\(D(p,q)+D(q,r) \\geq D(p,r)\\)?"
  },
  {
    "objectID": "materialer/gradientnedstigning/bevis_vha_middelvaerdisaetningen.html",
    "href": "materialer/gradientnedstigning/bevis_vha_middelvaerdisaetningen.html",
    "title": "Argument for at de retningsafledede kan udregnes med et prikprodukt ved hjælp af middelværdisætningen",
    "section": "",
    "text": "Vi vil her argumentere for formlen for, at de retningsafledede kan udregnes som et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\]\nved at bruge middelværdisætningen for funktioner af én variabel:\n\n\nSætning 1 (Middelværdisætningen) Hvis \\(f\\) er kontinuert på \\(\\left\\lbrack a;b \\right\\rbrack\\) og differentiabel i \\(\\left\\rbrack a;b \\right\\lbrack\\), så findes der et tal \\(c\\) mellem \\(a\\) og \\(b\\), så tangenthældningen i \\(c\\) er lig med middelværdien af hældningen på hele intervallet \\(\\left\\lbrack a;b \\right\\rbrack\\). Det vil sige, at \\[f^{'}\\left( c \\right) = \\frac{f\\left( b \\right) - f(a)}{b - a}\\]\n\n\nResultatet i middelværdisætningen kan omskrives til\n\\[\nf\\left( b \\right) - f\\left( a \\right) = f^{'}\\left( c \\right) \\cdot (b - a)\n\\tag{1}\\]\nsom er det, vi får brug for. Middelværdisætningen virker indlysende korrekt, hvis man prøver at tegne situationen, og beviset for middelværdisætningen kan findes i flere gymnasiebøger.\nInden vi går til argumentet for formlen for de retningsafledede, vil vi se på et enkelt eksempel med middelværdisætningen.\n\nEksempel 1 Funktionen \\(f\\left( x \\right) = \\sqrt{x}\\) er kontinuert på \\(\\left\\lbrack 0;4 \\right\\rbrack\\) og differentiabel i \\(\\left\\rbrack 0;4 \\right\\lbrack\\), så betingelserne for at bruge middelværdisætningen er opfyldt.\nDer findes så et tal \\(c\\) mellem 0 og 4, så \\(f^{'}\\left( c \\right) = \\frac{f\\left( 4 \\right) - f(0)}{4 - 0}\\).\nVi ved, at \\(f^{'}\\left( x \\right) = \\frac{1}{2\\sqrt{x}}\\) så ligningen ovenfor bliver \\[\n\\frac{1}{2\\sqrt{c}} = \\frac{\\sqrt{4} - \\sqrt{0}}{4 - 0}\n\\] Det vil sige, at \\[\n\\frac{1}{2\\sqrt{c}} = \\frac{1}{2}\n\\] hvilket giver \\(c = 1\\).\nTangenthældningen af grafen for \\(f\\left( x \\right) = \\sqrt{x}\\) i \\(c = 1\\) er altså det samme som middelværdien af hældningen af grafen på hele intervallet \\(\\left\\lbrack a;b \\right\\rbrack = \\left\\lbrack 0;4 \\right\\rbrack\\), det vil sige hældningen af den sekant, der forbinder startpunktet \\((0,f\\left( 0 \\right))\\) og slutpunktet \\((4,f\\left( 4 \\right))\\).\nPå figur 1 illustreres dette princip.\n\n\n\n\n\n\n\nFigur 1: Illustration af middelværdisætningen. Her har tangenten i \\((1,f(1))\\) (den grønne linje) samme hældning som sekanten gennem \\((0,f(0))\\) og \\((4,f(4))\\) (den blå linje).\n\n\n\nMiddelværdisætningen siger altså bare, at hvis man forbinder start og slutpunktet – den blå linje – og udregner dens hældning, så kan man altid finde mindst et punkt i det indre af intervallet, hvor tangenten i punktet – den grønne linje – har samme hældning. I eksemplet fandt vi et bestemt \\(c\\), som vi ifølge middelværdisætningen vidste, at vi kunne. Når vi i det følgende skal tænke endnu mere generelt, så bliver middelværdisætningen nyttig.\nVi vender nu tilbage til definitionen af de retningsafledede. Vi får i det følgende brug for at antage, at både \\(f_x(x,y)\\) og \\(f_y\\left( x,y \\right)\\) eksisterer, så vi kan bruge middelværdisætningen. Desuden får vi også brug for at antage, at \\(f_x(x,y)\\) og \\(f_y\\left( x,y \\right)\\) er kontinuerte på en omegn af \\((x_{0},y_{0})\\).\nVi husker på, at de retningsafledede var defineret ved\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\lim_{h \\rightarrow 0}\\frac{f\\left( x_{0} + hu_{1},y_{0} + hu_{2} \\right) - f(x_{0},y_{0})}{h}\n\\tag{2}\\]\nVi omskriver nu tælleren i (2) for at kunne bringe middelværdisætningen i spil \\[\n\\begin{aligned}\nf( x_{0} + h \\cdot u_{1}, y_{0} + h &\\cdot u_{2}) - f(x_{0}, y_{0})  = \\\\\n& f\\left( x_{0} + h \\cdot u_{1},y_{0} +  h \\cdot u_{2} \\right) \\\\\n& \\color{red}- f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right)  + f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) \\color{black}\\\\\n&- f(x_{0},y_{0})\n\\end{aligned}\n\\] Bemærk, at vi har lagt et led til og trukket det samme led fra (markeret med rødt). Det svarer til, at vi har indskudt et punkt i \\(xy\\)-planen, som illustreret i figur 2.\n\n\n\n\n\n\nFigur 2: Et rødt punkt er indskud i \\(xy\\)-planen.\n\n\n\nVi ser nu, at de to første led kun afviger på \\(x\\)-koordinaten (markeret med blåt nedenfor), og de to sidste led afviger kun på \\(y\\)-koordinaten (markeret med grønt): \\[\n\\begin{aligned}\nf\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f(x_{0},y_{0})   &= \\\\\n\\color{blue} f\\left( x_{0} + h \\cdot u_{1},y_{0} +  h \\cdot u_{2} \\right)  - & \\color{blue} f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right)  \\color{black} + \\\\  \\color{green} f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) - & \\color{green} f(x_{0},y_{0})\n\\end{aligned}\n\\tag{3}\\]\nAfvigelsen på henholdsvis \\(x\\)- og \\(y\\)-koordinaten er vist i figur 3.\n\n\n\n\n\n\nFigur 3: Afvigelsen på \\(x\\)-koordinaten er markeret med blåt, mens afvigelsen på \\(y\\)-koordinaten er markeret med grønt.\n\n\n\nVed at bruge den omskrevne middelværdisætning i (1) på de to snitfunktioner \\(f\\left( x,y_{0} + h \\cdot u_{2} \\right)\\) som en funktion af \\(x\\) og \\(f(x_{0},y)\\) som en funktion af \\(y\\), får vi nu følgende:\n\\[\n\\begin{aligned}\n\\color{blue} f\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) =  \\color{blue} f_x(c_{1},y_{0} + h \\cdot u_{2}) \\cdot h \\cdot u_{1}\n\\end{aligned}\n\\] og \\[\n\\color{green} f\\left( x_{0},y_{0} + h \\cdot u_{2} \\right) - f\\left( x_{0},y_{0} \\right) = f_y(x_{0},c_{2}) \\cdot h \\cdot u_{2}\n\\]\nHer har vi brugt, at den afledede af en snitfunktion, hvor vi kun varierer \\(x\\) er \\(f_x\\), og den afledede af en snitfunktion, hvor vi kun varierer \\(y\\) er \\(f_y\\). Tallet \\(c_{1}\\) ligger mellem \\(x_{0}\\) og \\(x_{0} + h \\cdot u_{1}\\), og tallet \\(c_{2}\\) ligger mellem \\(y_{0}\\) og \\(y_{0} + h \\cdot u_{2}\\). Dette er vist i figur 4.\n\n\n\n\n\n\nFigur 4: Tallet \\(c_{1}\\) ligger mellem \\(x_{0}\\) og \\(x_{0} + h \\cdot u_{1}\\), og tallet \\(c_{2}\\) ligger mellem \\(y_{0}\\) og \\(y_{0} + h \\cdot u_{2}\\).\n\n\n\nIndsætter vi de to udtryk ovenfor på højreside i (3) får vi \\[\n\\begin{multline}\nf\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f(x_{0},y_{0})  = \\color{blue} f_x(c_{1},y_{0} + h \\cdot u_{2}) \\cdot h \\cdot u_{1} \\color{black} + \\\\ \\color{green} f_y(x_{0},c_{2}) \\cdot h \\cdot u_{2} \\\\\n\\end{multline}\n\\]\nOg bruges dette i definitionen for den retningsafledede i (2) ender vi med \\[\n\\begin{aligned}\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) &= \\lim_{h \\rightarrow 0}\\frac{f\\left( x_{0} + h \\cdot u_{1},y_{0} + h \\cdot u_{2} \\right) - f(x_{0},y_{0})}{h}\n\\\\\n&=\n\\lim_{h \\rightarrow 0}\\frac{f_x\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) \\cdot h \\cdot u_{1} + f_y(x_{0},c_{2}) \\cdot h \\cdot u_{2}\\ }{h}\n\\end{aligned}\n\\] Vi kan nu dividere \\(h\\) op i hvert led og får \\[\n\\begin{aligned}\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right)\n&= \\underset{h \\rightarrow 0}{\\text{lim}} f_x\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) \\cdot u_{1} + f_y(x_{0},c_{2}) \\cdot u_{2}\\\n\\\\\n&= \\lim_{h \\rightarrow 0}\\begin{pmatrix}\nf_x\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) \\\\\nf_y(x_{0},c_{2})\n\\end{pmatrix} \\cdot\n\\begin{pmatrix}\nu_{1} \\\\\nu_{2}\n\\end{pmatrix}\n\\end{aligned}\n\\tag{4}\\] hvis grænsen eksisterer.\nHusk på, at \\(c_1\\) ligger i intervallet \\((x_0,x_0+h \\cdot u_1)\\) og \\(c_2\\) ligger i intervallet \\((y_0,y_0+h \\cdot u_2)\\). Derfor vil\n\\[\n\\lim_{h \\rightarrow 0}\\left( c_{1},y_{0} + h \\cdot u_{2} \\right) =\n(x_{0},y_{0})\n\\] og \\[\n\\lim_{h \\rightarrow 0}\\left( x_{0},c_{2} \\right) = \\ (x_{0},y_{0})\n\\]\nVi startede med at antage, at de partielle afledede er kontinuerte. Det får vi brug for nu. Det betyder nemlig, at grænseværdien i (4) eksisterer, og vi får det ønskede resultat\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\begin{pmatrix}\nf_x\\left( x_{0},y_{0} \\right) \\\\\nf_y(x_{0},y_{0}) \\\\\n\\end{pmatrix} \\cdot \\begin{pmatrix}\nu_{1} \\\\\nu_{2} \\\\\n\\end{pmatrix} = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\] Det var netop, hvad vi ønskede at vise1.\n\n\n1 Vi startede med at antage, at de partielle afledede eksisterer og er kontinuerte på en omegn. Bemærk, at vi ud fra den antagelse nu har vist, at alle de retningsafledede også vil eksistere."
  },
  {
    "objectID": "materialer/gradientnedstigning/gradientnedstigning.html",
    "href": "materialer/gradientnedstigning/gradientnedstigning.html",
    "title": "Gradientnedstigning",
    "section": "",
    "text": "I denne note vil vi forklare hvad gradientnedstigning går ud på, og hvordan gradientnedstigning kan bruges i forbindelse med at bestemme minimum eller maksimum for en funktion.\nVi vil her nøjes med at se på en funktion \\(f(x,y)\\) af to variable. I noten om funktioner af flere variable har vi skrevet, at gradientvektoren\n\\[\n\\nabla f\\left( x_{0},y_{0} \\right) = \\begin{pmatrix}\nf_x\\left( x_{0},y_{0} \\right) \\\\\nf_y\\left( x_{0},y_{0} \\right) \\\\\n\\end{pmatrix}\n\\]\nangiver den retning, man skal bevæge sig væk fra punktet \\((x_{0},y_{0})\\), for at funktionsværdierne \\(f(x,y)\\) vokser mest muligt. Det er denne egenskab, som vi vil bevise her og forklare, hvordan den kan bruges til at bestemme maksimum eller minimum for en funktion. For at gøre det må vi starte med at definere de såkaldte retningsafledede.\n\nRetningsafledede\nNår vi står i et punkt \\((x_{0},y_{0})\\) og gerne vil undersøge i hvilken retning funktionsværdien vokser mest, så kunne vi jo starte med at udregne de to partielle afledede\n\\[\nf_x( x_{0},y_{0}) \\quad \\textrm{og} \\quad f_y( x_{0},y_{0}).\n\\]\nDisse to størrelser angiver væksthastigheden i henholdsvis \\(x\\)- og \\(y\\)-aksens retning. Men der er ingen, som siger, at det lige præcis er i en af de to retninger, at funktionsværdien vokser mest. Det kunne lige så godt være i en hvilken som helst anden retning.\nVi vil her angive den retning i \\(xy\\)-planen, som vi nu vil bevæge os i med en enhedsvektor – det vil sige en vektor med længde 1:\n\\[\n\\vec{u} = \\begin{pmatrix}\nu_{1} \\\\\nu_{2} \\\\\n\\end{pmatrix}\n\\] hvor altså \\(\\lvert \\vec u \\rvert = 1\\).\nVi definerer nu den retningsafledede af \\(f\\) i punktet \\((x_{0},y_{0})\\) i retningen \\(\\vec{u}\\) ved\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\lim_{h \\rightarrow 0}\\frac{f\\left( x_{0} + hu_{1},y_{0} + hu_{2} \\right) - f(x_{0},y_{0})}{h}\n\\tag{1}\\]\nhvis ellers grænsen eksisterer.\nBemærk, at hvis \\(\\vec{u}\\) peger i \\(x\\)-aksens retning, så bliver den retningsafledede til \\(f_x(x_{0},y_{0})\\), og hvis den peger i \\(y\\)-aksens retning, bliver den til \\(f_y(x_{0},y_{0})\\).\nAf definitionen kan man se, at man udregner en sekanthældning ved at tage et skridt \\(h\\) i \\(\\vec{u}\\)’s retning og dividere den fundne funktionstilvækst med \\(h\\). Derefter lader man \\(h\\) gå mod 0. Det giver hældningen af grafen for \\(f\\) i punktet \\((x_{0},y_{0})\\) i retningen \\(\\vec{u}\\). Og dermed altså væksthastigheden for \\(f\\) i retningen \\(\\vec{u}\\).\nIdéen med den retningsafledede er illustreret i figuren nedenfor. Til venstre ses en repræsentant for \\(\\vec u\\) i \\(xy\\)-planen. Man kan ændre på den retning, som \\(\\vec u\\) peger i, ved at trække i skyderen. Til højre ses grafen for en funktion \\(f\\) af to variable, hvor et punkt \\(P(x_0,y_0,f(x_0,y_0))\\) på grafen er indtegnet. Samtidig vises den snitkurve som fås, hvis man på grafen i punktet \\(P\\) bevæger sig langs en linje i retningen \\(\\vec u\\). Denne snitkurve har i punktet \\(P\\) en tangent, som også er indtegnet, og denne tangents hældning vil netop svarer til størrelsen af den retningsafledede \\(D_{\\vec{u}}f\\left( x_{0},y_{0} \\right)\\). Hvis man ændrer på den retning, som \\(\\vec u\\) peger i, kan man se, hvordan størrelsen af den retningsafledede ændrer sig.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDet viser sig, at man kan udregne de retningsafledede med et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}.\n\\]\nVi vil nedenfor argumentere for formlen, men lad os først se på konsekvenserne af den. Vi ved fra almindelig vektorregning, at\n\\[\n\\vec{a} \\cdot \\vec{b} = \\lvert \\vec{a} \\rvert \\cdot \\lvert \\vec{b} \\rvert \\cdot \\cos(v)\n\\]\nhvor \\(v\\) er vinklen mellem de to vektorer. Da \\(\\lvert \\vec{u} \\rvert = 1\\) betyder det, at\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\lvert \\nabla f(x_{0},y_{0}) \\rvert \\cdot \\cos(v)\n\\]\nhvor \\(v\\) er vinklen mellem gradientvektoren \\(\\nabla f\\left( x_{0},y_{0} \\right)\\) og den valgte retning \\(\\vec{u}\\).\nVi ved, at \\(-1 \\leq \\cos(v) \\leq 1\\) samt at \\(\\cos(0^{{^\\circ}})=1\\) og \\(\\cos(180^{{^\\circ}})=-1\\). Det følger derfor, at den retningsafledede er størst (og dermed at \\(f\\) vokser mest), når \\(\\vec{u}\\) peger i \\(\\nabla f(x_{0},y_{0})\\)’s retning. Og tilsvarende at den retningsafledede er mindst (og dermed at \\(f\\) aftager mest), når \\(\\vec{u}\\) peger i \\(-\\nabla f(x_{0},y_{0})\\)’s retning. Det vil sige, at den retningsaflededes størsteværdi er\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\ \\ \\ \\lvert \\nabla f(x_{0},y_{0}) \\rvert\n\\]\nnår \\(v = 0^{{^\\circ}}\\) og retningsaflededes mindsteværdi er\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = - \\lvert \\nabla f(x_{0},y_{0}) \\rvert\n\\]\nnår \\(v = 180^{{^\\circ}}\\). Det var netop, hvad vi gerne ville vise.\nPrincippet er illustreret i figuren herunder. Gradientvektoren \\(\\nabla f(x_{0},y_{0})\\) er indtegnet (med blå) og man kan se, at den retningsafledede antager den største værdi, netop når \\(\\vec u\\) peger i gradientens retning (prøv at trække i skyderen). Og omvendt antager den retningsafledede den mindste værdi, når \\(\\vec u\\) peger i minus gradientens retning.\n\n\n\nFor at vise, at man kan udregne de retningsafledede med et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\]\nkan du vælge enten at læse et bevis, som baserer sig på geometriske argumenter eller et bevis som er baseret på middelværdisætningen.\n\n\nOptimering ved hjælp af gradientnedstigning\nVi vil nu se på, hvordan gradienten kan bruges til at bestemme maksimum eller minimum for en funktion.\nBetragt en funktion \\(f\\) givet ved forskriften \\[\nf\\left( x,y \\right) = \\left( \\left( x - 5 \\right)^{2} + 3 \\right) \\cdot \\left( 5 + \\left( y - 10 \\right)^{2} \\right) + 30\n\\]\nHvis man ser lidt på forskriften, kan man måske overbevise sig selv om, at funktionen har et minimum på 45, som fås, når \\(\\left( x,y \\right) = (5,10)\\).\nGrafen ses herunder.\n\n\n\nMan kan lave en iterativ metode til at finde minimumspunktet ved at udnytte egenskaben ved gradientvektoren:\n\nVælg et startpunkt \\((x_0,y_0)\\) som et første gæt på et minimumspunkt.\n\nVi udnytter nu, at \\(- \\nabla f(x_0,y_0)\\) angiver den retning, hvor funktionsværdien falder mest i punktet \\((x_0,y_0,f(x_0,y_0))\\).\n\nGå derfor et lille skridt i retningen \\(- \\nabla f(x_0,y_0)\\). Det giver så det næste punkt \\((x_1,y_1)\\), som forhåbentlig er et bedre bud på et minimumspunkt.\nProcessen foregår i definitionsmængden, men på grafen svarer det til at gå et lille stykke den stejleste vej ned ad bakken.\nProcessen itereres så gentagne gange indtil man forhåbentlig når minimumspunktet.\n\nVælger vi med den konkrete funktion et startpunkt på\n\\[\n(x_0,y_0) = ( - 3,4)\n\\]\nog vælger vi i hvert skridt at lægge -0,001 gange den negative gradientvektor i punktet til, så kan nogle af de følgende \\((x,y)\\)-punkter ses til venstre i figur 1. Læg her mærke til hvordan vi nærmer os det globale minimumssted i \\((5,10)\\). Til højre i figur 1 ses det også hvordan vi ved hjælp af gradientnedstigning, nærmer os den globale minimumsværdi på \\(f(5,10)=45\\).\n\n\n\n\n\n\nFigur 1: Til venstre ses et udvalg af nogle af de \\((x,y)\\)-punkter, som genereres i forbindelse med gradientnedstigning. Til højre ses et udvalg af nogle af de funktionsværdier, som genereres i forbindelse med gradientnedstigning.\n\n\n\nVi ser, at den iterative gradientnedstigning faktisk nærmer sig det globale minimumspunkt. Så om ikke andet så virker metoden i hvert fald i dette konkrete tilfælde.\n\n\nTræning af neurale netværk\nAt lede efter et globalt minimumspunkt eller i det mindste et brugbart lokalt minimumspunkt for en funktion af rigtig mange variable er et problem, man står overfor, når man skal træne et neuralt netværk og have fastlagt en masse vægte i netværket.\nDet kan ikke gøres analytisk, så derfor bruger man netop en iterativ proces baseret på gradientnedstigning som metode til at finde frem til minimumspunktet. Eksemplet ovenfor illustrerer derfor idéen bag en central del af træningen af et neuralt netværk.\nLæs mere om hvordan gradientnedstigning konkret bruges her: Perceptroner og Kunstige neurale netværk."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html",
    "href": "materialer/neurale_net/neurale_net.html",
    "title": "Kunstige neurale netværk",
    "section": "",
    "text": "Denne note giver en grundig gennemgang af matematikken bag kunstige neurale netværk."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-1",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-1",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 1",
    "text": "VIDEO: Kunstige neurale netværk 1\nI denne video forklarer lidt om hvad et kunstigt neuralt netværk er og lidt om hvilke input- og outputværdier, man kan bruge."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-2",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-2",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 2",
    "text": "VIDEO: Kunstige neurale netværk 2\nI denne video giver vi et eksempel på et simpelt kunstig neuralt netværk og forklarer feedforward."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-3",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-3",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 3",
    "text": "VIDEO: Kunstige neurale netværk 3\nI videoen her forklarer vi, hvad targetværdier er, og hvordan tabsfunktionen defineres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-4",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-4",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 4",
    "text": "VIDEO: Kunstige neurale netværk 4\nI denne video bliver gradientnedstigning forklaret."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-opdatering_w",
    "href": "materialer/neurale_net/neurale_net.html#sec-opdatering_w",
    "title": "Kunstige neurale netværk",
    "section": "Opdatering af \\(w\\)-vægtene",
    "text": "Opdatering af \\(w\\)-vægtene\nNår man bruger backpropagation, starter man med at finde de partielle afledede for de vægte, som direkte påvirker outputværdien \\(o\\). På figur 4 fremgår det, at det er vægtene \\(w_0, w_1\\) og \\(w_2\\) (husk at vi kalder vores bias for \\(w_0\\)). Lad os starte med at finde den partielle afledede for \\(w_1\\). Ved at bruge kædereglen får vi: \\[\n\\frac{\\partial E}{\\partial w_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial w_1}\n\\] Vi ved fra (12), at \\(E=\\frac{1}{2}(t-o)^2\\) og derfor er: \\[\n\\frac{d E}{d o} = \\frac{1}{2} \\cdot 2 \\cdot (t-o) \\cdot (-1) = -(t-o)\n\\tag{14}\\] Fra (10) har vi, at \\(o=\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)\\) og derfor får vi \\[\n\\frac{\\partial o}{\\partial w_1} =\\sigma'(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0) \\cdot z_1\n\\] Vi har tidligere vist, at \\(\\sigma'(z)=\\sigma(z)(1-\\sigma(z))\\) og derfor har vi \\[\n\\frac{\\partial o}{\\partial w_1} =\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)(1-\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)) \\cdot z_1\n\\] Bruger vi nu, at \\(o=\\sigma(w_1 \\cdot z_1 + w_2 \\cdot z_2 + w_0)\\) kan vi skrive ovenstående lidt mere kompakt: \\[\n\\frac{\\partial o}{\\partial w_1} =o(1-o) \\cdot z_1\n\\] Alt i alt får vi altså, at \\[\n\\frac{\\partial E}{\\partial w_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial w_1}\n= -(t-o) \\cdot o \\cdot (1-o) \\cdot z_1\n\\tag{15}\\] Vi kan nu udlede den første opdateringsregel for vægten \\(w_1\\) ved at bruge idéen fra (13): \\[\nw_1 \\leftarrow w_1 - \\eta  \\cdot \\frac{\\partial E}{\\partial w_1}\n\\] Indsættes udtrykket fra (15), får vi \\[\nw_1 \\leftarrow w_1 - \\eta  \\cdot (-(t-o) \\cdot o \\cdot (1-o) \\cdot z_1)\n\\] Det vil sige, at \\[\nw_1 \\leftarrow w_1 + \\eta  \\cdot (t-o) \\cdot o \\cdot (1-o) \\cdot z_1\n\\] Det er værd at dvæle lidt ved opdateringsleddet \\(\\eta  \\cdot (t-o) \\cdot o \\cdot (1-o) \\cdot z_1\\) på højresiden, fordi det faktisk giver intuitiv god mening. For det første er \\(\\eta\\), det vi som sagt kalder for vores learning rate - et lille positivt tal, som sørger for, at vi ikke tager for store skridt på vores vej ned i dalen (til det lokale minimum). Faktoren \\(t-o\\) er jo netop fejlen. Nemlig forskellen mellem det vi ønsker \\(t\\) (target), og det som netværket giver \\(o\\) (output). Jo større fejl/forskel, desto mere må vi justere vægten. Ser vi på faktoren \\(o\\cdot(1-o)\\), så vil det være sådan, at hvis outputværdien \\(o\\) er tæt på enten \\(0\\) eller \\(1\\) (man siger at neuronen er \"mættet\"), så vil \\(o\\cdot(1-o)\\) være tæt på \\(0\\). Det vil sige, at hvis outputværdien er tæt på \\(0\\) eller \\(1\\), så ændrer vi heller ikke så meget på vægten. Endelig er der faktoren \\(z_1\\), som er inputtet fra det foregående lag (se figur 4). Hvis værdien af denne er (numerisk) stor, så får det også stor betydning for opdateringsleddet (eller tænk på det omvendt: hvis \\(z_1\\) er tæt på \\(0\\), så har \\(z_1\\) alligevel ikke så stor indflydelse på outputværdien, og så giver det heller ikke mening at justere så meget på den tilhørende vægt \\(w_1\\)).\nDet viser sig faktisk, at faktoren \\((t-o) \\cdot o \\cdot (1-o)\\) kommer til at gå igen rigtige mange gange i det følgende. Det bliver i længden lidt tungt at slæbe rundt på. Derfor vælger vi at definere \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\tag{16}\\] og derfor kan opdateringsreglen for \\(w_1\\) nu også skrives: \\[\nw_1 \\leftarrow w_1 + \\eta  \\cdot \\delta \\cdot z_1\n\\tag{17}\\]\nHelt analogt med ovenstående kan man udlede opdateringsregler for \\(w_2\\) og \\(w_0\\). Resultatet er samlet her.\n\n\n\n\n\n\nOpdateringsregler for \\(w\\)-vægtene\n\n\n\n\\[\\begin{align*}\nw_0 &\\leftarrow w_0 + \\eta  \\cdot \\delta  \\\\\nw_1 &\\leftarrow w_1 + \\eta  \\cdot \\delta \\cdot z_1 \\\\\nw_2 &\\leftarrow w_2 + \\eta  \\cdot \\delta \\cdot z_2 \\\\\n\\end{align*}\\] hvor \\[\\delta = (t-o) \\cdot o \\cdot (1-o)\\]\n\n\nMen hvordan foregår det der med de opdateringsregler så egentligt? Jo altså vi starter med at sætte vægtene mere eller mindre tilfældigt. Så laver vi ved hjælp af vores træningseksempel \\((\\vec{x},t)\\) et feedforward i netværket, som det er beskrevet i afsnit 3. Derfor får vi beregnet outputværdien \\(o\\) samt \\(z_1\\) og \\(z_2\\) (husk at \\(z_1\\) og \\(z_2\\) bruges til at beregne \\(o\\)). Desuden kender vi jo fra vores træningsdata target-værdien \\(t\\). Og voila! Alt hvad der indgår på højresiderne i ovenstående opdateringsregler har vi nu adgang til, og vi kan derfor beregne de nye \\(w\\) vægte.\nSå mangler vi bare at finde opdateringsreglerne for de restende vægte!"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-5",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-5",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 5",
    "text": "VIDEO: Kunstige neurale netværk 5\nI videoen her forklarer vi hvordan \\(w\\)-vægtene opdateres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-opdatering_uv",
    "href": "materialer/neurale_net/neurale_net.html#sec-opdatering_uv",
    "title": "Kunstige neurale netværk",
    "section": "Opdatering af \\(u\\)- og \\(v\\)-vægtene",
    "text": "Opdatering af \\(u\\)- og \\(v\\)-vægtene\nVi går nu et trin længere tilbage i netværket - væk fra outputlaget. Her kan vi se neuronerne, som fyrer værdierne \\(z_1\\) og \\(z_2\\), som bliver påvirket af \\(u\\)- og \\(v\\)-vægtene. Lad os her starte med at bestemme opdateringsreglerne for \\(v\\)-vægtene. For at gøre det skal vi finde ud af hvordan \\(v\\)-vægtene påvirker neuronerne længere fremme i netværket. Se igen på figur 4. Her er det tydeligt, at \\(v\\)-vægtene påvirker den mørkegrønne neuron, som fyrer værdien \\(z_1\\), som igen påvirker outputværdien. Derfor kan vi bruge kædereglen på følgende måde: \\[\n\\frac{\\partial E}{\\partial v_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial v_1}\n\\] Vi ved allerede fra (14), at \\[\n\\frac{d E}{d o} = -(t-o)\n\\] Den partielle afledede af \\(o\\) med hensyn til \\(z_1\\) finder vi ved at bruge definitionen af outputværiden \\(o\\) i (10) \\[\n\\begin{aligned}\n\\frac{\\partial o}{\\partial z_1} &= \\sigma'(w_1 \\cdot z_1+w_2 \\cdot z_2 + w_0) \\cdot w_1  \\\\\n&= \\sigma(w_1 \\cdot z_1+w_2 \\cdot z_2 + w_0) \\cdot (1-\\sigma(w_1 \\cdot z_1+w_2 \\cdot z_2 + w_0)) \\cdot w_1  \\\\\n&= o \\cdot (1-o) \\cdot w_1\n\\end{aligned}\n\\tag{18}\\] hvor vi igen har brugt sætning 1. Og endelig ved at udnytte definitionen af \\(z_1\\) i (8) får vi, at \\[\\begin{align}\n\\frac{\\partial z_1}{\\partial v_1} &= \\sigma'(v_1 \\cdot y_1+v_2 \\cdot y_2 + v_0) \\cdot y_1 \\\\\n&= \\sigma(v_1 \\cdot y_1+v_2 \\cdot y_2 + v_0) \\cdot (1-\\sigma(v_1 \\cdot y_1+v_2 \\cdot y_2 + v_0)) \\cdot y_1 \\\\\n&= z_1 \\cdot (1-z_1) \\cdot y_1\n\\end{align}\\] Sætter vi det hele sammen får vi, at \\[\n\\frac{\\partial E}{\\partial v_1} = \\underbrace{-(t-o)}_{\\frac{\\partial E}{\\partial o}}  \\cdot \\underbrace{o \\cdot (1-o) \\cdot w_1}_{\\frac{\\partial o}{\\partial z_1}} \\cdot \\underbrace{z_1 \\cdot (1-z_1) \\cdot y_1}_{\\frac{\\partial z_1}{\\partial v_1}}\n\\] og bruger vi definitionen af \\(\\delta\\) i (16) får vi et lidt mere kompakt udtryk \\[\n\\frac{\\partial E}{\\partial v_1} = -\\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_1\n\\] Opdateringsreglen for \\(v_1\\) bliver derfor \\[\nv_1 \\leftarrow v_1 - \\eta \\cdot \\frac{\\partial E}{\\partial v_1}\n\\] og med det netop udledte udtryk for \\(\\frac{\\partial E}{\\partial v_1}\\) får vi \\[\nv_1 \\leftarrow v_1 - \\eta \\cdot (-\\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1)\\cdot y_1)\n\\] Det vil sige, at \\[\nv_1 \\leftarrow v_1 + \\eta \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_1\n\\] Læg igen mærke til, at når vi har været igennem et feedforward i netværket, så kender vi alle de størrelser, som indgår i ovenstående udtryk.\nPå helt tilsvarende vis kan man bestemme opdateringsreglerne for \\(v_0\\) og \\(v_2\\). De tre opdateringsregler for \\(v\\)-vægtene ses her:\n\n\n\n\n\n\nOpdateringsregler for \\(v\\)-vægtene\n\n\n\n\\[\\begin{align}\nv_0 &\\leftarrow v_0 + \\eta  \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\\\\nv_1 &\\leftarrow v_1 + \\eta  \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_1 \\\\\nv_2 &\\leftarrow v_2 + \\eta  \\cdot \\delta \\cdot w_1 \\cdot z_1 \\cdot (1-z_1) \\cdot y_2 \\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]\n\n\nOpdateringsreglerne for \\(u\\)-vægtene findes på præcis samme måde. Her skal man blot se, at \\(u\\)-vægtene har indflydelse på outputtet via \\(z_2\\) (se figur 4). Derfor skal man f.eks. finde den partielle afledede af \\(E\\) med hensyn til \\(u_1\\) ved at bruge kædereglen på denne måde \\[\n\\frac{\\partial E}{\\partial u_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial u_1}\n\\] Udregninger svarende til det netop gennemgåede giver os\n\n\n\n\n\n\nOpdateringsregler for \\(u\\)-vægtene\n\n\n\n\\[\\begin{align}\nu_0 &\\leftarrow u_0 + \\eta  \\cdot \\delta \\cdot w_2 \\cdot z_2 \\cdot (1-z_2) \\\\\nu_1 &\\leftarrow u_1 + \\eta  \\cdot \\delta \\cdot w_2 \\cdot z_2 \\cdot (1-z_2) \\cdot y_1 \\\\\nu_2 &\\leftarrow u_2 + \\eta  \\cdot \\delta \\cdot w_2 \\cdot z_2 \\cdot (1-z_2) \\cdot y_2 \\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-6",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-6",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 6",
    "text": "VIDEO: Kunstige neurale netværk 6\nI videoen her forklarer vi, hvordan \\(v\\)-vægtene opdateres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-opdatering_rs",
    "href": "materialer/neurale_net/neurale_net.html#sec-opdatering_rs",
    "title": "Kunstige neurale netværk",
    "section": "Opdatering af \\(r\\)- og \\(s\\)-vægtene",
    "text": "Opdatering af \\(r\\)- og \\(s\\)-vægtene\nSå er vi endelig fremme ved \\(r\\)- og \\(s\\) vægtene. Start lige med at tage en dyb indånding! Nu bliver det lidt mere kompliceret. Se på figur 4. Lad os starte med at finde den partielle afledede af \\(E\\) med hensyn til \\(r_1\\). Når man ser på netværket, kan man se, at \\(r_1\\) i første omgang påvirker \\(y_1\\), \\(y_1\\) påvirker både \\(z_1\\) og \\(z_2\\), som så til sidst påvirker outputværdien \\(o\\). Det kan illustreres sådan her \\[\n\\begin{matrix}\n& & & & z_1 & & & \\\\\n& & & \\nearrow & & \\searrow & & \\\\\nr_1 & \\rightarrow & y_1 & & & & \\rightarrow & o \\\\\n& & & \\searrow & & \\nearrow & & \\\\\n& & & & z_2 & & & \\\\\n\\end{matrix}\n\\]\nBalladen er, at \\(y_1\\) både påvirker \\(z_1\\) og \\(z_2\\), og det gør det hele lidt mere kompliceret. Lad os lige starte med at se bort fra det. Ifølge kædereglen får vi så: \\[\n\\frac{\\partial E}{\\partial r_1} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial y_1}  \\cdot \\frac{\\partial y_1}{\\partial r_1}\n\\] Men så var det jo, at \\(o\\) i virkeligheden afhænger af \\(y_1\\) både via \\(z_1\\) og \\(z_2\\). Man kunne skrive det sådan her: \\[\no(z_1(y_1), z_2(y_1))\n\\] Bemærk, at \\(z_1\\) og \\(z_2\\) jo også afhænger af \\(y_2\\), men når vi skal differentiere med hensyn til \\(y_1\\), så er \\(y_2\\) at betragte som en konstant. Og når konstanter bliver differentieret, så giver det som bekendt \\(0\\).\nDerfor: For at finde den partielle afledede af \\(o\\) med hensyn til \\(y_1\\) må vi benytte kædereglen for funktioner af flere variable. Den siger, at \\[\n\\frac{\\partial o}{\\partial y_1} = \\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial y_1} + \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial y_1}\n\\] Det samlede udtryk for den partielle afledede af \\(E\\) med hensyn til \\(r_1\\) bliver derfor \\[\n\\frac{\\partial E}{\\partial r_1} = \\frac{d E}{d o} \\cdot\n\\left(\n\\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial y_1} + \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial y_1}\n\\right)\n\\cdot \\frac{\\partial y_1}{\\partial r_1}\n  \\tag{19}\\] Vi finder hver af de afledede, som indgår i ovenstående udtryk én ad gangen. Vi ved allerede fra (14), at \\[\n\\frac{d E}{d o} = \\frac{1}{2} \\cdot 2 \\cdot (t-o) \\cdot (-1) = -(t-o)\n\\] Vi ved også fra (18), at \\[\n\\frac{\\partial o}{\\partial z_1} = o \\cdot (1-o) \\cdot w_1\n\\] Differentieres \\(z_1\\) (se (8)) med hensyn til \\(y_1\\) får vi \\[\\begin{align}\n\\frac{\\partial z_1}{\\partial y_1} &= \\sigma'(v_1 \\cdot y_1 + v_2 \\cdot y_2 + v_0)\\cdot v_1 \\\\\n&= z_1 \\cdot (1-z_1) \\cdot v_1\n\\end{align}\\] hvor vi igen har brugt sætning 1 og definitionen af \\(z_1\\) i (8). Helt tilsvarende kan vi finde \\(\\frac{\\partial o}{\\partial z_2}\\) og \\(\\frac{\\partial z_2}{\\partial y_1}\\) (se (9)) \\[\n\\frac{\\partial o}{\\partial z_2} = o \\cdot (1-o)\\cdot w_2\n\\] og \\[\n\\frac{\\partial z_2}{\\partial y_1} = z_2 \\cdot (1-z_2)\\cdot u_1\n\\] Den sidste partielle afledede \\(\\frac{\\partial y_1}{\\partial r_1}\\) finder vi ved at differentiere udtrykket for \\(y_1\\) i (4), hvor vi endnu engang udnytter sætning 1.\nIndsætter vi nu alle de udtryk, som vi netop har udledt, i (19) får vi et temmelig langt udtryk for \\(\\frac{\\partial E}{\\partial r_1}\\): \\[\\begin{align}\n\\frac{\\partial E}{\\partial r_1} &= \\underbrace{-(t-o)}_{\\frac{dE}{do}}\\cdot \\\\ &\\Big( \\underbrace{o\\cdot(1-o)\\cdot w_1}_{\\frac{\\partial o}{\\partial z_1}} \\cdot \\underbrace{z_1\\cdot(1-z_1)\\cdot v_1}_{\\frac{\\partial z_1}{\\partial y_1}}+\\underbrace{o\\cdot(1-o)\\cdot w_2}_{\\frac{\\partial o}{\\partial z_2}}\\cdot \\underbrace{z_2\\cdot(1-z_2)\\cdot u_1}_{\\frac{\\partial z_2}{\\partial y_1}}\\Big)\\cdot \\\\ & \\qquad \\underbrace{y_1\\cdot(1-y_1)\\cdot x_1}_{\\frac{\\partial y_1}{\\partial r_1}}\n\\end{align}\\] Og sætter vi \\(o\\cdot(1-o)\\) uden for parentesen og erstatter \\((t-o)\\cdot o\\cdot (1-o)\\) med \\(\\delta\\) får vi \\[\n\\frac{\\partial E}{\\partial r_1}\n=-\\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_1\n\\] Helt i tråd med tidligere får vi altså følgende opdateringsregel for \\(r_1\\) \\[r_1 \\leftarrow r_1 - \\eta \\cdot \\frac{\\partial E}{\\partial r_1} \\] Det vil sige \\[\nr_1 \\leftarrow r_1 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_1\n\\]\nUdleder man tilsvarende opdateringsregler for \\(r_2, r_3, r_4\\) og \\(r_0\\) vil man se, at det eneste, som kommer til at ændre sig i ovenstående, er den sidste faktor \\(x_1\\), som bliver erstattet med henholdsvis \\(x_2, x_3, x_4\\) og \\(1\\). Derfor får vi samlet set\n\n\n\n\n\n\nOpdateringsregler for \\(r\\)-vægtene\n\n\n\n\\[\\begin{align}\nr_0 &\\leftarrow r_0 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\\\\nr_1 &\\leftarrow r_1 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_1\\\\\nr_2 &\\leftarrow r_2 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_2\\\\\nr_3 &\\leftarrow r_3 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_3\\\\\nr_4 &\\leftarrow r_4 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_1+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_1 \\Big) \\cdot y_1\\cdot (1-y_1) \\cdot x_4\\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]\n\n\nOpdateringen af \\(s\\)-vægtene foregår på samme måde. Hvis du ser på figur 4, kan du se, at alle \\(s\\)-vægtene påvirker \\(y_2\\), som så påvirker både \\(z_1\\) og \\(z_2\\), som i sidste ende påvirker outputtet \\(o\\). Ser vi generelt på vægten \\(s_i\\), hvor \\(i=0, 1, 2, 3\\) eller \\(4\\), har vi altså \\[\n\\begin{matrix}\n& & & & z_1 & & & \\\\\n& & & \\nearrow & & \\searrow & & \\\\\ns_i & \\rightarrow & y_2 & & & & \\rightarrow & o \\\\\n& & & \\searrow & & \\nearrow & & \\\\\n& & & & z_2 & & & \\\\\n\\end{matrix}\n\\] Som tidligere kan vi starte med at skrive \\[\n\\frac{\\partial E}{\\partial s_i} = \\frac{d E}{d o} \\cdot \\frac{\\partial o}{\\partial y_2}  \\cdot \\frac{\\partial y_2}{\\partial s_i}\n\\] og bruger vi igen kædreglen for funktioner af flere variable, får vi \\[\n\\frac{\\partial E}{\\partial s_i} = \\frac{d E}{d o} \\cdot\n\\left(\n\\frac{\\partial o}{\\partial z_1} \\cdot \\frac{\\partial z_1}{\\partial y_2} + \\frac{\\partial o}{\\partial z_2} \\cdot \\frac{\\partial z_2}{\\partial y_2}\n\\right)\n\\cdot \\frac{\\partial y_2}{\\partial s_i}\n\\] I ovenstående udtryk bliver det klart, at opdateringsreglerne vil blive ens bortset fra den sidste faktor.\nNu udledes alle de partielle afledede, fuldstændig som for \\(r\\)-vægtene og vi ender med følgende opdateringsregler for \\(s\\)-vægtene:\n\n\n\n\n\n\nOpdateringsregler for \\(s\\)-vægtene\n\n\n\n\\[\\begin{align}\ns_0 &\\leftarrow s_0 +  \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2) \\\\\ns_1 &\\leftarrow s_1 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2) \\cdot x_1\\\\\ns_2 &\\leftarrow s_2 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2)  \\cdot x_2\\\\\ns_3 &\\leftarrow s_3 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2)  \\cdot x_3\\\\\ns_4 &\\leftarrow s_4 + \\eta \\cdot \\delta \\cdot \\Big(w_1 \\cdot z_1\\cdot (1-z_1)\\cdot v_2+w_2 \\cdot z_2 \\cdot (1-z_2)\\cdot  u_2 \\Big) \\cdot y_2\\cdot (1-y_2)  \\cdot x_4\\\\\n\\end{align}\\] hvor \\[\n\\delta = (t-o) \\cdot o \\cdot (1-o)\n\\]\n\n\nDet var faktisk det! Altså det blev jo en værre omgang bogstavgymnastik, men faktum er, at vi er i mål med at udlede backpropagation algoritmen for vores simple netværk i figur 4. Hurra for det!"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-7",
    "href": "materialer/neurale_net/neurale_net.html#video-kunstige-neurale-netværk-7",
    "title": "Kunstige neurale netværk",
    "section": "VIDEO: Kunstige neurale netværk 7",
    "text": "VIDEO: Kunstige neurale netværk 7\nI denne video forklares hvordan \\(r\\)-vægtene opdateres."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-feedforward_indekser",
    "href": "materialer/neurale_net/neurale_net.html#sec-feedforward_indekser",
    "title": "Kunstige neurale netværk",
    "section": "Feedforward med indekser",
    "text": "Feedforward med indekser\nVi vil nu se på, hvordan de forskellige \\(a_j^{(k)}\\)-værdier beregnes. Det vil sige, at vi altså skal se på, hvordan de forskellige feedforward-ligninger ser ud med vores nye notation.\n\n\n\n\n\n\nFigur 9: Udregning af \\(a_1^{(2)}\\).\n\n\n\nLad os se på et konkret eksempel, så bliver det lidt nemmere at forholde sig til. Vi starter med at udregne outputværdien \\(a_1^{(2)}\\) for den første neuron i det andet lag. Denne neuron får input fra alle neuroner i det foregående lag (som her er inputlaget). Bruger vi den notation for vægtene, som vi lige har indført, så starter vi med at beregne: \\[\nz_1^{(2)} = w_{11}^{(2)} \\cdot x_1 + w_{12}^{(2)} \\cdot x_2 + w_{13}^{(2)} \\cdot x_3 + w_{14}^{(2)} \\cdot x_4 + b_1^{(2)}\n\\] Der er to ting at bemærke her: 1) Vi vælger, at kalde udtrykket på højreside for \\(z_1^{(2)}\\) og, 2) vi har kaldt biasen for \\(b_1^{(2)}\\).\nBruger vi nu de mere generelle udtryk for inputværdierne \\(a_1^{(1)}, a_2^{(1)}, \\dots, a_4^{(1)}\\) kan vi skrive: \\[\\begin{align}\nz_1^{(2)} &= w_{11}^{(2)} \\cdot a_1^{(1)} + w_{12}^{(2)} \\cdot a_2^{(1)} + w_{13}^{(2)} \\cdot a_3^{(1)} + w_{14}^{(2)} \\cdot a_4^{(1)} + b_1^{(2)} \\\\\n&= \\sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)}\n\\end{align}\\] Og endelig finder vi outputværdien \\(a_1^{(2)}\\) for den første neuron i det andet lag ved som tidligere at anvende sigmoid-funktionen på ovenstående udtryk: \\[\\begin{align}\na_1^{(2)} &= \\sigma(z_1^{(2)}) \\\\\n&= \\sigma \\left( \\sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)} \\right)\n\\end{align}\\] Det her er faktisk notationsmæssigt selve idéen. Folder vi det ud til hele det andet lag får vi derfor:\n\n\n\n\n\n\nFeedforwardligninger til lag 2\n\n\n\nBeregn først: \\[\\begin{align}\nz_1^{(2)} &= \\sum_{i=1}^{4} w_{1i}^{(2)} a_i^{(1)} +  b_1^{(2)} \\\\\n& \\\\\nz_2^{(2)} &=\\sum_{i=1}^{4} w_{2i}^{(2)} a_i^{(1)} +  b_2^{(2)} \\\\\n& \\\\\nz_3^{(2)} &= \\sum_{i=1}^{4} w_{3i}^{(2)} a_i^{(1)} +  b_3^{(2)} \\\\\n\\end{align}\\] Outputværdierne for neuroner i det andet lag udregnes dernæst på denne måde: \\[\\begin{align}\na_1^{(2)} &= \\sigma(z_1^{(2)}) \\\\\n& \\\\\na_2^{(2)} &= \\sigma(z_2^{(2)}) \\\\\n&\\\\\na_3^{(2)} &= \\sigma(z_3^{(2)}) \\\\\n\\end{align}\\]\n\n\nOg vover vi pelsen, kan vi helt generelt skrive:\n\n\n\n\n\n\nFeedforward-ligninger til lag 2\n\n\n\nBeregn først: \\[\\begin{align}\nz_j^{(2)} = \\sum_{i=1}^{4} w_{ji}^{(2)} a_i^{(1)} +  b_j^{(2)}\n\\end{align}\\] Outputværdierne for neuroner i det andet lag udregnes dernæst på denne måde: \\[\\begin{align}\na_j^{(2)} &= \\sigma(z_j^{(2)})\n\\end{align}\\] for \\(j \\in \\{1, 2, 3 \\}\\).\n\n\nFordelen ved denne notation er, at det nu er utrolig nemt at opskrive feedforward-ligningerne for lag 3 og 4 - det er blot nogle indekser, som skal ændres lidt. I det tredje lag er der to neuroner, hvis outputværdier beregnes på denne måde:\n\n\n\n\n\n\nFeedforward-ligninger til lag 3\n\n\n\nBeregn først: \\[\nz_j^{(3)} = \\sum_{i=1}^{3} w_{ji}^{(3)} a_i^{(2)} +  b_j^{(3)}\n\\tag{20}\\] Outputværdierne for neuroner i det tredje lag udregnes dernæst på denne måde: \\[\\begin{align}\na_j^{(3)} &= \\sigma(z_j^{(3)})\n\\end{align}\\] for \\(j \\in \\{1, 2 \\}\\).\n\n\nOg endelig beregnes outputtet fra hele netværket i det fjerde lag:\n\n\n\n\n\n\nFeedforward-ligninger til lag 4\n\n\n\nUdregn først: \\[\nz_j^{(4)} = \\sum_{i=1}^{2} w_{ji}^{(4)} a_i^{(3)} +  b_j^{(4)}\n\\tag{21}\\] Outputværdierne for neuroner i det tredje lag udregnes dernæst på denne måde: \\[\\begin{align}\ny_j = a_j^{(4)} &= \\sigma(z_j^{(4)})\n\\end{align}\\] for \\(j \\in \\{1, 2, 3 \\}\\).\n\n\nDet fremgår nu tydeligt, at feedforward-ligningerne er på fuldstændig samme form, og vi vil derfor helt generelt kunne skrive:\n\n\n\n\n\n\nFeedforward-ligninger generelt\n\n\n\nBeregn først: \\[\\begin{align}\nz_j^{(k)} = \\sum_{i} w_{ji}^{(k)} a_i^{(k-1)} +  b_j^{(k)}\n\\end{align}\\] Outputværdierne for neuroner i det \\(k\\)’te lag udregnes dernæst på denne måde: \\[\\begin{align}\na_j^{(k)} &= \\sigma(z_j^{(k)})\n\\end{align}\\] for \\(k \\in \\{2, 3, 4 \\}\\).\n\n\nNår man bruger feedforward, starter man altså med at udregne outputværdierne for det første skjulte lag, dernæst for det andet skjulte lag og så videre, indtil man når til outputværdierne for selve netværket (deraf navnet: feedforward ). Bemærk her, at det ikke giver mening at udregne \\(a_j^{(1)}\\), fordi det svarer til inputværdierne til netværket."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#sec-backpropagation_indekser",
    "href": "materialer/neurale_net/neurale_net.html#sec-backpropagation_indekser",
    "title": "Kunstige neurale netværk",
    "section": "Backpropagation med indekser",
    "text": "Backpropagation med indekser\nLad os nu se på hvordan backpropagation fungerer. Vi skal altså have opskrevet vores opdateringsregler med den nye notation, og vi vil gribe det an, ligesom vi gjorde det i afsnit 4. Nemlig ved at starte i det sidste lag (her lag \\(4\\)) og finde opdateringsreglerne for de vægte og bias, som har direkte indflydelse på outputværdierne fra lag \\(4\\).\n\nOpdateringsregler for lag \\(4\\)\nVi er altså i første omgang på jagt efter \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(4)}},\n\\] for \\(j \\in \\{1, 2, 3\\}\\), \\(i \\in \\{1, 2\\}\\). Tabsfunktionen \\(E\\), som hører til netværket i figur 7, bliver her: \\[\nE=\\frac{1}{2} \\sum_{j=1}^3 \\left( t_j-y_j \\right)^2 = \\frac{1}{2} \\sum_{j=1}^3 \\left( t_j-a_j^{(4)} \\right)^2\n\\tag{22}\\] hvor igen \\(t_j\\) er den ønskede target-værdi for den \\(j\\)’te outputneuron.\nLad os starte med at bestemme \\(\\frac{\\partial E}{\\partial w_{ji}^{(4)}}\\). Vi må derfor først se på, hvordan \\(w_{ji}^{(4)}\\) påvirker tabsfunktionen \\(E\\). Da \\(w_{ji}^{(4)}\\) kun indgår i udtrykket for beregningen af \\(z_j^{(4)}\\), som igen bruges til beregningen af \\(a_j^{(4)}\\), som dernæst direkte påvirker tabsfunktionen, kan vi skrive: \\[\nw_{ji}^{(4)} \\rightarrow z_j^{(4)} \\rightarrow a_j^{(4)} \\rightarrow E\n\\] Bruger vi først kædereglen én gang, får vi derfor \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} = \\frac{\\partial E}{\\partial z_j^{(4)}} \\cdot \\frac{\\partial z_j^{(4)}}{\\partial w_{ji}^{(4)}}\n\\tag{23}\\] og bruges kædereglen igen, kan første faktor udfoldes yderligere \\[\n\\frac{\\partial E}{\\partial z_j^{(4)}} = \\frac{\\partial E}{\\partial a_j^{(4)}} \\cdot  \\frac{\\partial a_j^{(4)}}{\\partial z_j^{(4)}}\n\\] Lad os starte med at udregne \\(\\frac{\\partial E}{\\partial z_j^{(4)}}\\) ved at udregne hver faktor på højresiden i ovenstående udtryk for sig. Fra (22) får vi, at \\[\nE=\\frac{1}{2} \\sum_{j=1}^3 \\left( t_j-a_j^{(4)} \\right)^2 = \\frac{1}{2} \\left( \\left( t_1-a_1^{(4)} \\right)^2 + \\left( t_2-a_2^{(4)} \\right)^2+ \\left( t_3-a_3^{(4)}\\right)^2 \\right)\n\\] Hvis vi f.eks. skal differentiere ovenstående med hensyn til \\(a_2^{(4)}\\), kan vi se at alle de led, som ikke indeholder \\(a_2^{(4)}\\), vil være at betragte som konstanter, når vi differentierer - og når vi differentierer konstanter, får vi som bekendt \\(0\\). Derfor får vi, at \\[\n\\frac{\\partial E}{\\partial a_2^{(4)}} = \\frac{1}{2}\\cdot 2 \\cdot (t_2-a_2^{(4)})\\cdot (-1) = -(t_2-a_2^{(4)})\n\\] På tilsvarende vis har vi derfor generelt, at \\[\n\\frac{\\partial E}{\\partial a_j^{(4)}} = -(t_j-a_j^{(4)})\n\\tag{24}\\] Vi ved også, at \\[\na_j^{(4)} = \\sigma(z_j^{(4)})\n\\] Og bruger vi endnu en gang resultatet fra sætning 1 får vi, at \\[\n\\frac{\\partial a_j^{(4)}}{\\partial z_j^{(4)}}  = \\sigma'(z_j^{(4)})= \\sigma(z_j^{(4)}) \\cdot (1-\\sigma(z_j^{(4)}))= a_j^{(4)}\\cdot (1-a_j^{(4)})\n\\tag{25}\\] Indtil videre har vi altså, at \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(4)}} &= \\frac{\\partial E}{\\partial a_j^{(4)}} \\cdot  \\frac{\\partial a_j^{(4)}}{\\partial z_j^{(4)}} \\\\\n&=-(t_j-a_j^{(4)}) \\cdot  a_j^{(4)}\\cdot (1-a_j^{(4)})\n\\end{align}\\] I forhold til det videre arbejde viser det sig hensigtsmæssigt, at lave en samlet betegnelse for \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(4)}}  \n&=-(t_j-a_j^{(4)}) \\cdot  a_j^{(4)}\\cdot (1-a_j^{(4)})\n\\end{align}\\] Vi sætter derfor \\[\n\\delta_j^{(4)} = \\frac{\\partial E}{\\partial z_j^{(4)}}  = -(t_j-a_j^{(4)}) \\cdot a_j^{(4)} \\cdot (1-a_j^{(4)})\n\\] Udtrykket \\(\\delta_j^{(4)}\\) kalder man også for fejlleddet for det fjerde lag, men det kommer vi tilbage til senere.\nVi har nu fundet den første faktor i (23), og mangler derfor kun at bestemme \\(\\frac{\\partial z_j^{(4)}}{\\partial w_{ji}^{(4)}}\\). Bruger vi (21) ser vi, at \\[\nz_j^{(4)} =  \\sum_{i=1}^{2} w_{ji}^{(4)} a_i^{(3)} +  b_j^{(4)}  =\nw_{j1}^{(4)} a_1^{(3)}+ w_{j2}^{(4)} a_2^{(3)} +  b_j^{(4)}\n\\] Skal vi f.eks. differentiere dette udtryk med hensyn til \\(w_{j1}^{(4)}\\), får vi (fordi de fleste led i ovenstående, vil være at betragte som konstanter) \\[\n\\frac{\\partial z_j^{(4)}}{\\partial w_{j1}^{(4)}} =  a_1^{(3)}\n\\] Og helt tilsvarende hvis vi differentierer med hensyn til \\(w_{j2}^{(4)}\\), får vi \\[\n\\frac{\\partial z_j^{(4)}}{\\partial w_{j2}^{(4)}} =  a_2^{(3)}\n\\] Generelt har vi derfor, at \\[\n\\frac{\\partial z_j^{(4)}}{\\partial w_{ji}^{(4)}} = a_i^{(3)}\n\\tag{26}\\]\nSamler vi nu de tre udtryk, som vi netop har udledt og indsætter i (23) får vi \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} =  -(t_j-a_j^{(4)}) \\cdot a_j^{(4)} \\cdot (1-a_j^{(4)}) \\cdot a_i^{(3)}\n\\] og med den lidt kortere notation, som vi indførte ovenfor, kan vi nu skrive \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(4)}} =  \\delta_j^{(4)} \\cdot a_i^{(3)}\n\\] For at finde opdateringsreglerne for biasene, må vi først bestemme de partielle afledede af \\(E\\) med hensyn til \\(b_j^{(4)}\\). På helt tilsvarende vis får vi, at \\[\n\\frac{\\partial E}{\\partial b_j^{(4)}} = \\frac{\\partial E}{\\partial z_j^{(4)}} \\cdot \\frac{\\partial z_j^{(4)}}{\\partial b_j^{(4)}}\n\\] Vi ved allerede, at \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(4)}}  = \\delta_j^{(4)}\n\\end{align}\\] og ser man på ligningen i (21), ses det nemt, at \\[\n\\frac{\\partial z_j^{(4)}}{\\partial b_j^{(4)}} = 1\n\\] og derfor har vi, at \\[\n\\frac{\\partial E}{\\partial b_j^{(4)}}  =\\delta_j^{(4)}\n\\] Opdateringsreglerne for de vægte og bias, som hører til outputlaget (lag \\(4\\)) er derfor \\[\nw_{ji}^{(4)} \\leftarrow w_{ji}^{(4)} - \\eta \\cdot \\frac{\\partial E}{\\partial w_{ji}^{(4)}} = w_{ji}^{(4)} - \\eta \\cdot \\delta_j^{(4)} \\cdot a_i^{(3)}\n\\] og \\[\nb_j^{(4)} \\leftarrow b_j^{(4)} - \\eta \\cdot \\frac{\\partial E}{\\partial b_j^{(4)}}  = b_j^{(4)} - \\eta \\cdot \\delta_j^{(4)}\n\\] Vi kan altså opsummere:\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i outputlaget (lag 4)\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\nw_{ji}^{(4)} \\leftarrow w_{ji}^{(4)} - \\eta \\cdot \\delta_j^{(4)} \\cdot a_i^{(3)}\n\\] Biasene i outputlaget opdateres på denne måde: \\[\nb_j^{(4)} \\leftarrow b_j^{(4)} - \\eta \\cdot \\delta_j^{(4)}\n\\] hvor \\[\n\\delta_j^{(4)} = \\frac{\\partial E}{\\partial z_j^{(4)}}= -(t_j-a_j^{(4)}) \\cdot a_j^{(4)} \\cdot (1-a_j^{(4)})\n\\tag{27}\\]\n\n\nUdtrykket \\(\\delta_j^{(4)}\\) kalder man, som nævnt tidligere, også for fejlleddet i den \\(j\\)’te række i det fjerde lag, og man kan se på ovenstående opdateringsregler, at dette fejlled netop indgår i opdateringen af både vægtene og biasene. Faktisk kan vi, præcis som vi gjorde det tidligere, tillægge dette fejlled en intuitiv god mening. Det kommer vi tilbage til igen senere!\nBemærk, at hvis vi i vores netværk starter med at vælge mere eller mindre tilfældige vægte, så kan vi på baggrund af dem bruge feedforwardligningerne til at udregne, \\(a_j^{(4)}\\)- og \\(a_i^{(3)}\\)- værdierne. Samtidig kender vi target-værdierne \\(t_j\\), og vi kan derfor også udregne fejlleddene \\(\\delta_j^{(4)}\\). Vi har altså alt, hvad vi skal bruge for at benytte ovenstående opdateringsregler.\n\n\nOpdateringsregler for lag \\(3\\)\nVi bevæger os nu et trin længere bagud i netværket og udleder opdateringsreglerne for det næstsidste lag - lag \\(3\\). Altså skal vi have bestemt \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(3)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(3)}},\n\\] for \\(j \\in \\{1, 2\\}\\), \\(i \\in \\{1, 2, 3\\}\\). Vi må igen se på, hvordan \\(w_{ji}^{(3)}\\) påvirker tabsfunktionen \\(E\\). Ser vi på figur figur 7, kan vi se, at \\(w_{ji}^{(3)}\\) direkte påvirker \\(z_j^{(3)}\\), som igen direkte påvirker \\(a_j^{(3)}\\). Nu vil den \\(j\\)’te neuron i det tredje lag fyre værdien \\(a_j^{(3)}\\) til alle neuroner i det fjerde lag. Altså vil \\(a_j^{(3)}\\) påvirke \\(z_1^{(4)}, z_2^{(4)}\\) og \\(z_3^{(4)}\\), som bruges til beregning af \\(a_1^{(4)}, a_2^{(4)}\\) og \\(a_3^{(4)}\\), som så igen vil påvirke tabsfunktionen \\(E\\). Det kan illustreres på denne måde \\[\n\\begin{matrix}\n& & & & z_1^{(4)} \\rightarrow a_1^{(4)} & & \\\\\n& & & \\nearrow  & &  \\searrow & \\\\\nw_{ji}^{(3)} & \\rightarrow & z_j^{(3)} \\rightarrow a_j^{(3)} & \\rightarrow &\nz_2^{(4)} \\rightarrow a_2^{(4)} & \\rightarrow & E \\\\\n& & & \\searrow & &  \\nearrow &  \\\\\n& & & & z_3^{(4)} \\rightarrow a_3^{(4)} & & \\\\\n\\end{matrix}\n\\] I første omgang kan vi skrive \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(3)}} = \\frac{\\partial E}{\\partial z_j^{(3)}} \\cdot \\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}}\n\\tag{28}\\] og så gentagne gange bruge kædereglen til at udfolde dette udtryk.\nLad os starte med det nemmeste, nemlig \\(\\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}}\\). Ser vi på definitionen af \\(z_j^{(3)}\\) i (20), kan vi argumentere helt tilsvarende, som da vi ovenfor udledte udtrykket i (26) og får \\[\n\\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}} = a_i^{(2)}\n\\]\nLad os nu kaste os over den første faktor i (28). Vi kan starte med at udnytte denne lidt overordnede måde, som \\(z_j^{(3)}\\) påvirker \\(E\\) på \\[\nz_j^{(3)} \\rightarrow a_j^{(3)} \\rightarrow E\n\\] Kædereglen giver os derfor i første omgang \\[\n\\frac{\\partial E}{\\partial z_j^{(3)}} = \\frac{\\partial E}{\\partial a_j^{(3)}} \\cdot\n\\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}}\n\\tag{29}\\] Igen er sidste faktor nem nok, idet \\[\na_j^{(3)} = \\sigma (z_j^{(3)})\n\\] og derfor er \\[\n\\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}} = \\sigma' (z_j^{(3)})=\\sigma(z_j^{(3)})\\cdot (1-\\sigma(z_j^{(3)}))= a_j^{(3)} \\cdot (1-a_j^{(3)}),\n\\] hvor vi endnu en gang har benyttet sætning 1.\nNår vi skal bestemme \\(\\frac{\\partial E}{\\partial a_j^{(3)}}\\) kommer vi ikke udenom kædereglen for funktioner af flere variable. Det bliver tydeligt, når vi zoomer ind på hvordan \\(a_j^{(3)}\\) påvirker \\(E\\): \\[\n\\begin{matrix}\n  & & z_1^{(4)} \\rightarrow a_1^{(4)} & & \\\\\n  & \\nearrow  & &  \\searrow & \\\\\n  a_j^{(3)} & \\rightarrow &\nz_2^{(4)} \\rightarrow a_2^{(4)} & \\rightarrow & E \\\\\n& \\searrow & &  \\nearrow &  \\\\\n& & z_3^{(4)} \\rightarrow a_3^{(4)} & & \\\\\n\\end{matrix}\n\\] For at vi senere kan udnytte nogle af de ligninger, som vi udledte i lag \\(4\\), vil vi faktisk bare nøjes med at se på det, på denne måde: \\[\n\\begin{matrix}\n  & & z_1^{(4)} & & \\\\\n  & \\nearrow  & &  \\searrow & \\\\\n  a_j^{(3)} & \\rightarrow &\nz_2^{(4)} & \\rightarrow & E \\\\\n& \\searrow & &  \\nearrow &  \\\\\n& & z_3^{(4)}  & & \\\\\n\\end{matrix}\n\\] Nu er vi endelig klar til at bruge kædereglen for funktioner af flere variable: \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(3)}} &=  \\frac{\\partial E}{\\partial z_1^{(4)}} \\cdot \\frac{\\partial z_1^{(4)}}{\\partial a_j^{(3)}}  + \\frac{\\partial E}{\\partial z_2^{(4)}} \\cdot \\frac{\\partial z_2^{(4)}}{\\partial a_j^{(3)}} + \\frac{\\partial E}{\\partial z_3^{(4)}} \\cdot \\frac{\\partial z_3^{(4)}}{\\partial a_j^{(3)}} \\\\\n&= \\sum_{k=1}^{3}\\frac{\\partial E}{\\partial z_k^{(4)}} \\cdot \\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}  \n\\end{align}\\] Se nu dukker der noget op, som vi har set før! Nemlig det fejlled, som vi definerede i (27), og som vi allerede har regnet ud, da vi opdaterede vægtene og biasene i lag \\(4\\). Tænk lige over det - det er faktisk ret fedt! Dvs. at vi kan skrive: \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial a_j^{(3)}} &= \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot \\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}  \n\\end{aligned}\n\\tag{30}\\] Så mangler vi kun lige at finde \\(\\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}\\)! Fra (21) har vi, at \\[\nz_k^{(4)} = \\sum_i w_{ki}^{(4)} a_i^{(3)}+b_k^{(4)}\n\\] så \\[\n\\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}} = \\frac{\\partial}{\\partial a_j^{(3)}} \\left(\\sum_i w_{ki}^{(4)} a_i^{(3)}+b_k^{(4)} \\right)\n\\] Når vi skal differentierer summen i ovenstående udtryk, får vi kun et led med, når \\(i=j\\), fordi i alle andre tilfælde, vil vi med hensyn til \\(a_j^{(3)}\\) skulle differentiere en konstant. Og da \\[\n\\frac{\\partial}{\\partial a_j^{(3)}}\\left ( w_{kj}^{(4)} a_j^{(3)} \\right) = w_{kj}^{(4)}\n\\] har vi altså, at \\[\n\\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}} = w_{kj}^{(4)}\n\\] Indsætter vi dette i (30), har vi nu \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(3)}} = \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot \\frac{\\partial z_k^{(4)}}{\\partial a_j^{(3)}}  = \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot w_{kj}^{(4)}\n\\end{align}\\]\nNu skal vi i første omgang tilbage til (29) og indsætte det vi netop er kommet frem til: \\[\\begin{align}\n\\frac{\\partial E}{\\partial z_j^{(3)}}=\\underbrace{\\left ( \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot w_{kj}^{(4)}\\right )}_{\\frac{\\partial E}{\\partial a_j^{(3)}}}\n\\cdot \\underbrace{a_j^{(3)} \\cdot (1-a_j^{(3)})}_{\\frac{\\partial a_j^{(3)}}{\\partial z_j^{(3)}}}\n\\end{align}\\] Som vi gjorde i afsnit 5.2.1, vil vi også give dette lidt lange udtryk en særlig betegnelse, nemlig \\[\\begin{align}\n\\delta_j^{(3)} = \\frac{\\partial E}{\\partial z_j^{(3)}}=\\left ( \\sum_{k=1}^{3} \\delta_k^{(4)} \\cdot w_{kj}^{(4)}\\right )\n\\cdot a_j^{(3)} \\cdot (1-a_j^{(3)})\n\\end{align}\\] Det kan vist godt være lidt svært at bevare overblikket her, men nu er vi faktisk i mål! Vi indsætter i (28) \\[\\begin{align}\n\\frac{\\partial E}{\\partial w_{ji}^{(3)}} &= \\frac{\\partial E}{\\partial z_j^{(3)}} \\cdot \\frac{\\partial z_j^{(3)}}{\\partial w_{ji}^{(3)}} \\\\\n&= \\delta_j^{(3)} \\cdot a_i^{(2)}\n\\end{align}\\]\nDet er nu en smal sag at bestemme \\(\\frac{\\partial E}{\\partial b_j^{(3)}}\\), da \\[\\begin{align}\n\\frac{\\partial E}{\\partial b_j^{(3)}} &= \\frac{\\partial E}{\\partial z_j^{(3)}} \\cdot \\frac{\\partial z_j^{(3)}}{\\partial b_j^{(3)}} \\\\ &= \\delta_j^{(3)}\\cdot \\frac{\\partial z_j^{(3)}}{\\partial b_j^{(3)}}\n\\end{align}\\] Fra (20) har vi, at \\[\nz_j^{(3)} = \\sum_{i=1}^3 w_{ji}^{(3)} a_i^{(2)} + b_j^{(3)}\n\\] og derfor er \\[\n\\frac{\\partial z_j^{(3)}}{\\partial b_j^{(3)}} = 1\n\\] Altså får vi \\[\\begin{align}\n\\frac{\\partial E}{\\partial b_j^{(3)}} = \\delta_j^{(3)}\n\\end{align}\\] Glæden er stor, da vi nu har alle ingredienser til at opskrive opdateringsreglerne for det tredje lag!\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i lag 3\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\nw_{ji}^{(3)} \\leftarrow w_{ji}^{(3)} - \\eta \\cdot \\delta_j^{(3)} \\cdot a_i^{(2)}\n\\] Biasene i outputlaget opdateres på denne måde: \\[\nb_j^{(3)} \\leftarrow b_j^{(3)} - \\eta \\cdot \\delta_j^{(3)}\n\\] hvor \\[\n\\delta_j^{(3)} = \\frac{\\partial E}{\\partial z_j^{(3)}}=\\left( \\sum_{k=1}^{3}\\delta_k^{(4)} \\cdot w_{kj}^{(4)}   \\right) \\cdot a_j^{(3)} \\cdot (1-a_j^{(3)})\n\\tag{31}\\]\n\n\nBemærk, at udgangspunktet for ovenstående er, at vi først har lavet et feedforward i netværket, så vi har alle \\(a_i^{(2)}\\)- og \\(a_j^{(3)}\\)-værdier. Derudover har vi allerede opdateret vægtene og biasene i lag \\(4\\). Derfor kender vi også fejleddene \\(\\delta_k^{(4)}\\) fra lag \\(4\\), som indgår i beregningen af \\(\\delta_j^{(3)}\\) i (31). Altså er det muligt at foretage de beregninger, som opdateringsreglerne i lag \\(3\\) kræver.\n\n\nOpdateringsregler for lag \\(2\\)\nVi er nu fremme ved det sidste lag, hvor vi skal have opdateret vægte og bias (husk på at \\(a_i^{(1)}\\)-værdierne jo ikke skal beregnes, men er inputværdierne til netværket). Den gode nyhed her er, at der absolut intet nyt er under solen! Vi vil derfor heller ikke gå i drabelige deltaljer med alle udregninger her, men blot skitsere idéen.\nVi er nu på jagt efter \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(2)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(2)}}\n\\] og kigger vi på vores netværk i figur 7 kan vi se følgende afhængigheder: \\[\n\\begin{matrix}\n& & & & z_1^{(3)}  & & \\\\\n& & & \\nearrow  & &  \\searrow & \\\\\nw_{ji}^{(2)} & \\rightarrow & z_j^{(2)} \\rightarrow a_j^{(2)} &  &  &  & E \\\\\n& & & \\searrow & &  \\nearrow &  \\\\\n& & & & z_2^{(3)} & & \\\\\n\\end{matrix}\n\\] Vi kan nu igen skrive \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(2)}} = \\frac{\\partial E}{\\partial z_j^{(2)}} \\cdot \\frac{\\partial z_j^{(2)}}{\\partial w_{ji}^{(2)}}\n\\tag{32}\\] Helt analogt til tidligere ses det nemt, at \\[\n\\frac{\\partial z_j^{(2)}}{\\partial w_{ji}^{(2)}} = a_i^{(1)}\n\\] og kædreglen giver igen, at \\[\n\\frac{\\partial E}{\\partial z_j^{(2)}}= \\frac{\\partial E}{\\partial a_j^{(2)}} \\cdot\n\\frac{\\partial a_j^{(2)}}{\\partial z_j^{(2)}}\n\\tag{33}\\] Her fås også uden problemer, at den sidste faktor kan skrives som \\[\n\\frac{\\partial a_j^{(2)}}{\\partial z_j^{(2)}} = a_j^{(2)} \\cdot (1-a_j^{(2)})\n\\] og bruger man kædereglen for funktioner af flere variable, kommer man frem til, at \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(2)}} &= \\sum_{k=1}^2 \\frac{\\partial E}{\\partial z_k^{(3)}}\n\\cdot \\frac{\\partial  z_k^{(3)}}{\\partial a_j^{(2)}} \\\\\n&= \\sum_{k=1}^2  \\delta_k^{(3)} w_{kj}^{(3)},\n\\end{align}\\] hvor vi allerede har udregnet \\(\\delta_k^{(3)}\\), da vi opdaterede vægtene og biasene i lag \\(3\\).\nIndsætter vi i (33) og samtidig definerer fejlleddet \\(\\delta_j^{(2)}\\) for det andet lag, får vi \\[\n\\delta_j^{(2)} = \\frac{\\partial E}{\\partial z_j^{(2)}} = \\left ( \\sum_{k=1}^2  \\delta_k^{(3)} w_{kj}^{(3)} \\right ) \\cdot a_j^{(2)} \\cdot (1-a_j^{(2)})\n\\] Alt i alt ender vi med \\[\\begin{align}\n\\frac{\\partial E}{\\partial w_{ji}^{(2)}} &= \\delta_j^{(2)} \\cdot a_i^{(1)} \\\\\n&= \\delta_j^{(2)} \\cdot x_i\n\\end{align}\\] fordi alle \\(a_i^{(1)}\\)-værdierne svarer til selve inputværdierne \\(x_i\\) til netværket.\nDet er nu ikke svært at se, at \\[\n\\frac{\\partial E}{\\partial b_j^{(2)}} = \\delta_j^{(2)}\n\\] og vi får derfor følgende opdateringsregler for lag 2:\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i lag 2\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(2)} \\leftarrow w_{ji}^{(2)} - \\eta \\cdot \\delta_j^{(2)} \\cdot a_i^{(1)}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(2)} \\leftarrow b_j^{(2)} - \\eta \\cdot \\delta_j^{(2)}\n\\end{align}\\] hvor \\[\n\\delta_j^{(2)} = \\frac{\\partial E}{\\partial z_j^{(2)}}= \\left ( \\sum_{k=1}^2  \\delta_k^{(3)} w_{kj}^{(3)} \\right ) \\cdot a_j^{(2)} \\cdot (1-a_j^{(2)})\n\\tag{34}\\]"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#var-det-så-egentlig-smart-med-alle-de-indekser",
    "href": "materialer/neurale_net/neurale_net.html#var-det-så-egentlig-smart-med-alle-de-indekser",
    "title": "Kunstige neurale netværk",
    "section": "Var det så egentlig smart med alle de indekser?",
    "text": "Var det så egentlig smart med alle de indekser?\nHvis man er nået hertil, kan man godt følge sig en lille smule forpustet. Der har godt nok været mange indekser at holde styr på! Både nogle der var sænkede, og nogle der var hævede og sat i parenteser! Alligevel kan man måske godt se fidusen nu.\nHvis vi ser på de opdateringsregler, som vi lige har udledt, så kan man se, at selve opdateringsreglerne af vægte og bias følger præcis samme form. Faktisk kan man, hvis man sammenligner opdateringsreglerne for de tre lag se, at opdateringsreglerne er på denne form:\n\n\n\n\n\n\nGenerelle opdateringsregler til vægte og bias\n\n\n\nVægtene opdateres generelt på denne måde: \\[\\begin{align}\nw_{ji}^{(\\text{lag})} \\leftarrow w_{ji}^{(\\text{lag})} - \\eta \\cdot \\delta_j^{(\\text{lag})} \\cdot a_i^{(\\text{lag-1})}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(\\text{lag})} \\leftarrow b_j^{(\\text{lag})} - \\eta \\cdot \\delta_j^{(\\text{lag})}\n\\end{align}\\]\n\n\nBemærk her, at da vi allerede har lavet en feedforward i netværket, så kender vi outputværdierne \\(a_i^{(\\text{lag})}\\) i alle lag. Det vil sige, at vi kan opdatere vægtene og biasene, når blot vi kan beregne fejlleddene.\nDen eneste reelle forskel på opdateringsreglerne er, at fejlleddene udregnes lidt forskelligt, alt efter om der er tale om outputlaget eller et skjult lag:\n\n\n\n\n\n\nBeregning af fejlleddene\n\n\n\nFejlleddene i outputlaget beregnes på denne måde: \\[\\begin{align}\n\\delta_j^{(\\text{outputlag})} = -(t_j-y_j) \\cdot y_j \\cdot (1-y_j),\n\\end{align}\\] idet outputværdierne fra netværket netop er \\(y_1, y_2, \\dots\\).\nFejlleddene i et skjult lag beregnes på denne måde: \\[\\begin{align}\n\\delta_j^{(\\text{lag})} = \\left ( \\sum_{k}  \\delta_k^{(\\text{lag+1})} w_{kj}^{(\\text{lag+1})} \\right ) \\cdot a_j^{(\\text{lag})} \\cdot (1-a_j^{(\\text{lag})})\n\\end{align}\\]\n\n\nBemærk her, at fejlleddene fra outputlaget uden videre kan beregnes, da vi kender target-værdierne \\(t_j\\) og outputværdierne \\(y_j\\) fra netværket (fordi vi allerede har lavet en feedforward). Vi kan også beregne fejlleddene i alle skjulte lag, idet vi hele tiden arbejder bagud i netværket (backpropagation). Det vil sige, at vi hele tiden har adgang til fejlleddene i laget længere fremme (lag+1), hvor (lag+1) første gang vil svare til outputlaget. Desuden kender vi pga. feedforward alle outputværdier \\(a_j^{(\\text{(lag)})}\\) og alle vægte \\(w_{kj}^{(\\text{(lag+1)})}\\). Derfor kan vi også beregne fejlleddene i alle de skjulte lag.\nDenne indsigt og den generelle overordnede struktur på opdateringsreglerne, var meget svær at indse med fremgangsmåde i afsnit 4. Her druknede alt bare i et sandt bogstavshelvede!\nDer er et par andre interessante ting at sige om beregningen af fejlleddene. Lad os først se på outputlaget: \\[\n\\delta_j^{(\\text{outputlag})} = -(t_j-y_j) \\cdot y_j \\cdot (1-y_j)\n\\] Hvis der er stor forskel på target-værdien \\(t_j\\) og outputværdien \\(y_j\\), så bliver forskellen \\(t_j-y_j\\) numerisk stor. Altså vil en stor forskel på det, vi ønsker, og det vi får ud af netværket betyde, at fejlleddet bliver større og i sidste ende, at de vægte, som direkte påvirker outputtet, også vil blive opdateret meget. Endelig ser vi igen, at hvis outputneuronen er mættet (dvs. at \\(y_j\\) enten er tæt på \\(0\\) eller \\(1\\)), så vil fejlleddet ikke blive opdateret i samme grad, som hvis outputneuronen ikke havde været mættet (fordi hvis \\(y_j\\) enten er tæt på \\(0\\) eller \\(1\\), så vil \\(y_j \\cdot (1-y_j)\\) være tæt på \\(0\\)).\nVi ser altså, at fejlleddet fra det sidste lag direkte afhænger af hvor stor forskellen er på target-værdi og outputværdi.\nSer vi så på fejlleddene fra de skjulte lag: \\[\n\\delta_j^{(\\text{lag})} = \\left ( \\sum_{k}  \\delta_k^{(\\text{lag+1})} w_{kj}^{(\\text{lag+1})} \\right ) \\cdot a_j^{(\\text{lag})} \\cdot (1-a_j^{(\\text{lag})})\n\\] Så kan vi igen se, at hvis den tilhørende outputneuron, som fyrer værdien \\(a_j^{(\\text{lag})}\\), er mættet, så vil fejlleddet være tættere på \\(0\\), end hvis neuronen ikke havde været mættet. Samtidig kan vi også se, at der i fejlleddet indgår en vægtet sum af alle fejlleddene fra laget længere fremme: \\[\n\\sum_{k}  \\delta_k^{(\\text{lag+1})} w_{kj}^{(\\text{lag+1})}\n\\] På den måde vil store fejl i laget længere fremme også få indflydelse på fejlleddet i det nuværende lag."
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#backpropagation---generelt",
    "href": "materialer/neurale_net/neurale_net.html#backpropagation---generelt",
    "title": "Kunstige neurale netværk",
    "section": "Backpropagation - generelt",
    "text": "Backpropagation - generelt\nLad os så se på backpropagation. Vi ved fra det foregående, at der reelt set kun er to ting, vi skal gøre:\n\nFinde opdateringsreglerne for vægte og bias i outputlaget.\nFinde opdateringsreglerne for vægte og bias i et vilkårligt skjult lag.\n\n\nOpdateringsregler i outputlaget\nVores tabsfunktion er stadig \\[\nE= \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_i - a_i^{(K)} \\right )^2,\n\\] hvor \\(t_i\\) igen er targetværdierne. Vi skal bestemme \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(K)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(K)}}\n\\] Vi gør præcis som i afsnit 5.2.1. Vi indser først, at vi har denne direkte afhængighed fra \\(w_{ji}^{(K)}\\) til \\(E\\): \\[\nw_{ji}^{(K)} \\rightarrow z_j^{(K)} \\rightarrow a_j^{(K)} \\rightarrow E\n\\] Derfor får vi \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(K)}} = \\frac{\\partial E}{\\partial z_j^{(K)}} \\cdot \\frac{\\partial z_j^{(K)}}{\\partial w_{ji}^{(K)}}\n\\tag{37}\\] På grund af feedforwardligningen i (35) får vi for det første, at \\[\n\\frac{\\partial z_j^{(K)}}{\\partial w_{ji}^{(K)}} = a_i^{(K-1)}\n\\tag{38}\\] Nu bruger vi kædereglen til at bestemme \\[\n\\frac{\\partial E}{\\partial z_j^{(K)}} = \\frac{\\partial E}{\\partial a_j^{(K)}} \\cdot  \\frac{\\partial a_j^{(K)}}{\\partial z_j^{(K)}}\n\\tag{39}\\] På grund af feedforwardligningen i (36) og sætning 1 får vi sidste faktor til \\[\n\\frac{\\partial a_j^{(K)}}{\\partial z_j^{(K)}}  =  a_j^{(K)}\\cdot (1-a_j^{(K)})\n\\] Endelig får vi, ved at differentiere tabsfunktionen med hensyn til \\(a_j^{(K)}\\) \\[\n\\frac{\\partial E}{\\partial a_j^{(K)}} = -(t_j-a_j^{(K)})\n\\] Vi definerer nu igen fejlleddet for outputlaget \\(\\delta_j^{(K)}\\), som tidligere \\[\n\\delta_j^{(K)} = \\frac{\\partial E}{\\partial z_j^{(K)}}\n\\] og indsætter vi det, vi netop har udledt, i (39) får vi \\[\n\\delta_j^{(K)} =  -(t_j-a_j^{(K)}) \\cdot a_j^{(K)} \\cdot (1-a_j^{(K)})\n\\] Indsætter vi nu det hele i (37), har vi altså: \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(K)}} = \\delta_j^{(K)}  \\cdot a_i^{(K-1)}\n\\] Det er ikke svært at overbevise sig selv om, at \\[\n\\frac{\\partial E}{\\partial b_j^{(K)}} = \\delta_j^{(K)}\n\\] og derfor har vi:\n\n\n\n\n\n\nGenerelle opdateringsregler til vægte og bias i outputlaget (lag \\(K\\))\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(K)} \\leftarrow w_{ji}^{(K)} - \\eta \\cdot \\delta_j^{(K)} \\cdot a_i^{(K-1)}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(K)} \\leftarrow b_j^{(K)} - \\eta \\cdot \\delta_j^{(K)}\n\\end{align}\\] hvor \\[\\begin{align}\n\\delta_j^{(K)} = \\frac{\\partial E}{\\partial z_j^{(K)}}= -(t_j-a_j^{(K)}) \\cdot a_j^{(K)} \\cdot (1-a_j^{(K)})\n\\end{align}\\]\n\n\n\n\nOpdateringsregler i et vilkårligt skjult lag\nVi ser nu på et vilkårligt skjult lag \\(k\\), som hverken er inputlaget eller outputlaget. Det vil sige, at \\(k \\in \\{2, 3, \\dots, K-1 \\}\\). Vi antager, at vi har kørt backpropagation på alle lag, der ligger længere fremme i netværket, og specielt har vi altså beregnet fejlleddene i lag \\(k+1:\\) \\[\n\\delta_j^{(k+1)} = \\frac{\\partial E}{\\partial z_j^{(k+1)}}\n\\] Vi indser først, at vi har denne afhængighed fra \\(w_{ji}^{(k)}\\) til tabsfunktionen \\(E\\): \\[\n\\begin{matrix}\n& & & & z_1^{(k+1)}  & & \\\\\n& & & \\nearrow  & \\vdots &  \\searrow & \\\\\nw_{ji}^{(k)} & \\rightarrow & z_j^{(k)} \\rightarrow a_j^{(k)} & \\rightarrow  &  z_j^{(k+1)} & \\rightarrow  & E \\\\\n& & & \\searrow & \\vdots &  \\nearrow &  \\\\\n& & & & z_{n_{k+1}}^{(k+1)} & & \\\\\n\\end{matrix}\n\\tag{40}\\] Vi starter som tidligere med at bruge kædereglen én gang: \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} = \\frac{\\partial E}{\\partial z_j^{(k)}} \\cdot \\frac{\\partial z_j^{(k)}}{\\partial w_{ji}^{(k)}}\n\\tag{41}\\] Fra feedforwardligningen i (35) får vi for det første, at \\[\n\\frac{\\partial z_j^{(k)}}{\\partial w_{ji}^{(k)}} = a_i^{(k-1)}\n\\] Endnu en anvendelse af kædereglen, og hvor vi også i samme hug definerer fejlleddet \\(\\delta_j^{(k)}\\) for det \\(k\\)’te skjulte lag, giver: \\[\n\\delta_j^{(k)} = \\frac{\\partial E}{\\partial z_j^{(k)}}= \\frac{\\partial E}{\\partial a_j^{(k)}} \\cdot\n\\frac{\\partial a_j^{(k)}}{\\partial z_j^{(k)}}\n\\tag{42}\\] Den sidste partielle afledede kan vi udlede fra feedforwardligningen (36) og sætning 1: \\[\n\\frac{\\partial a_j^{(k)}}{\\partial z_j^{(k)}} = a_j^{(k)} \\cdot (1-a_j^{(k)})\n\\] For at beregne \\(\\frac{\\partial E}{\\partial a_j^{(k)}}\\) må vi have fat i kædereglen for funktioner af flere variable (se illustrationen i (40): \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(k)}} = \\sum_{i=1}^{n_{k+1}} \\frac{\\partial E}{\\partial z_i^{(k+1)}}\n\\cdot \\frac{\\partial  z_i^{(k+1)}}{\\partial a_j^{(k)}}\n\\end{align}\\] Vi udnytter nu, at vi allerede kender fejlleddene fra lag \\(k+1\\) og kan derfor omskrive til\n\\[\n\\frac{\\partial E}{\\partial a_j^{(k)}} = \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)}\n\\cdot \\frac{\\partial  z_i^{(k+1)}}{\\partial a_j^{(k)}}\n\\tag{43}\\]\nFra feedforwardligningen i (35) får vi, at \\(z_i^{(k+1)}\\) kan skrives som \\[\nz_i^{(k+1)} = \\sum_{j} w_{ij}^{(k+1)} a_j^{(k)} +  b_i^{(k+1)}\n\\] og derfor er \\[\\begin{align}\n\\frac{\\partial  z_i^{(k+1)}}{\\partial a_j^{(k)}} = w_{ij}^{(k+1)}\n\\end{align}\\] Indsætter vi i (43) fås \\[\\begin{align}\n\\frac{\\partial E}{\\partial a_j^{(k)}} = \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)}\n\\cdot w_{ij}^{(k+1)}\n\\end{align}\\] og ved indsættelse i (42) får vi nu fejlleddet i det \\(k\\)’te lag \\[\n\\delta_j^{(k)} = \\frac{\\partial E}{\\partial z_j^{(k)}}=  \\left ( \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)} \\cdot w_{ij}^{(k+1)} \\right) \\cdot a_j^{(k)} \\cdot (1-a_j^{(k)})\n\\] Vi bruger nu udtrykket for \\(\\frac{\\partial E}{\\partial w_{ji}^{(k)}}\\) i (41) og ender med \\[\\begin{align}\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} = \\delta_j^{(k)} \\cdot a_i^{(k-1)}\n\\end{align}\\] og tilsvarende får vi også, at \\[\n\\frac{\\partial E}{\\partial b_j^{(k)}} = \\delta_j^{(k)}\n\\] Opdateringsreglerne for et vilkårligt skjult lag bliver så:\n\n\n\n\n\n\nOpdateringsregler til vægte og bias i et vilkårligt skjult lag \\(k\\)\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(k)} \\leftarrow w_{ji}^{(k)} - \\eta \\cdot \\delta_j^{(k)} \\cdot a_i^{(k-1)}\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(k)} \\leftarrow b_j^{(k)} - \\eta \\cdot \\delta_j^{(k)}\n\\end{align}\\] hvor \\[\\begin{align}\n\\delta_j^{(k)} = \\frac{\\partial E}{\\partial z_j^{(k)}}=  \\left ( \\sum_{i=1}^{n_{k+1}} \\delta_i^{(k+1)} \\cdot w_{ij}^{(k+1)} \\right) \\cdot a_j^{(k)} \\cdot (1-a_j^{(k)})\n\\end{align}\\]"
  },
  {
    "objectID": "materialer/neurale_net/neurale_net.html#stokastisk-gradientnedstigning",
    "href": "materialer/neurale_net/neurale_net.html#stokastisk-gradientnedstigning",
    "title": "Kunstige neurale netværk",
    "section": "Stokastisk gradientnedstigning",
    "text": "Stokastisk gradientnedstigning\nVi har faktisk snydt lidt… Okay – indrømmet – det er lidt træls at komme at sige nu! Men i alt hvad vi har lavet indtil nu, har vi kun kigget på ét træningseksempel. Vi har ladet inputværdierne for det ene træningseksempel \"kører igennem\" netværket (feedforward), beregnet tabsfunktionen og brugt resultatet herfra til at opdatere alle vægtene (backpropagation). Men vi har jo ikke kun ét træningseksempel. Vi har faktisk rigtig mange! Måske ligefrem tusindvis af træningsdata. Men hvad gør man så?\nLad os lige genopfriske den tabsfunktion, som vi endte med i det helt generelle tilfælde: \\[\nE= \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_i - a_i^{(K)} \\right )^2.\n\\tag{44}\\] Her er \\(t_i\\) target-værdien for den \\(i\\)’te outputneuron for lige præcis det træningseksempel vi står med. Husk på at et givet træningseksempel består af inputværdierne \\[\nx_1, x_2, \\dots, x_{n_1}\n\\] og de ønskede target-værdier \\[\nt_1, t_2, \\dots, t_{n_K}.\n\\] Når vi kører disse inputværdier igennem netværket, får de selvfølgelig i sidste ende direkte betydning for outputværdierne i det sidste lag (\\(K\\)): \\[\na_1^{(K)}, a_2^{(K)}, \\cdots, a_{n_K}^{(K)}.\n\\] Det vil sige, at i vores tabsfunktion i (44), så afhænger både \\(t_i\\)’erne og \\(a_i^{(K)}\\)’erne af træningseksemplet. Hvis vi sådan lidt generelt benævner vores træningseksempel med \\(x\\), så vil det kunne udtrykkes sådan her: \\[\nE_x= \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_{x,i} - a_{x,i}^{(K)} \\right )^2,\n\\] hvor så \\(t_{x,i}\\) er target-værdien for den \\(i\\)’te outputneuron fra træningsdata \\(x\\) og \\(a_{x,i}^{(K)}\\) er outputværdien for den \\(i\\)’te outputneuron, som er beregnet på baggrund af inputværdierne fra træningsdata \\(x\\).\nDen samlede tabsfunktion, som er den, vi i virkeligheden ønsker at minimere, bliver så gennemsnittet af tabsfunktionerne hørende til de enkelte træningsdata: \\[\nE = \\frac{1}{n} \\sum_x E_x= \\frac{1}{n} \\sum_x \\left ( \\frac{1}{2} \\sum_{i=1}^{n_K} \\left ( t_{x,i} - a_{x,i}^{(K)} \\right )^2 \\right ).\n\\tag{45}\\] Husk på at vi er ude efter \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial b_j^{(k)}}\n\\] for \\(k \\in \\{2, 3, \\dots, K\\}\\) og hvor \\(E\\) nu er summen i (45). Heldigvis kan vi differentiere ledvis, og der gælder derfor \\[\n\\frac{\\partial E}{\\partial w_{ji}^{(k)}} = \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial w_{ji}^{(k)}}\n\\] og tilsvarende \\[\n\\frac{\\partial E}{\\partial b_j^{(k)}} = \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial b_j^{(k)}}\n\\] Det kommer så til at betyde, at opdateringsreglerne nu generelt bliver på formen \\[\nw_{ji}^{(k)} \\leftarrow w_{ji}^{(k)}-\\eta \\cdot \\frac{\\partial E}{\\partial w_{ji}^{(k)}}  =\nw_{ji}^{(k)}-\\eta \\cdot \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial w_{ji}^{(k)}}\n\\tag{46}\\] og tilsvarende for biasene \\[\nb_j^{(k)} \\leftarrow b_j^{(k)} -\\eta \\cdot \\frac{\\partial E}{\\partial b_j^{(k)}}  =\nb_j^{(k)}-\\eta \\cdot \\frac{1}{n} \\sum_x \\frac{\\partial E_x}{\\partial b_j^{(k)}}\n\\tag{47}\\] Alle leddene \\(\\frac{\\partial E_x}{\\partial w_{ji}^{(k)}}\\) og \\(\\frac{\\partial E_x}{\\partial b_j^{(k)}}\\), som indgår i opdateringsreglerne, svarer netop til hvad vi har udledt i de foregående afsnit, fordi vi jo netop her kun så på ét træningseksempel ad gangen. Hvis vi overfører dette til opdateringsreglerne i outputlaget, så vil vi f.eks. få\n\n\n\n\n\n\nGenerelle opdateringsregler til vægte og bias i outputlaget (lag \\(K\\)) med brug af alle træningsdata\n\n\n\nVægtene i outputlaget opdateres på denne måde: \\[\\begin{align}\nw_{ji}^{(K)} \\leftarrow w_{ji}^{(K)} - \\eta \\cdot \\frac{1}{n} \\sum_x \\left ( \\delta_{x,j}^{(K)} \\cdot a_{x,i}^{(K-1)} \\right )\n\\end{align}\\] Biasene i outputlaget opdateres på denne måde: \\[\\begin{align}\nb_j^{(K)} \\leftarrow b_j^{(K)} - \\eta \\cdot \\frac{1}{n} \\sum_x \\left ( \\delta_{x,j}^{(K)} \\right )\n\\end{align}\\] hvor \\[\\begin{align}\n\\delta_{x,j}^{(K)} = \\frac{\\partial E_x}{\\partial z_j^{(K)}}= -(t_{x,j}-a_{x,j}^{(K)}) \\cdot a_{x,j}^{(K)} \\cdot (1-a_{x,j}^{(K)})\n\\end{align}\\]\n\n\nOg helt tilsvarende vil det se ud for opdateringsreglerne i de skjulte lag.\nLad os lige dvæle lidt ved, hvad det her, det egentlig betyder. Lad os sige at vi har \\(1000\\) træningsdata. Så skal vi lade de \\(1000\\) træningsdata kører igennem netværket, så vi kan beregne de \\(1000\\) led, som indgår i de ovenstående summer. Herefter kan vi opdatere alle vægte og bias én gang. Det vil blot være ét lille skridt på vej ned i dalen mod det lokale minimum, som vi er på jagt efter. Dette lille skridt skal gentages rigtig mange gange, indtil værdien af tabsfunktionen ser ud til at begynde at konvergere – svarende til at vi har ramt det lokale minimum.\nSå selvom gradientnedstigning kan bruges til at finde et lokalt minimum for tabsfunktionen \\(E\\), så er det faktisk også en beregningsmæssig stor og tung opgave! Derfor er der forsket meget videre i at gøre det endnu bedre og endnu hurtigere. I algoritmer som disse er der ofte et trade-off: Man kan gøre noget hurtigere ved at bruge mere hukommelse – eller bruge mindre hukommelse ved at gøre det en smule langsommere. En af de teknikker, der er kommet ud af den forskning, er, at man kan bruge mindre hukommelse ved i hvert opdateringsskridt kun at bruge en tilfældigt udvalgt del af træningsdata – det kunne f.eks. være \\(10\\%\\) af alle træningsdata. Så vil man i hvert skridt stadig bruge opdateringsreglerne i (46) og (47), men hvor der nu kun summeres over de \\(10 \\%\\) af træningsdatene. Hver gang man laver et nyt opdateringsskridt, vil man tage en ny tilfældigt udvalgt del af træningsdata. Denne teknik kalder man stokastisk gradientnedstigning (stochastic gradient descent). Og der er endnu flere af sådanne små ændringer, der enten gør algoritmen hurtigere eller, at den bruger mindre hukommelse. Det vil komme an på den enkelte anvendelse, hvad der er vigtigst her."
  },
  {
    "objectID": "materialer/kmeans/kmeans.html",
    "href": "materialer/kmeans/kmeans.html",
    "title": "Clustering med K-means",
    "section": "",
    "text": "K-means\nNår \\(K\\)-means metoden bruges, er målet at inddele nogle observationer i grupper, så observationerne i hver gruppe minder meget om hinanden.\n\n\n\n\n\n\nFigur 1: Til venstre ses en række observationer, som ønskes inddelt i \\(3\\) grupper. Til højre ses et bud på en sådan inddeling.\n\n\n\nPå figur 1 til venstre ses en række punkter, hvor vi ønsker at inddele punkterne i 3 grupper. Man kan nok godt få en idé om, hvordan grupperne kan laves alene ved at se på billedet til venstre. På figur 1 til højre ses et bud på en løsning, som ser fornuftig ud, men ved nogle punkter tænker man nok alligevel lidt, om de nu skulle have været i den orange eller blå gruppe. Når vi arbejder med \\(K\\)-means, så er idéen, at vi ikke på forhånd har nogle observationer, hvor vi ved hvilken gruppe, de tilhører. Med andre ord har vi altså ikke et træningsdatasæt at gå ud fra her. Derfor taler man også om unsupervised learning. Det eneste, vi ved om vores punkter i figur 1, er deres \\(x\\)- og \\(y\\)-koordinat og ud fra det, skal vi så prøve at danne nogle grupper. Antallet af grupper ved man faktisk heller ikke nødvendigvis noget om – så her er det et valg, at vi har besluttet at prøve at inddele data i 3 grupper. Det kunne i princippet lige så godt have været 2 eller 4 grupper eller noget helt andet!\nObservationerne vil vi her kalde for \\(\\vec{x_1}, \\vec{x_2},....,\\vec{x_n}\\), så der i alt er \\(n\\) observationer. Hver observation er et punkt med \\(d\\) koordinater (som dog behandles, som var det vektorer/stedvektorer), og som udgangspunkt benyttes euklidisk afstand til at bestemme afstand mellem punkter. I eksemplet i figur 1 er \\(d=2\\), fordi alle punkter i planen har 2 koordinater.\nGivet et heltal \\(k\\), så ønsker vi at opdele de \\(n\\) observationer \\(\\vec{x_1}, \\vec{x_2},....,\\vec{x_n}\\) i \\(k\\) grupper, som vi kalder for \\(S_1,S_2,....,S_k\\). Antallet af observationer i gruppen1 \\(S_i\\) betegnes med \\(|S_i|\\).\n1 En gruppe \\(S_i\\) er egentlig en mængde, og \\(|S_i|\\) er kardinaliteten af denne mængde – altså antallet af elementer i mængden.Hele idéen i \\(K\\)-means metoden er, at det skal være sådan, at observationerne i samme gruppe ligger tæt på hinanden. Det er også sådan, at vi har farvet punkterne til højre i figur 1.\nHvis man skal oversætte det til matematik, så betyder det, at vi ønsker at minimere følgende sum (som vi kalder for \\(SUMPAR\\))\n\\[SUMPAR=\\sum_{i=1}^{k}\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2\\] Det ser måske lidt voldsomt ud, men lad os prøve at nedbryde ovenstående lidt. Vi forestiller os, at vi har de \\(k\\) grupper \\(S_1, S_2, \\dots , S_k\\). Vi ser først på et punkt \\(\\vec p \\in S_i\\). Den kvadrerede afstand til et andet punkt \\(\\vec q\\) i samme gruppe er givet ved udtrykket\n\\[\n\\|\\vec p- \\vec q\\|^2\n\\]\nDet vil sige, den euklidiske afstand mellem \\(\\vec p\\) og \\(\\vec q\\) opløftet i anden. Den gennemsnitlige kvadrerede afstand til alle punkter i samme gruppe \\(S_i\\) vil derfor være\n\\[\\frac{1}{|S_i|} \\sum_{\\vec q \\in S_i} \\|\\vec p- \\vec q\\|^2 \\]\nDet er altså den gennemsnitlige kvadrerede afstand fra ét punkt \\(\\vec p\\) til alle andre punkter i samme gruppe – inklusiv punktet selv. Vi vil nu lægge alle disse gennemsnitlige kvadrerede afstande sammen for alle punkter i \\(S_i\\). Gør vi det, får vi:\n\\[ \\sum_{\\vec p\\in S_i}\\frac{1}{|S_i|}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2 \\]\nDa størrelsen \\(\\frac{1}{|S_i|}\\) indgår i alle led i den yderste sum, kan vi sætte \\(\\frac{1}{|S_i|}\\) uden for det yderste sumtegn2. Derfor kan vi omskrive ovenstående til\n2 Det svarer bare til at sætte uden for en parentes.\\[\n\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2\n\\]\nDet her vil vi gerne gøre for alle grupper, og derfor ender vi samlet set med\n\\[\nSUMPAR=\\sum_{i=1}^{k}\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2\n\\tag{1}\\]\nAlt i alt får vi altså, at \\(SUMPAR\\) giver summen af hvert punkts gennemsnitlige kvadrerede afstand til alle punkter i samme gruppe som sig selv (inklusiv sig selv).\nIdéen er så nu, at vi vil prøve at bestemme grupperne \\(S_1, S_2, \\dots, S_k\\) sådan, at denne sum bliver så lille så muligt. Det vil nemlig svare til, at de punkter, der ligger tæt på hinanden, kommer i samme gruppe, og punkter, som ligger langt væk fra hinanden, kommer i forskellige grupper.\nDet er desværre ikke lige til at finde den optimale løsning på dette problem, men her angives en metode/algoritme, som forhåbentlig finder en god løsning.\n\n\nAlgoritme\nVi vil nu se på en metode til at finde en god løsning til \\(K\\)-means problemet. Vi får her brug for “midterpunktet” for hver gruppe, som vi vil kalde for \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\). Ved midterpunktet vil vi simpelthen bare forstå gennemsnittet af alle punkter i den pågældende gruppe.\nI algoritmen vil vi prøve at minimere følgende sum\n\\[\nSUMMIDT=\\sum_{i=1}^{k}\\sum_{\\vec p\\in S_i}\\|\\vec p-\\vec{\\mu_i}\\|^2\n\\tag{2}\\]\nHer summeres altså den kvadrerede afstand fra hvert punkt til midterpunktet for gruppen, som punktet er i. Og det gør man så for alle grupper og lægger alle de kvadredede afstande sammen. Senere vil vi se på sammenhængen mellem summen \\(SUMPAR\\) og summen \\(SUMMIDT\\).\nSpørgsmålet er nu, hvordan man kommer igang med at fastlægge grupper og midterpunkter, for vi kender ikke mængderne \\(S_1,S_2,....,S_k\\) og dermed heller ikke midterpunkterne \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\).\nFor at løse det problem vil vi bruge følgende fremgangsmåde/algoritme:\n\nStart med at tage hver eneste observation og tilføj den til en tilfældig gruppe (der skal mindst være én observation i hver gruppe).\nMidterpunkterne bestemmes ved at lade\n\n\\[\n\\vec{\\mu_i}=\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\vec p\n\\]\n\nFor hver af de \\(n\\) observationer findes det midterpunkt, der har den mindste afstand til punktet. Hvis det for en observation \\(\\vec{x_i}\\) er midterpunktet \\(\\vec{\\mu_a}\\), der er nærmest, skal \\(\\vec{x_i}\\) være i mængden \\(S_a\\).\nGentag trin 2 og 3 indtil vi kommer til et tidspunkt, hvor ingen punkter kommer til at skifte til en anden gruppe.\n\nDet virker jo meget rimeligt. Så er spørgsmålet bare, om denne fremgangsmåde virkelig fungerer! Det vil vi se nærmere på i afsnittet om sammenhængen mellem SUMPAR og SUMMIDT. Men lad os starte med at se på et par eksempler.\n\n\nEksempel på beregning af midterpunkter\nFørst kunne det måske være rart at få en fornemmelse af, hvorfor \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\) betegnes som midterpunkter.\n\nEksempel 1 Vi forestiller os, at vi har to grupper med følgende punkter:\n\nGruppe 1 med punkterne \\((3,9)\\) og \\((7,11)\\).\nGruppe 2 med punkterne \\((10,30)\\), \\((17,34)\\), \\((12,27)\\) og \\((11,32)\\).\n\nSom nævnt tidligere kan vi tænke på hvert punkt som stedvektoren til punktet.3 Vi kan nu finde midterpunktet for den første gruppe:\n3 Husk at et punkt og stedvektoren til punktet har samme koordinater.\\[\\vec{\\mu_1}=\\frac{1}{|S_1|}\\sum_{\\vec p\\in S_1}\\vec p = \\frac{\\begin{pmatrix}\n3 \\\\ 9\\end{pmatrix} + \\begin{pmatrix}\n7 \\\\ 11\\end{pmatrix}}{2}= \\frac{\\begin{pmatrix}\n10 \\\\ 20\\end{pmatrix} }{2} = \\begin{pmatrix}\n5 \\\\ 10\\end{pmatrix}\\]\nMidterpunktet for den første gruppe har altså koordinatsæt \\((5,10)\\).\nMidterpunktet for den anden gruppe bliver tilsvarende\n\\[\\vec{\\mu_2}=\\frac{1}{|S_2|}\\sum_{\\vec p\\in S_2}\\vec p = \\frac{\\begin{pmatrix}\n10 \\\\ 30\\end{pmatrix} + \\begin{pmatrix}\n17 \\\\ 34\\end{pmatrix} + \\begin{pmatrix}\n12 \\\\ 27\\end{pmatrix} + \\begin{pmatrix}\n11 \\\\ 32\\end{pmatrix}}{4}= \\frac{\\begin{pmatrix}\n50 \\\\ 123 \\end{pmatrix} }{4} = \\begin{pmatrix}\n12.5 \\\\ 30.75 \\end{pmatrix}\\]\nMidterpunktet for den anden gruppe har så koordinatsæt \\((12.5, 30.75)\\).\nDette er illustreret i figur 2.\n\n\n\n\n\n\nFigur 2: To grupper af punkter (orange og blå) sammen med de tilhørende midterpunkter \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\).\n\n\n\nPå figur 2 bliver det tydeligt, hvorfor det er fornuftigt at vælge midterpunkterne, som det sker i trin 2 i algoritmen – midterpunkterne ligger simpelthen i “midten” af hver gruppe.\n\n\n\nEksempel på algoritmen\nLad os nu prøve at bruge algoritmen på punkterne fra eksempel 1. I figur 3 ses punkterne indtegnet, men uden angivelse af hvilken gruppe hvert enkelt punkt tilhører.\n\n\n\n\n\n\n\n\nFigur 3: Illustration af punkter som ønskes inddelt i 2 grupper.\n\n\n\n\n\nI trin 1 skal vi tilføje hver observation i en tilfældig gruppe. Et sådant valg ses i figur 4.\n\n\n\n\n\n\n\n\nFigur 4: Tilfældig inddeling af punkterne i 2 grupper.\n\n\n\n\n\nVi skal nu have beregnet midtpunkterne i hver af de to grupper. Gør man det fås:\n\\[\n\\vec{\\mu_1} = \\begin{pmatrix} 8.33 \\\\ 22.0 \\end{pmatrix} \\quad \\textrm{og} \\quad \\vec{\\mu_2} = \\begin{pmatrix} 11.7 \\\\ 25.7 \\end{pmatrix}\n\\] Disse to midtpunkter er indtegnet i figur 5 og markeret med et plus.\n\n\n\n\n\n\n\n\nFigur 5: Tilfældig inddeling af punkterne i 2 grupper og med tilhørende midtpunkter, som her er markeret med et plus.\n\n\n\n\n\nI trin 3 skal vi have beregnet afstand fra hver af de 6 punkter til hver af de to midtpunkter. For eksempel bliver afstanden \\(d\\) fra punktet \\((3,9)\\) til punktet med stedvektor \\(\\vec{\\mu_1}\\) være:\n\\[\nd=\\sqrt{(3-8.33)^2+(9-22.0)^2}=14.05\n\\] Resultatet af at beregne alle afstande på denne måde ses i tabel 1.\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand til \\(\\vec{\\mu_1}\\)\nAfstand til \\(\\vec{\\mu_2}\\)\n\n\n\n\n14.05\n18.79\n\n\n11.08\n15.39\n\n\n8.172\n4.643\n\n\n14.8\n9.894\n\n\n6.2\n1.374\n\n\n10.35\n6.368\n\n\n\n\n\n\nTabel 1: Afstanden fra de 6 datapunkter til hvert af midtpunkterne \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\).\n\n\n\n\nVi skal nu afgøre hvilken gruppe, de enkelte punkter skal tilhøre, ved at se på hvilket midtpunkt som hvert enkelt punkt ligger tættest på. For eksempel kan vi i tabel 1 se, at det første punkt \\((3,9)\\) ligger tættest på \\(\\vec{\\mu_1}\\), og det punkt skal derfor (fortsat) hører til gruppe 1.\nI tabel 2 ses den oprindelige gruppe samt den nye gruppe for hvert punkt.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand til \\(\\vec{\\mu_1}\\)\nAfstand til \\(\\vec{\\mu_2}\\)\nOpr. gruppe\nNy gruppe\n\n\n\n\n14.05\n18.79\n1\n1\n\n\n11.08\n15.39\n2\n1\n\n\n8.172\n4.643\n1\n2\n\n\n14.8\n9.894\n2\n2\n\n\n6.2\n1.374\n1\n2\n\n\n10.35\n6.368\n2\n2\n\n\n\n\n\n\nTabel 2: Afstanden fra de 6 datapunkter til hvert af midtpunkterne \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\) samt en angivelse af, hvilken gruppe punktet oprindeligt tilhørte, og hvilken gruppe punktet tilhører efter trin 3.\n\n\n\n\nI figur 6 ses punkterne indtegnet med en angivelse af den nye inddeling (men stadig med de først beregnede midterpunkter).\n\n\n\n\n\n\n\n\nFigur 6: Inddeling af punkterne i 2 grupper efter første gennemløb af algoritmen.\n\n\n\n\n\nVi skal nu i gang med det næste gennemløb af algoritmen, og vi bestemmer derfor først de nye midtpunkter. Gør man det fås:\n\\[\n\\vec{\\mu_1} = \\begin{pmatrix} 5.00 \\\\ 10.0 \\end{pmatrix} \\quad \\textrm{og} \\quad \\vec{\\mu_2} = \\begin{pmatrix} 12.5 \\\\ 30.8 \\end{pmatrix}\n\\]\nDe to nye midtpunkter ses indtegnet i figur 7 – igen markeret med et plus.\n\n\n\n\n\n\n\n\nFigur 7: Inddeling af punkterne i 2 grupper efter første gennemløb af algoritmen og med de nye tilhørende midtpunkter indtegnet.\n\n\n\n\n\nVi kan nu igen udregne afstande fra alle punkter til de to nye midtpunkter og finde ud af om nogle af punkterne eventuelt skal skifte gruppe. Resultatet ses i tabel 3\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand til \\(\\vec{\\mu_1}\\)\nAfstand til \\(\\vec{\\mu_2}\\)\nOpr. gruppe\nNy gruppe\n\n\n\n\n2.236\n23.73\n1\n1\n\n\n2.236\n20.5\n1\n1\n\n\n20.62\n2.61\n2\n2\n\n\n26.83\n5.551\n2\n2\n\n\n18.38\n3.783\n2\n2\n\n\n22.8\n1.953\n2\n2\n\n\n\n\n\n\nTabel 3: Afstanden fra de 6 datapunkter til hvert af de nye midtpunkterne \\(\\vec{\\mu_1}\\) og \\(\\vec{\\mu_2}\\) samt en angivelse af, hvilken gruppe punktet oprindeligt tilhørte, og hvilken gruppe punktet tilhører efter trin 3 (andet gennemløb af algoritmen).\n\n\n\n\nVi kan nu se, at ingen af punkterne har skiftet gruppe, og algoritmen stopper derfor. Den endelige inddeling i grupper bliver derfor som vist i figur 7, hvilket nok også er den inddelingen, som vi ville have valgt bare ved at kigge på punkterne med det blotte øje.\n\n\nFornuftigt valg af midterpunkter og grupper\nVi vil nu argumentere for, hvorfor algoritmen virker. Vi starter med at se på, hvorfor det er fornuftigt at vælge midterpunkterne, som vi gør i trin 2 i algoritmen.\nDa vi med algoritmen ønsker, at summen i (2) kaldet \\(SUMMIDT\\) skal minimeres, vil vi se, at valget af \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\) netop minimerer denne sum, når vi tænker, at grupperne er fastlagt.\nVed summen \\(SUMMIDT\\) har \\(\\vec{\\mu_i}\\) kun en effekt på delen hørende til gruppen \\(S_i\\), altså \\[\\sum_{\\vec p\\in S_i}\\|\\vec p-\\vec{\\mu_i}\\|^2\\]\nFor en vektor \\(\\vec v\\), har vi følgende sammenhæng mellem længde og skalarprodukt/prikprodukt:\n\\[\\|\\vec v\\|^2=\\vec v\\cdot \\vec v \\tag{3}\\]\nDette gør, at vi kan omskrive vores sum for gruppen \\(S_i\\) til\n\\[\\sum_{\\vec p\\in S_i}{(\\vec  p-\\vec{\\mu_i})\\cdot (\\vec p-\\vec{\\mu_i})}\\] Skalarproduktet udregnes ved at tage summen af produktet af tilsvarende koordinater for vektorerne. Hvis vi lader \\(p_m\\) og \\(\\mu_{i,m}\\) betegne det \\(m\\)’te koordinat af henholdsvis \\(\\vec p\\) og \\(\\vec{\\mu_i}\\), så kan ovenstående sum skrives som\n\\[\\sum_{\\vec p\\in S_{i}}\\sum_{m=1}^{d}{(p_m-\\mu_{i,m})\\cdot (p_m-\\mu_{i,m})} = \\sum_{m=1}^{d} \\sum_{\\vec p\\in S_{i}} {(p_m-\\mu_{i,m})\\cdot (p_m-\\mu_{i,m})}\\] Her vil valget af \\(\\mu_{i,m}\\) kun have effekt på \\[\\sum_{\\vec  p\\in S_{i}}{(p_m-\\mu_{i,m})\\cdot (p_m-\\mu_{i,m})}\\] I denne sum har vi ikke længere vektorer, og vi kan derfor benytte anden kvadratsætning til at få\n\\[\\sum_{\\vec p\\in S_i}{(p_m^2-2\\cdot p_m\\cdot \\mu_{i,m}+\\mu_{i,m}^2)}\\] For at finde ud af hvordan \\(\\mu_{i,m}\\) skal vælges for at lave summen mindst mulig, differentieres ovenstående udtryk med hensyn til \\(\\mu_{i,m}\\) og udtrykket sættes lig med \\(0\\):\n\\[\\begin{align}\n\\frac{\\partial}{\\partial \\mu_{i,m}} \\sum_{\\vec p\\in S_i}{(p_m^2-2\\cdot p_m\\cdot \\mu_{i,m}+\\mu_{i,m}^2)}\n&= \\sum_{\\vec p\\in S_i} \\frac{\\partial}{\\partial \\mu_{i,m}} {(p_m^2-2\\cdot p_m\\cdot \\mu_{i,m}+\\mu_{i,m}^2)}\\\\\n&= \\sum_{\\vec p\\in S_i}{(-2\\cdot p_m+2\\cdot \\mu_{i,m})}=0\n\\end{align}\\]\nDen sidste ligning kan omskrives til \\[ \\sum_{\\vec p\\in S_i}{2\\cdot \\mu_{i,m}} = \\sum_{\\vec p\\in S_i}{2\\cdot p_m}\\] Ved division med \\(2\\) fås \\[ \\sum_{\\vec p\\in S_i}{\\mu_{i,m}} = \\sum_{\\vec p\\in S_i}{p_m}\\]\nVi kan nu udnytte at hvert led i den første sum slet ikke afhænger af \\(\\vec p\\), og da summen består af\\(|S_i|\\) led fås \\[|S_i| \\cdot  \\mu_{i,m}= \\sum_{\\vec p\\in S_i}{p_m}\\]\nAltså er \\[\\mu_{i,m}=\\frac{1}{|S_i|} \\sum_{\\vec p\\in S_i}p_m\\] Hvis dette valg tages for alle koordinater for \\(\\vec{\\mu_i}\\) svarer det til \\[\\vec{\\mu_{i}}=\\frac{1}{|S_i|} \\sum_{\\vec p\\in S_i} \\vec p\\] som netop er den måde \\(\\vec{\\mu_i}\\) vælges på ved trin \\(2\\) i algoritmen.\nHer glemte vi at argumentere for, at valget af \\(\\mu_{i,m}\\) rent faktisk gav et lokalt minimum, men lidt løst kan man sige, at hvis \\(\\mu_{i,m}\\) enten vælges alt for lille eller stor, vil afstanden og dermed også den kvadrerede afstand til punkterne i gruppen \\(S_i\\) blive store. Det kan selvfølgelig også bevises helt formelt.\nLad os nu se på valget af grupper ved trin \\(3\\) i algoritmen. For en punkt \\(\\vec p\\) vælges den gruppe \\(S_i\\), hvor midtpunktet \\(\\vec{\\mu_i}\\) er tættest på \\(\\vec p\\). Derved er det oplagt, at denne proces minimerer summen \\(SUMMIDT\\) i (2), når vi har fastholdt midterpunkterne \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\).\nNår et punkt skifter gruppe vil \\(SUMMIDT\\) ikke længere være optimal i forhold til \\(\\vec{\\mu_1},\\vec{\\mu_2},...,\\vec{\\mu_k}\\) før de bliver opdateret igen. I algoritmen bliver disse to trin netop gentaget, indtil ingen punkter skifter gruppe, hvorved \\(SUMMIDT\\) har ramt et lokalt minimum i forhold til valg af gruppe for det enkelt punkt og valg af midterpunkt for hver gruppe.\n\n\nSammenhængen mellem SUMPAR og SUMMIDT\nNu vil vi endelig se på sammenhængen mellem de to summer \\(SUMMIDT\\) i (2) og \\(SUMPAR\\) i (1). Vi vil vise, at \\[SUMPAR=2\\cdot SUMMIDT\\] når midterpunkterne er valgt på denne måde\n\\[\n\\vec{\\mu_{i}}=\\frac{1}{|S_i|} \\sum_{\\vec p\\in S_i}\\vec p \\quad \\quad \\textrm{og derved} \\quad \\quad |S_i|\\cdot \\vec{\\mu_{i}}=\\sum_{\\vec p\\in S_i} \\vec p\n\\tag{4}\\]\nDet betyder, at hvis vi minimerer summen \\(SUMMIDT\\), så har vi også minimeret summen \\(SUMPAR\\), som var det vi oprindeligt ønskede.\nVi starter med at se på summen \\(SUMPAR\\) i (1) dog kun for en af grupperne \\(S_a\\) og uden faktoren \\(\\frac{1}{|S_i|}\\). Altså ser vi på summen \\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p-\\vec q\\|^2\n\\tag{5}\\]\nVed at bruge sammenhængen mellem længde af vektor og skalarprodukt får vi\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}(\\vec p-\\vec q)\\cdot(\\vec p-\\vec q)\n\\]\nHer bruger vi nu, hvad der svarer til anden kvadratsætning for vektorer og vi omskriver tilbage til længder ved at bruge (3)\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}(\\|\\vec p\\|^2+\\|\\vec q\\|^2-2\\cdot \\vec p\\cdot \\vec q)\n\\]\nDenne dobbeltsum opdeles nu i tre dobbeltsummer og \\(-2\\) kan trækkes ud af den ene\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2+\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec q\\|^2-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a} \\vec p\\cdot \\vec q\n\\]\nDe to første dobbeltsummer er faktisk ens og derfor får vi\n\\[\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q\n\\tag{6}\\]\nFor at komme videre med ovenstående vælger vi at se på dobbeltsummen\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q\n\\] Den inderste sum afhænger ikke af \\(\\vec p\\) og derfor kan \\(\\vec p\\) sættes uden for sumtegnet4:\n4 Husk på at den distributive regel også gælder for vektorer: \\(\\vec a \\cdot \\vec b + \\vec a \\cdot \\vec c = \\vec a \\cdot \\left (\\vec b + \\vec c \\right)\\)\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\sum_{\\vec p\\in S_a}\\vec p\\cdot \\left (\\sum_{\\vec q\\in S_a} \\vec q \\right )\n\\]\nFra valget af \\(\\vec{\\mu_a}\\) ved vi fra (4), at \\(|S_a|\\cdot \\vec{\\mu_{a}}=\\sum_{\\vec q \\in S_a} \\vec q\\). Bruger vi det får vi\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\sum_{\\vec p\\in S_a}\\vec p\\cdot |S_a|\\cdot \\vec{\\mu_{a}}\n\\] Sætter vi \\(|S_a|\\cdot \\vec{\\mu_{a}}\\) uden for summmen5 og udnytter ovenstående én gang til, får vi:\n5 Bemærk, at vi igen her benytter den distributive regel for vektorer.\\[\\begin{align}\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a} \\vec p\\cdot \\vec q &= |S_a|\\cdot \\vec{\\mu_{a}} \\cdot \\left ( \\sum_{\\vec p\\in S_a}\\vec p \\right ) \\\\\n&= \\left ( |S_a|\\cdot \\vec{\\mu_{a}} \\right ) \\cdot \\left ( |S_a|\\cdot \\vec{\\mu_{a}} \\right )\n\\end{align}\\]\nVi har nu et prikprodukt mellem to vektorer, som hver især er ganget med en skalar (her \\(|S_a|\\)). Bruger vi den kommutative lov6 for at gange med en skalar, får vi\n6 Den kommutative lov siger, at \\(k \\cdot (\\vec a \\cdot \\vec b) =  (k \\cdot\\vec a) \\cdot (\\vec b) =  (\\vec a ) \\cdot (k \\cdot\\vec b)\\)\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a} \\vec p\\cdot \\vec q = |S_a|^2 \\cdot \\| \\vec{\\mu_{a}} \\|^2\n\\]\nDet må derfor betyde, at \\[\n|S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q=0 \\quad \\Leftrightarrow  \\quad\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q=0\n\\]\nDa dette giver \\(0\\), kan det tilføjes til udtrykket i (6):\n\\[\\begin{align}\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2&-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\\\\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2-2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q &+\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q = \\\\\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2 +\n2 \\cdot |S_a|^2 &\\cdot \\|\\vec{\\mu_a}\\|^2-4\\cdot\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\vec p\\cdot \\vec q\n\\end{align}\\]\nI den sidste dobbeltsum kan \\(\\vec p\\) igen tages ud af den inderste sum og vi kan igen udnytte at \\(|S_a|\\cdot \\vec{\\mu_{a}}=\\sum_{\\vec q \\in S_a} \\vec q\\). Derved får vi\n\\[\n2\\cdot \\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2 +\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-4\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot |S_a|\\cdot \\vec{\\mu_{a}}\n\\]\nVed den første dobbeltsum ses det, at leddene ikke afhænger af \\(\\vec q\\) og derfor er \\(\\sum_{\\vec q\\in S_a}\\|\\vec p\\|^2 = |S_a| \\cdot \\|\\vec p\\|^2\\) (fordi der er \\(|S_a|\\) led i summen). Det vil sige, at vi kan omskrive til\n\\[\n2\\cdot \\sum_{\\vec p\\in S_a}|S_a| \\cdot \\|\\vec p\\|^2 +\n2 \\cdot |S_a|^2\\cdot \\|\\vec{\\mu_a}\\|^2-4\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot |S_a|\\cdot \\vec{\\mu_{a}}\n\\]\nVi kan nu se, at \\(2 \\cdot |S_a|\\) indgår i alle led og vi kan derfor skrive:\n\\[\n2\\cdot |S_a| \\cdot \\left ( \\sum_{\\vec p\\in S_a} \\|\\vec p\\|^2  +\n|S_a|\\cdot \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot \\vec{\\mu_{a}} \\right )\n\\]\nHer kan \\(|S_a|\\cdot \\|\\mu_a\\|^2\\) laves om til en sum, hvor alle led er \\(\\|\\mu_a\\|^2\\). Det vil sige\n\\[\n2\\cdot |S_a| \\cdot \\left ( \\sum_{\\vec p\\in S_a} \\|\\vec p\\|^2  +\n\\sum_{\\vec p\\in S_a} \\|\\vec{\\mu_a}\\|^2-2\\cdot\\sum_{\\vec p\\in S_a}\\vec p\\cdot \\vec{\\mu_{a}} \\right )\n\\]\nHele udtrykket kan nu samles i én sum:\n\\[\n2\\cdot |S_a| \\sum_{\\vec p\\in S_a} \\left (  \\|\\vec p\\|^2  +\n\\|\\vec{\\mu_a}\\|^2-2\\cdot\\vec p\\cdot \\vec{\\mu_{a}} \\right )\n\\] Ved brug af anden kvadratsætning for vektorer kan dette omskrives til\n\\[\n2\\cdot |S_a| \\sum_{\\vec p\\in S_a}   (\\vec p - \\vec{\\mu_a}) \\cdot (\\vec p - \\vec{\\mu_a}) = 2\\cdot |S_a| \\sum_{\\vec p\\in S_a} \\| \\vec p - \\vec{\\mu_a} \\|^2\n\\] Nu kan man jo godt have glemt, hvad det overhovedet var, vi var igang med at regne på! Men vi minder om, at det var udtrykket i (5). Det vil sige, at vi er kommet frem til, at\n\\[\n\\sum_{\\vec p\\in S_a}\\sum_{\\vec q\\in S_a}\\|\\vec p-\\vec q\\|^2 = 2\\cdot |S_a| \\sum_{\\vec p\\in S_a} \\| \\vec p - \\vec{\\mu_a} \\|^2\n\\] Eller skrevet på en anden måde:\n\\[\n\\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2 = 2 \\sum_{\\vec p\\in S_i} \\| \\vec p - \\vec{\\mu_i} \\|^2\n\\] Summerer vi over alle \\(k\\) grupper får vi: \\[\n\\sum_{i=1}^k \\frac{1}{|S_i|}\\sum_{\\vec p\\in S_i}\\sum_{\\vec q\\in S_i}\\|\\vec p-\\vec q\\|^2 = 2 \\sum_{i=1}^k \\sum_{\\vec p\\in S_i} \\| \\vec p - \\vec{\\mu_i} \\|^2\n\\] Sammenligner vi med (1) og (2) har vi netop vist, at\n\\[\nSUMPAR = 2 \\cdot SUMMIDT\n\\]\nDet vil altså sige, at hvis vi minimerer summen \\(SUMMIDT\\), så har vi også minimeret summen \\(SUMPAR\\), hvilket præcis var, hvad vi oprindeligt ønskede.\n\n\nOpsummering/optimal løsning\nNu har vi set på selve algoritmen og fundet ud af, at den finder et lokalt minimum for summen \\(SUMPAR\\), som man ønsker minimeret. Der er dog ingen garanti for, at man opnår et globalt minimum, eller hvor lang tid algoritmen er om at finde en løsning.\nDet er egentlig heller ikke noget problem at få lavet en algoritme, der finder en optimal løsning, problemet er blot, at den vil køre alt for langsomt. En sådan optimal algoritme kan laves ved blot at undersøge hver mulig inddeling i grupper og så finde den inddeling, der giver den mindste værdi af \\(SUMPAR\\). Dog vil det være sådan, at selv ved blot \\(2\\) grupper og \\(100\\) punkter vil der være \\(2^{99}\\) muligheder7, der skal tjekkes. At undersøge så mange muligheder er ikke praktisk muligt – selv ikke på en computer!\n7 Fordi for hvert punkt kan punktet enten være i den ene eller den anden gruppe. Det giver i første omgang \\(2^{100}\\) grupper. Nu vil en inddeling hvor for eksempel punktet \\(A\\) og \\(B\\) er i gruppe \\(1\\), mens \\(C\\) er i gruppe \\(2\\) være den samme inddeling, som hvis \\(C\\) er i gruppe \\(1\\) og \\(A\\) og \\(B\\) er i gruppe \\(2\\). På grund af denne symmetri ender vi derfor samlet set med \\(2^{100}/2=2^{99}\\) grupper.\n\nK-means ikke blot med punkter\nIndtil videre har vi udelukkende set på data som værende punkter, hvor vi kan anvende euklidisk afstand for at måle afstanden mellem punkterne. Det kunne dog være langt mere interessant f.eks. at arbejde med mennesker og information om dem (f.eks. alder, køn, forbrug og så videre) og stadigvæk med et ønske om at inddele disse mennesker i et bestemt antal grupper, hvor der er stor ligmed mellem dem indenfor samme gruppe. Her skal man selvfølgelig have tænkt lidt over, hvordan man kommer fra mennesker til punkter og efterfølgende får noget, der svarer til euklidisk afstand. Det kan man læse meget mere om under feature-skalering."
  },
  {
    "objectID": "materialer/simple_neurale_net/smartere_end_adaline.html",
    "href": "materialer/simple_neurale_net/smartere_end_adaline.html",
    "title": "AI - Aalborg Intelligence - OLD VERSION!",
    "section": "",
    "text": "I noten om perceptroner beskrev vi perceptron learning algoritmen, som altid konvergerer, hvis data er lineært separabel. Men verden er sjældent lineært separabel, og derfor introducerede vi ADALINE algoritmen, som også virker, selvom data ikke er lineært separabel. I noten om simple neurale netværk beskrev vi en helt tredje metode.\nVi vil her med et enkelt lille eksempel afsløre, at ADALINE ikke altid er så smart, som man kunne tro. Dernæst vil vi forklare hvordan simple neurale netværk, kan være en løsning på det skitserede problem.\nVi vil se på data i nedenstående tabel\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(-0.5\\)\n\\(0.5\\)\n\\(1\\)\n\n\n\\(-0.3\\)\n\\(0.3\\)\n\\(1\\)\n\n\n\\(-0.1\\)\n\\(0.7\\)\n\\(1\\)\n\n\n\\(0.1\\)\n\\(0.4\\)\n\\(-1\\)\n\n\n\\(-0.1\\)\n\\(0.2\\)\n\\(-1\\)\n\n\n\\(0.1\\)\n\\(-0.1\\)\n\\(-1\\)\n\n\n\nBemærk, at i ADALINE er targetværdien \\(t \\in \\{-1,1\\}\\).\nI figur 1 har vi indtegnet punkterne \\((x_1,x_2)\\) og farvet punkterne med en targetværdi på \\(1\\) blå og dem med en targetværdi på \\(-1\\) røde.\n\n\n\n\n\n\nFigur 1: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde.\n\n\n\nDet er tydeligt, at punkterne er lineært separabel og den indtegnede linje er også den som ADALINE giver1. Du kan selv prøve ADALINE her. De estimerede vægte er \\(w_0=-0.9346, w_1=-2.838\\) og \\(w_2=1.668\\).Det vil sige, at den indtegnede linje har ligning\n1 Her er alle startvægte sat til \\(0\\), learning rate er på \\(0.1\\), stop-kriterie er på \\(0.000001\\) og maksimalt antal iterationer er sat til \\(50000\\).\\[\n-0.9346-2.838 x_1 + 1.668x_2=0\n\\]\nDet er alt sammen meget fint, men lad os nu prøve at indtegne et nyt rødt punkt:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(1\\)\n\\(-1\\)\n\\(-1\\)\n\n\n\nDet nye punkt er indtegnet i figur 2 sammen med de øvrige seks punkter. Det er tydeligt, at data stadig er lineært separabel.\n\n\n\n\n\n\nFigur 2: Et nyt rødt punkt er indtegnet og data er stadig lineært separabel.\n\n\n\nHvis vi prøver at køre ADALINE algoritmen fås linjen, som er indtegnet i figur 3. Vi kan allerede se nu, at det er helt skørt. Data er lineært separabel, men alligevel er der et rødt punkt, som bliver klassificeret forkert – faktisk var den oprindelige linje fra figur 1 bedre.\n\n\n\n\n\n\nFigur 3: Et nyt rødt punkt er indtegnet og den linje, som ADALINE finder.\n\n\n\nDet er jo ikke ligefrem super overbevisende. Data er lineært separabel og alligevel kan ADALINE ikke finde ud af at finde en ret linje, som kan adskille de røde punkter fra de blå!\nHvis vi skal forstå, hvad der sker, må vi se lidt nærmere på den tabsfunktion, som ADALINE forsøger at mininere. Fra afsnittet om ADALINE ved vi, at tabsfunktionen2 er\n2 Bemærk her, at det ikke er afgørende, at der er ganget med \\(1/2\\) – det viser sig bare smartere senere.\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n)\\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\end{aligned}\n\\]\nhvor det \\(m\\)’te træningseksempel er \\[(x_{m,1}, x_{m,2}, \\dots, x_{m,n}, t_m)\\]\nDet vil sige, at det \\(m\\)’te træningseksempel giver et bidrag til tabsfunktionen på\n\\[\n\\left ( t_m- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\]\nFor et blåt punkt med \\(t_m=1\\) vil det sige, at bidraget til tabsfunktionen er præcis \\(0,\\) hvis \\[\n1- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})=0\n\\] og for et rødt punkt med \\(t_m=-1\\) er bidraget til tabsfunktionen præcis \\(0,\\) hvis \\[\n-1- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})=0\n\\] Nu er \\(1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) og \\(-1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) jo bare ligninger for rette linjer3. Disse linjer ses indtegnet på figur 4 (som henholdsvis en blå og rød stiplet linje) sammen med de oprindelige seks punkter og den linje, som ADALINE fandt baseret på disse seks punkter. Samtidig er det for hvert punkt markeret, hvor meget dette punkt bidrager til tabsfunktionen.\n3 Det er i hvert tilfælde \"bare linjer\", når \\(n=2\\). Hvis \\(n=3\\), er der tale om ligningen for en plan, og hvis \\(n&gt;3\\), kalder man det for ligningen for en \"hyperplan\". Men sidstnævnte er visuelt svære at forestille sig, fordi koordinatsystemet, disse hyperplaner skal tegnes i, har en dimension større end \\(3\\). Og de er ikke så nemme at tegne!\n\n\n\n\n\nFigur 4: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE fandt. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\).\n\n\n\nDet ses nu på figur 4, at blå punkter, som ligger tæt på den blå stiplede linje, bidrager mindst til tabsfunktionen, mens røde punkter, som ligger tæt på den røde stiplede linje, ligeledes bidrager mindst til tabsfunktionen. Den samlede værdi af tabsfunktionen er her \\(0.75\\).\nLaver vi nu samme øvelse med det ekstra punkt fås resultat i figur 5.\n\n\n\n\n\n\nFigur 5: I alt syv punkter sammen med den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE finder. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(2.00\\).\n\n\n\nIgen ser vi, at blå punkter tæt på den blå stiplede linje bidrager mindst til tabsfunktionen og tilsvarende for de røde punkter, som ligger tæt på den røde stiplede linje. Det nye punkts bidrag til tabsfunktionen bliver derfor her det mindste bidrag blandt alle de røde punkter. Den samlede værdi af tabsfunktionen er her \\(2.00\\).\nHvis vi i stedet prøver at bruge vores egen oprindelige linje (baseret på de seks første punkter), som rent faktisk kunne adskille de blå punkter fra de røde, så fås det resultat, som ses i figur 6.\n\n\n\n\n\n\nFigur 6: I alt syv punkter sammen med den sorte linje, som ADALINE giver baseret på de oprindelige seks punkter. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(10.60\\).\n\n\n\nDet er nu tydeligt, at det nye røde punkter ligger så langt væk fra den stiplede røde linje, at det bidrager betydeligt til tabsfunktionen. Derfor er den samlede værdi af tabsfunktionen \\(10.60\\) – og derfor vælger ADALINE linjen i figur 5 til at adskille punkterne. Ikke fordi, det er den linje, som giver den laveste andel af korrekt klassificerede, men fordi det er den linje, som minimerer tabsfunktionen! Det kan jo godt virke lidt skørt, når vi selv kan indtegne en linje, som kan separere alle punkterne."
  },
  {
    "objectID": "materialer/simple_neurale_net/smartere_end_adaline.html#hvorfor-er-simple-neurale-netværk-smartere-end-adaline",
    "href": "materialer/simple_neurale_net/smartere_end_adaline.html#hvorfor-er-simple-neurale-netværk-smartere-end-adaline",
    "title": "AI - Aalborg Intelligence - OLD VERSION!",
    "section": "",
    "text": "I noten om perceptroner beskrev vi perceptron learning algoritmen, som altid konvergerer, hvis data er lineært separabel. Men verden er sjældent lineært separabel, og derfor introducerede vi ADALINE algoritmen, som også virker, selvom data ikke er lineært separabel. I noten om simple neurale netværk beskrev vi en helt tredje metode.\nVi vil her med et enkelt lille eksempel afsløre, at ADALINE ikke altid er så smart, som man kunne tro. Dernæst vil vi forklare hvordan simple neurale netværk, kan være en løsning på det skitserede problem.\nVi vil se på data i nedenstående tabel\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(-0.5\\)\n\\(0.5\\)\n\\(1\\)\n\n\n\\(-0.3\\)\n\\(0.3\\)\n\\(1\\)\n\n\n\\(-0.1\\)\n\\(0.7\\)\n\\(1\\)\n\n\n\\(0.1\\)\n\\(0.4\\)\n\\(-1\\)\n\n\n\\(-0.1\\)\n\\(0.2\\)\n\\(-1\\)\n\n\n\\(0.1\\)\n\\(-0.1\\)\n\\(-1\\)\n\n\n\nBemærk, at i ADALINE er targetværdien \\(t \\in \\{-1,1\\}\\).\nI figur 1 har vi indtegnet punkterne \\((x_1,x_2)\\) og farvet punkterne med en targetværdi på \\(1\\) blå og dem med en targetværdi på \\(-1\\) røde.\n\n\n\n\n\n\nFigur 1: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde.\n\n\n\nDet er tydeligt, at punkterne er lineært separabel og den indtegnede linje er også den som ADALINE giver1. Du kan selv prøve ADALINE her. De estimerede vægte er \\(w_0=-0.9346, w_1=-2.838\\) og \\(w_2=1.668\\).Det vil sige, at den indtegnede linje har ligning\n1 Her er alle startvægte sat til \\(0\\), learning rate er på \\(0.1\\), stop-kriterie er på \\(0.000001\\) og maksimalt antal iterationer er sat til \\(50000\\).\\[\n-0.9346-2.838 x_1 + 1.668x_2=0\n\\]\nDet er alt sammen meget fint, men lad os nu prøve at indtegne et nyt rødt punkt:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\n\n\n\n\n\\(1\\)\n\\(-1\\)\n\\(-1\\)\n\n\n\nDet nye punkt er indtegnet i figur 2 sammen med de øvrige seks punkter. Det er tydeligt, at data stadig er lineært separabel.\n\n\n\n\n\n\nFigur 2: Et nyt rødt punkt er indtegnet og data er stadig lineært separabel.\n\n\n\nHvis vi prøver at køre ADALINE algoritmen fås linjen, som er indtegnet i figur 3. Vi kan allerede se nu, at det er helt skørt. Data er lineært separabel, men alligevel er der et rødt punkt, som bliver klassificeret forkert – faktisk var den oprindelige linje fra figur 1 bedre.\n\n\n\n\n\n\nFigur 3: Et nyt rødt punkt er indtegnet og den linje, som ADALINE finder.\n\n\n\nDet er jo ikke ligefrem super overbevisende. Data er lineært separabel og alligevel kan ADALINE ikke finde ud af at finde en ret linje, som kan adskille de røde punkter fra de blå!\nHvis vi skal forstå, hvad der sker, må vi se lidt nærmere på den tabsfunktion, som ADALINE forsøger at mininere. Fra afsnittet om ADALINE ved vi, at tabsfunktionen2 er\n2 Bemærk her, at det ikke er afgørende, at der er ganget med \\(1/2\\) – det viser sig bare smartere senere.\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n)\\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\end{aligned}\n\\]\nhvor det \\(m\\)’te træningseksempel er \\[(x_{m,1}, x_{m,2}, \\dots, x_{m,n}, t_m)\\]\nDet vil sige, at det \\(m\\)’te træningseksempel giver et bidrag til tabsfunktionen på\n\\[\n\\left ( t_m- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\]\nFor et blåt punkt med \\(t_m=1\\) vil det sige, at bidraget til tabsfunktionen er præcis \\(0,\\) hvis \\[\n1- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})=0\n\\] og for et rødt punkt med \\(t_m=-1\\) er bidraget til tabsfunktionen præcis \\(0,\\) hvis \\[\n-1- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})=0\n\\] Nu er \\(1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) og \\(-1- (w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)=0\\) jo bare ligninger for rette linjer3. Disse linjer ses indtegnet på figur 4 (som henholdsvis en blå og rød stiplet linje) sammen med de oprindelige seks punkter og den linje, som ADALINE fandt baseret på disse seks punkter. Samtidig er det for hvert punkt markeret, hvor meget dette punkt bidrager til tabsfunktionen.\n3 Det er i hvert tilfælde \"bare linjer\", når \\(n=2\\). Hvis \\(n=3\\), er der tale om ligningen for en plan, og hvis \\(n&gt;3\\), kalder man det for ligningen for en \"hyperplan\". Men sidstnævnte er visuelt svære at forestille sig, fordi koordinatsystemet, disse hyperplaner skal tegnes i, har en dimension større end \\(3\\). Og de er ikke så nemme at tegne!\n\n\n\n\n\nFigur 4: Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE fandt. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\).\n\n\n\nDet ses nu på figur 4, at blå punkter, som ligger tæt på den blå stiplede linje, bidrager mindst til tabsfunktionen, mens røde punkter, som ligger tæt på den røde stiplede linje, ligeledes bidrager mindst til tabsfunktionen. Den samlede værdi af tabsfunktionen er her \\(0.75\\).\nLaver vi nu samme øvelse med det ekstra punkt fås resultat i figur 5.\n\n\n\n\n\n\nFigur 5: I alt syv punkter sammen med den sorte linje med ligning \\(w_0+w_1 x_1 + w_2 x_2=0\\) svarer til den ADALINE finder. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(2.00\\).\n\n\n\nIgen ser vi, at blå punkter tæt på den blå stiplede linje bidrager mindst til tabsfunktionen og tilsvarende for de røde punkter, som ligger tæt på den røde stiplede linje. Det nye punkts bidrag til tabsfunktionen bliver derfor her det mindste bidrag blandt alle de røde punkter. Den samlede værdi af tabsfunktionen er her \\(2.00\\).\nHvis vi i stedet prøver at bruge vores egen oprindelige linje (baseret på de seks første punkter), som rent faktisk kunne adskille de blå punkter fra de røde, så fås det resultat, som ses i figur 6.\n\n\n\n\n\n\nFigur 6: I alt syv punkter sammen med den sorte linje, som ADALINE giver baseret på de oprindelige seks punkter. Punkter med en targetværdi på \\(1\\) er blå og dem med en targetværdi på \\(-1\\) er røde. Den blå stiplede linje har ligning \\(1-(w_0+w_1 x_1 + w_2 x_2)=0\\), mens den røde stiplede linje har ligning \\(-1-(w_0+w_1 x_1 + w_2 x_2)=0\\). Den samlede værdi af tabsfunktionen er her \\(10.60\\).\n\n\n\nDet er nu tydeligt, at det nye røde punkter ligger så langt væk fra den stiplede røde linje, at det bidrager betydeligt til tabsfunktionen. Derfor er den samlede værdi af tabsfunktionen \\(10.60\\) – og derfor vælger ADALINE linjen i figur 5 til at adskille punkterne. Ikke fordi, det er den linje, som giver den laveste andel af korrekt klassificerede, men fordi det er den linje, som minimerer tabsfunktionen! Det kan jo godt virke lidt skørt, når vi selv kan indtegne en linje, som kan separere alle punkterne."
  },
  {
    "objectID": "materialer/simple_neurale_net/smartere_end_adaline.html#simple-neurale-netværk-og-aktiveringsfunktioner",
    "href": "materialer/simple_neurale_net/smartere_end_adaline.html#simple-neurale-netværk-og-aktiveringsfunktioner",
    "title": "AI - Aalborg Intelligence - OLD VERSION!",
    "section": "Simple neurale netværk og aktiveringsfunktioner",
    "text": "Simple neurale netværk og aktiveringsfunktioner\nProblemet med ADALINE, som vi har set i eksemplet ovenfor, opstår fordi, et ekstremt punkt får lov til at \"trække\" uforholdsmæssigt meget i den linje, som ADALINE finder, for at dette punkts bidrag til tabsfunktionen ikke skal blive alt for stort.\nVi så det i figur 5 og figur 6. I figur 5 brugte vi den linje, som ADALINE gav, og her var det ekstreme punkts bidrag til tabsfunktionen på \\(0.32\\). I figur 6 valgte vi en linje, som oplagt er bedre til at adskille de blå punkter fra de røde, men her er det ekstreme punkts bidrag til tabsfunktionen helt oppe på \\(19.72\\).\nFor at forstå det lidt bedre skal vi måske lige repetere, hvordan man finder afstanden fra et punkt \\(P(x_1,y_1)\\) til en linje \\(l\\) med ligning \\(ax+by+c=0\\):\n\\[\n\\textrm{dist}(P,l)=\\frac{|a x_1 + b y_1 +c|}{\\sqrt{a^2+b^2}}\n\\]\nDenne afstandsformel kan generaliseres, så afstanden fra et punkt \\(P(x_{m,1}, x_{m,2}, \\dots, x_{m,n})\\) (i et \\(n\\)-dimensionalt rum!) til linjen \\(l\\) med ligning \\(w_0+w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n=0\\) er:\n\\[\n\\textrm{dist}(P,l)=\\frac{|w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}|}{\\sqrt{w_1^2 + w_2^2 + \\cdots + w_n^2}}\n\\]\nDet vil sige, at udtrykket i tælleren \\(|w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}|\\) bliver et mål for hvor langt væk punktet \\(P(x_{m,1}, x_{m,2}, \\dots, x_{m,n})\\) ligger fra linjen. Det forklarer, hvordan et ekstremt punkt kan give et meget stort bidrag til tabsfunktionen:\n\\[\n\\left ( t- (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\tag{1}\\]\nHvis punktet ligger langt væk fra den linje, som måske umiddelbart ser fornuftig ud, så vil punktet give et stort bidrag til tabsfunktionen, fordi værdien af \\(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}\\) bliver stor, og dermed vil bidraget til tabsfunktionen i (1) også blive stort!\nAlt det her leder os frem til, at valget af tabsfunktion måske i virkeligheden ikke er super smart. Problemet opstår grundlæggende, fordi targetværdien \\(t\\) og udtrykket i den inderste parentes i (1) er på to helt vidt forskellige skalaer. Targetværdien er enten \\(-1\\) eller \\(1\\), mens udtrykket \\(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}\\) kan antage en hvilken som helst reel værdi – en værdi som kan blive vældig stor, hvis punktet \\(P(x_{m,1}, x_{m,2}, \\dots, x_{m,n})\\) ligger langt væk fra linjen. Derfor bliver ADALINE nødt til at tvinge linjen med ligningen\n\\[\nw_0 + w_1 \\cdot x_{1} + \\cdots + w_n \\cdot x_{n}=0\n\\]\nover mod et ekstremt punkt, sådan at dette punkts bidrag til tabsfunktionen ikke bliver alt for stort.\nProblemet kan løses ved at bruge et simpelt neuralt netværk.\nHelt grundlæggende handler problemet om, at targetværdi \\(t,\\) og det udtryk, som vi beregner på baggrund af punktet \\(P(x_{m,1}, x_{m,2}, \\dots, x_{m,n})\\), skal være på samme skala. I det simple neurale netværk brugte vi sigmoid-funktionen \\(\\sigma\\), som aktiveringsfunktion. Forskriften for sigmoid-funktionen er:\n\\[\n\\sigma(x)=\\frac{1}{1+e^{-x}}\n\\tag{2}\\]\nog grafen ses i figur 7.\n\n\n\n\n\n\nFigur 7: Grafen for sigmoid-funktionen med forskrift \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\).\n\n\n\nDet centrale her er værdimængden for sigmoid-funktion:\n\\[\nVm(\\sigma)=(0,1).\n\\]\nDet vil vi udnytte og nu omdefinere targetværdien \\(t\\) på denne måde:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis punktet er blåt} \\\\\n0 & \\textrm{hvis punktet er rødt} \\\\\n\\end{cases}\n\\]\nSå targetværdierne er nu \\(0\\) eller \\(1\\) i stedet for \\(-1\\) og \\(1\\). Vi husker nu, hvordan vi definerede tabsfunktionen for det simple neurale netværk:\n\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) \\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\end{aligned}\n\\tag{3}\\]\nBemærk, at problemet med de to skalaer nu er løst. Targetværdien er enten \\(0\\) eller \\(1\\) samtidig med, at \\(\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\\) også ligger mellem \\(0\\) og \\(1\\). Vi sammenligner altså ikke længere pærer med bananer! Den \"perceptron\", som minimerer tabsfunktionen i (3), er netop det, vi kalder for et simpelt neuralt netværk.\nI noten om simple neurale netværk beskrev vi, hvordan vi kan tænke på outputværdien\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n)\n\\]\nsom en sandsynlighed for at punktet \\(P(x_1, x_2, \\dots, x_n)\\) er blåt. Det gjorde vi på denne måde:\n\\[\n\\textrm{Nyt punkt }=\n\\begin{cases}\n\\textrm{blåt} & \\textrm{hvis } o \\geq 0.5\\\\\n\\textrm{rødt} & \\textrm{hvis } o &lt; 0.5\\\\\n\\end{cases}\n\\tag{4}\\]\nhvor\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n).\n\\]\nVi argumenterede også for, at skillelinjen, for hvornår et punkt \\((x_1, x_2, \\dots, x_n)\\) er blåt eller rødt, kan beskrives ved ligningen\n\\[\nw_0 + w_1 \\cdot x_{1} + \\cdots + w_n \\cdot x_{n} = 0\n\\]\nTabsfunktionen i simple neurale netværk giver os altså stadigvæk en ret linje, som kan bruges til at adskille de røde punkter fra de blå.\nLad os prøve først at illustrere det med datasættet bestående af de seks punkter i figur 1. Resultat af at bruge ADALINE (fuldt optrukket linje) og et simpelt neuralt netværk (stiplet linje) ses i figur 8. Det er her tydeligt, at begge metoder kan bruges til at finde en linje, som adskiller de blå punkter fra de røde, og der er i det hele taget ikke den store forskel på de to metoder.\n\n\n\n\n\n\nFigur 8: Fuldt optrukket linje svarer til ADALINE – stiplet linje svarer til et simpelt neuralt netværk.\n\n\n\nBruger vi nu ADALINE og et simpelt neuralt netværk på data fra figur 2 fås resultatet i figur 9. Igen svarer ADALINE til fuldt optrukket linje og sigmoid til stiplet linje. Vi kan nu se, at det simple neurale netværk præcis gør det, som vi havde håbet på: Den adskiller de blå punkter fra de røde også selvom ét af punkterne er ekstremt.\n\n\n\n\n\n\nFigur 9: Fuldt optrukket linje svarer til ADALINE – stiplet linje svarer til et simpelt neuralt netværk.\n\n\n\nVægtene fra det simple neurale netværk i det sidste eksempel er \\(w_0=-6.046\\), \\(w_1=-16.69\\) og \\(w_2=10.94\\) svarende til linjen med ligning \\[\n-6.046 - 16.69x_1+10.94x_2=0\n\\] Udregner vi \\[\no = \\sigma(-6.046 - 16.69x_1+10.94x_2)\n\\] får vi altså sandsynligheden for at et punkt er blåt. Gør vi det fås resultatet i nedenstående tabel:\n\n\n\n\\(x_1\\)\n\\(x_2\\)\nTargetværdi\nSandsynlighed\n\n\n\n\n\\(-0.5\\)\n\\(0.5\\)\n\\(1\\)\n\\(1.00\\)\n\n\n\\(-0.3\\)\n\\(0.3\\)\n\\(1\\)\n\\(0.90\\)\n\n\n\\(-0.1\\)\n\\(0.7\\)\n\\(1\\)\n\\(0.96\\)\n\n\n\\(0.1\\)\n\\(0.4\\)\n\\(0\\)\n\\(0.03\\)\n\n\n\\(-0.1\\)\n\\(0.2\\)\n\\(0\\)\n\\(0.10\\)\n\n\n\\(0.1\\)\n\\(-0.1\\)\n\\(0\\)\n\\(0.00\\)\n\n\n\\(1\\)\n\\(-1\\)\n\\(0\\)\n\\(0.00\\)\n\n\n\nDer er her fin overensstemmelse mellem targetværdien og den beregnede sandsynlighed (outputværdien \\(o\\)). Læg også mærke til at det ekstreme punkt har en beregnet sandsynlighed på \\(0.00\\) og dermed bliver prædikteret til klart at være et ikke blåt – det vil sige et rødt – punkt."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_bioteknologi.html",
    "href": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_bioteknologi.html",
    "title": "Screeningsprogrammer - bioteknologi",
    "section": "",
    "text": "Der tages udgangspunkt i afsnittet om kræft i Bioteknologi A - bind 3, men en tilsvarende bog om emnet kan selvfølgelig anvendes.\n\n\n\n\n\n\nModul 1 - Hvad er kræft?\n\n\n\n\n\n\nMateriale\n\nBioteknologi A - bind 3, side 226\nBioteknologi A - bind 3, side 213\nBioteknologi A - bind 3, side 214\n\n\n\nArbejdsspørgsmål til teksten\n\nHvad er forskellen mellem en godartet og en ondartet svulst?\nHvordan spreder godartede svulster sig i kroppen sammenlignet med ondartede svulster?\nHvordan er godartede svulster ofte omkredset, og hvad betyder det for deres behandling?\nHvordan kan ondartede svulster sprede sig i kroppen, hvad kaldes denne proces?\nHvilken behandlingsudfordring står læger over for, når det kommer til ondartede svulster, som ikke er til stede ved godartede svulster?\nHvorfor kan det være svært at fjerne alle kræftceller ved en operation, når der er metastaser til stede?\nHvilke alternative behandlingsformer kan anvendes til at bekæmpe kræft, når operation ikke er tilstrækkelig?\nHvad er betydningen af at opdage kræft tidligt for patientens overlevelseschancer?\nHvordan opstår kræft gradvist ifølge beskrivelsen?\nHvilken rolle spiller mutationer i udviklingen af kræft?\nHvordan påvirker hver ny mutation cellens vækstmønster?\nHvordan ændrer cellens udseende sig over tid – inddrag figur 416 og 417?\nHvordan adskiller kræftceller sig fra normale celler – inddrag figur 417?\nHvordan bidrager den reducerede tid i G1-fasen af cellecyklussen til cellens mindre størrelse?\nHvordan påvirker fejlregulerede gener, såsom oncogener og tumorsuppressorgener, udviklingen af kræft?\nHvordan kan forståelsen af disse geners funktion bidrage til kræftscreeninger?\n\n\n\n\n\n\n\n\n\n\n\nModul 2 - Genetik?\n\n\n\n\n\n\nMateriale\n\nBioteknologi A - bind 3, side 215\nBioteknologi A - bind 3, side 216\n\n\n\nArbejdsspørgsmål til teksten\n\nHvad adskiller et oncogen fra et proto-oncogen?\nHvordan kan mutationer i proto-oncogenet føre til dannelse af et oncogen?\nHvad er restriktionspunktet, hvordan påvirker ændringer i kontrol af dette punkt udviklingen af kræft?\nHvordan kan kromosomtranslokationer eller genamplifikationer føre til dannelse af oncogener?\nHvad er RAS-proteiner?\nHvordan påvirker aktiverende mutationer i RAS-proto-oncogener udviklingen af kræft?\nHvordan påvirker mutationer i MYC-gener celledelinger og regulering af restriktionspunktet?\nHvordan fungerer Myc som en transskriptionsfaktor?\nHvordan kan forståelsen af oncogener som RAS og MYC bidrage til udviklingen af kræftbehandling?\nHvad er funktionen af et tumorsuppressorgen?\nHvad sker der, hvis et tumorsuppressorgen inaktiveres?\nHvilken genetiske ændring skal der til for at et tumorsuppressorgen mister sin funktion?\nHvad er p53, og hvorfor er det et vigtigt protein i forbindelse med kræft?\nHvad er de tre hovedfunktioner af p53?\nHvordan aktiveres p53 – inddrag figur 422?\nHvordan reguleres nedbrydningen af p53 normalt?\nHvorfor betragtes p53 som \"genomets vogter\"?\n\n\n\n\n\n\n\n\n\n\n\nModul 3 - Artiklens metode og resultater\n\n\n\n\n\n\nMateriale\nNovel Blood-Based, Five-Gene Biomarker Set for the Detection of Colorectal Cancer\n\n\nArbejdsspørgsmål til teksten\n\nHvor mange personer blev inkluderet i studiet?\nHvordan blev de fordelt mellem kontrolgruppen og CRC-patientgruppen?\nHvad var formålet med at opdele prøverne i tre sæt?\nHvordan blev gener med forskelligt grad af udtryk identificeret i mikroarray-dataene?\nHvordan blev ændringer i genudtryk beregnet for PCR-resultaterne?\nHvilke forskelle sås mellem kontrol- og CRC-patientgrupper?\nHvilke fordele er der ved at bruge fx fem markører – hvilke ulemper kan der være ved at have flere eller færre?\nOvervej hvilken betydning det kan have, at der er falske negative resultater\n\nFor den enkelte\nFor samfundet\n\n\n\n\n\n\n\n\n\n\n\n\nModul 4 - Samlet opgave\n\n\n\n\n\nI dette modul samles sammen på indholdet fra de foregående timer, og der skrives en kort opgave med følgende opgaveformulering:\n\nRedegør for hvordan kræft kan opstå, og hvilke genetiske ændringer der ses i forbindelse med udvikling af tumorer.\nKom ind på betydningen af tidlig diagnosticering og i denne sammenhæng screeningsprogrammer.\nVurdér hvilke fordele og ulemper der er ved artiklens metode i forhold til tidligere metoder til at screene for CRC.\nAnalyser artiklens resultater og diskuter om genetisk test kan stå alene eller skal være et supplement."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html",
    "href": "undervisningsforloeb/polynomium_old.html",
    "title": "Perceptroner og rødder",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nAndengradspolynomier og rødder\n\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#hvad-er-en-perceptron",
    "href": "undervisningsforloeb/polynomium_old.html#hvad-er-en-perceptron",
    "title": "Perceptroner og rødder",
    "section": "Hvad er en perceptron?",
    "text": "Hvad er en perceptron?\nI dette forløb skal vi arbejde med perceptoner, og det har du nok aldrig hørt om før! Start derfor med at se videoen herunder, hvor vi kort forklarer, hvad en perceptron er.\n\nDu kan også læse meget mere om perceptroner her."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#andengradspolynomier-og-rødder",
    "href": "undervisningsforloeb/polynomium_old.html#andengradspolynomier-og-rødder",
    "title": "Perceptroner og rødder",
    "section": "Andengradspolynomier og rødder",
    "text": "Andengradspolynomier og rødder\nNu tilbage til vores eksempel om andengradspolynomier og rødder! Lad os for en god ordens skyld minde om, at et andengradspolynomium er en funktion med en forskrift på formen \\[\nf(x)=ax^2 + bx + c, \\quad a \\neq 0\n\\] Grafen for et andengradspolynomium kaldes som bekendt for en parabel. I figur 1 ses tre eksempler på sådanne parabler.\n\n\n\n\n\n\nFigur 1: Graferne for tre forskellige andengradspolynomier.\n\n\n\nHvis vi løser andengradsligningen \\[\nf(x)=ax^2 + bx + c=0\n\\] finder vi andengradspolynomiets rødder. Men at løse \\(f(x)=0\\), svarer netop til at bestemme, hvor den tilhørende parabel skærer \\(x\\)-aksen. I figur 1 kan vi se, at den grønne parabel skærer \\(x\\)-aksen to steder. Det vil sige, at det tilhørende andengradspolynomium har to rødder. Den røde parabel skærer \\(x\\)-aksen ét sted – det tilhørende andengradspolynomium har altså én rod. Endelig kan vi se, at den blå parabel slet ikke skærer \\(x\\)-aksen, og det tilhørende andengradspolynomium har derfor ingen rødder.\nDu husker nok, hvordan man bestemmer antallet af rødder i et andengradspolynomium. Vi har brug for diskriminanten \\(d\\):\n\\[\nd = b^2-4ac\n\\tag{1}\\]\nOg der gælder så, at \\[\n\\begin{aligned}\n&d&lt;0: \\quad f \\textrm{ har ingen rødder} \\\\\n&d=0: \\quad f \\textrm{ har én rod} \\\\\n&d&gt;0: \\quad f \\textrm{ har to rødder} \\\\\n\\end{aligned}\n\\]\nIdéen er nu at undersøge, om det er muligt at få en perceptron til at lære1, om et andengradspolynomium overhovedet har nogle rødder alene ude fra de tre koefficienter \\(a\\), \\(b\\) og \\(c\\) – og helt uden at kende noget til diskriminantformlen i (1)!\n1 Det er klart, at der er intet nyt under solen her. Vi kan jo bare selv beregne diskriminanten og svare på spørgsmålet. Men formålet er her at lære lidt om, hvad det vil sige at træne en perceptron i et tilfælde, hvor vi allerede selv kender svaret. Desuden findes der ingen lukkede løsningsformler for at bestemme rødder i et polynomium, så snart graden af polynomiet er \\(5\\) eller derover. Så idéen kan generaliseres, og så er den måske slet ikke så tosset endda!Inden vi går i gang, vil vi starte med at indse, at i stedet for at løse ligningen\n\\[\na x^2 + bx +c = 0\n\\tag{2}\\]\nSå kan vi lige så godt løse en ligning på formen\n\\[\nx^2 + bx +c =0\n\\] hvor altså \\(a=1\\). Det virker måske som en forsimpling, men da vi har antaget, at \\(a \\neq 0,\\) så kan vi i ligningen i (2) dividere igennem med \\(a\\) og få\n\\[\n\\begin{aligned}\n\\frac{a}{a} x^2 + \\frac{b}{a} x + \\frac{c}{a} &= \\frac{0}{a} \\quad \\Leftrightarrow \\\\\nx^2 + \\frac{b}{a} x + \\frac{c}{a} &= 0\n\\end{aligned}\n\\]\nDet betyder, at når vi skal bestemme rødder i andengradspolynomier, så er det tilstrækkeligt, at betragte andengradspolynomier med en forskrift på formen\n\\[\nf(x)=x^2+bx+c\n\\] fordi man simpelthen bare tager sit oprindelige andengradspolynomium og dividerer igennem med \\(a\\). Lad os illustrere det med et eksempel.\n\nBetragt andengradspolynomiet med forskriften\n\\[\nf(x)=-4x^2+8x+12\n\\] Her har vi \\(a=-4, b=8\\) og \\(c=12\\). Løser vi ligningen \\(f(x)=0\\), finder vi ud af, at \\(f\\) har to rødder nemlig \\(-1\\) og \\(3\\). Dividerer vi forskriften for \\(f\\) igennem med \\(a=-4\\) fås et nyt andengradspolynomium \\(g\\) med forskrift\n\\[\ng(x)=x^2-2x-3\n\\] Her er koefficienterne \\(a=1, b=-2\\) og \\(c=-3\\). Men \\(g\\) har præcis samme rødder som \\(f\\) – nemlig \\(-1\\) og \\(3\\). Dette ses også illustreret i figur 2, hvor grafen for \\(f\\) og \\(g\\) begge skærer \\(x\\)-aksen i \\(-1\\) og \\(3\\).\n\n\n\n\n\n\nFigur 2: Grafen for \\(f(x)=-4x^2+8x+12\\) (den blå) og \\(g(x)=x^2-2x-3\\) (den grønne), som begge skærer \\(x\\)-aksen samme sted. Det vil sige, at \\(f\\) og \\(g\\) har de samme rødder. I dette tilfælde \\(-1\\) og \\(3\\)."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#træningsdata",
    "href": "undervisningsforloeb/polynomium_old.html#træningsdata",
    "title": "Perceptroner og rødder",
    "section": "Træningsdata",
    "text": "Træningsdata\nI dette eksempel vil vi nøjes med at se på, hvordan man kan træne en perceptron, så den forhåbentlig kan fortælle os, om et givent andengradspolynomium enten har ingen eller en eller to rødder. Det svarer til, at vi ønsker en perceptron, som for en given parabel kan svare på, om parablen skærer \\(x\\)-aksen eller ej (og altså ikke hvor mange gange den eventuelt skærer \\(x\\)-aksen).\n\n\n\n\n\n\nOpgave 1: Rødder eller ej?\n\n\n\n\n\nOvervej følgende:\n\nHvordan laver man et andengradspolynomium, der har én eller to rødder?\nHvordan laver man et andengradspolynomium, som ingen rødder har?\n\n\n\n\nFor at træne en perceptron, skal perceptronen se en masse eksempler på forskellige andengradspolynomier (det vil her sige med forskellige værdier af \\(b\\) og \\(c\\)) samtidig med, at vi fortæller perceptronen, om det tilhørende andengradspolynomium har rødder eller ej. At angive om et polynomium har rødder eller ej kalder man for en targetværdi. Tænk på det som en lille label du sætter på hvert eksempel, hvor du fortæller perceptronen, hvad det rigtige svar er – “det er altså det her, jeg gerne vil have, at du lærer!”. Samlet set kalder man de forskellige eksempler inklusiv targetværdien for træningsdata.\n\n\n\n\n\n\nOpgave 2: Træningsdata\n\n\n\n\n\n\nFind selv på forskellige værdier af \\(b\\) og \\(c\\) og find ud af om det tilhørende andengradspolynomium har rødder eller ej. Du skal finde på mindst to andengradspolynomier, der har rødder og to, der ikke har, men gerne et par stykker mere.Skriv dine værdier ned (enten bare på papir eller i f.eks. et regneark).\nIndtegn dine værdier \\(b\\) og \\(c\\) i et koordinatsystem, hvor værdien af \\(b\\) er på \\(x\\)-aksen, og værdien af \\(c\\) er på \\(y\\)-aksen. Herunder er lavet et eksempel med \\(b=0\\) og \\(c=-1\\), som svarer til et andengradspolynomium med to rødder samt \\(b=2\\) og \\(c=4\\), som svarer til et andengradspolynomium uden rødder."
  },
  {
    "objectID": "undervisningsforloeb/polynomium_old.html#træning-af-perceptron",
    "href": "undervisningsforloeb/polynomium_old.html#træning-af-perceptron",
    "title": "Perceptroner og rødder",
    "section": "Træning af perceptron",
    "text": "Træning af perceptron\nVi skal nu overveje, hvordan perceptronen kan trænes. Perceptronen gør dybest set det, at den prøver at bestemme en ret linje, som kan bruges til at adskille de røde punkter fra de blå punkter i punktplottet ovenfor. En ret linje i et 2-dimensionalt koordinatsystem har helt generelt en ligning på formen2\n2 Du er nok vant til at møde linjens ligning på denne form: \\(a \\cdot x+b \\cdot y+c=0\\). Skrivemåden, vi bruger her, er \\(w_0+w_1 \\cdot x + w_2 \\cdot y=0\\). Det vil sige i forhold til den skrivemåde, som du kender, så er \\(w_0=c, w_1=a\\) og \\(w_2=b\\).\\[\nw_0 + w_1 \\cdot x + w_2 \\cdot y = 0\n\\] Og for alle punkter på den ene side af linjen gælder, at\n\\[\nw_0 + w_1 \\cdot x + w_2 \\cdot y &gt; 0\n\\] og for alle punkter på den anden side, at\n\\[\nw_0 + w_1 \\cdot x + w_2 \\cdot y &lt; 0\n\\]\nI vores tilfælde har vi \\(b\\)-værdier ud af \\(x\\)-aksen og \\(c\\)-værdier op af \\(y\\)-aksen. Med de betegnelser bliver ligningen for en ret linje\n\\[\nw_0 + w_1 \\cdot b + w_2 \\cdot c = 0\n\\]\nHer tænker vi altså på \\(b\\) og \\(c\\) som de variable.\nNår man træner en perceptron, gør man det ved hjælp af en algoritme, som løbende opdaterer vægtene \\(w_0, w_1\\) og \\(w_2\\), så den linje, vægtene giver, bliver bedre og bedre til at adskille de røde punkter fra de blå. Hver gang man opdaterer vægtene, siger man, at algoritmen har foretaget én iteration3.\n3 En iteration betyder en gentagelse.Du kan godt løse resten af opgaverne uden at forstå, hvorfor vægtene opdateres, som de gør. Men hvis du gerne vil have en forklaring så se videoen herunder.\n\n\n\n\n\n\n\nOpgave 3: Træning af perceptron\n\n\n\n\n\nLad os bruge startvægtene \\(w_0=1\\), \\(w_1=-3\\) og \\(w_2=2\\).\n\nHvilken linje svarer det til? Indtegn linjen i et koordinatsystemet.\nAdskiller denne linje de to grupper af punkter (med og uden rødder)? Hvis grupperne allerede er adskilt, skal du tilføje punktet med \\(b=2\\) og \\(c=1\\), som svarer til et andengradspolynomium, der har én rod.\n\nTræningsdata der svarer til polynomier med rødder, giver vi targetværdien \\(t=-1\\) og dem uden rødder får targetværdien \\(t=1\\).\nAlle punkter, der ligger over startlinjen, opfylder uligheden \\[\nw_0 + w_1 \\cdot b + w_2 \\cdot c &gt; 0\n\\] og får outputværdien \\(o=1\\), mens dem, der ligger under linjen, opfylder den omvendte ulighed og får outputværdien \\(o=-1\\).\n\nUdvælg et punkt der bliver fejlklassificeret. Det vil sige som enten ligger under linjen (\\(o=-1\\)), men har target \\(t=1\\) svarende til ingen rødder eller omvendt.\nUdregn fejlen \\(error=t-o\\) som enten er -2 eller 2.\nOpdater nu alle tre vægte ved brug af opdateringsreglen (hvor du selv vælger \\(\\eta\\), f.eks. \\(\\eta=1\\)): \\[\n\\begin{aligned}\n  w_0 \\leftarrow w_0 + & \\,\\eta \\cdot error \\\\\n  w_1 \\leftarrow w_1 + & \\,\\eta \\cdot error \\cdot x_1 \\\\\n  w_2 \\leftarrow w_2 + & \\,\\eta \\cdot error \\cdot x_2 \\\\\n\\end{aligned}\n\\] Husk at \\(x_1\\) er \\(b\\)-værdien og \\(x_2\\) er \\(c\\)-værdien!\nFik du efter opdateringen en linje, der adskiller de to grupper?\nHvis ikke, kan du så selv lave en ret linje “på øjemål”, der adskiller dem?\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Flere træningsdata\n\n\n\n\n\n\nAfgør om følgende andengradspolynomier har rødder og tilføj dem til dit træningsdata:\n\n\\[\n\\begin{aligned}\nf_1(x) &= x^2 + 10x + 26 \\\\\nf_2(x) &= x^2 + 10x + 24\\\\\nf_3(x) &= x^2 + 5x + 6\\\\\nf_4(x) &= x^2 + 5x + 7 \\\\\nf_5(x) &= x^2 + 2x + 1\\\\\nf_6(x) &= x^2 + 2x + 2 \\\\\n\\end{aligned}\n\\]\n\nKan det lade sig gøre at adskille de to grupper med en ret linje nu?\n\n\n\n\nSom du netop har opdaget, er det en umulig opgave, vi har givet perceptronen! Vi kan ikke finde en ret linje, som i alle tilfælde kan bruges til at adskille de to slags punkter. Lad os se på hvorfor. Som tidligere nævnt har vores linje en ligning på formen\n\\[\nw_0 + w_1 \\cdot b + w_2 \\cdot c = 0\n\\tag{3}\\]\nVi husker nu på formlen for diskriminanten \\(d=b^2-4ac=b^2-4c\\), da \\(a=1\\) i vores eksempel. Skillelinjen for om andengradspolynomiet har ingen eller flere rødder, går netop ved \\(d=0\\). Det vil sige\n\\[\nb^2-4c =0\n\\tag{4}\\]\nMen vi kan ikke finde nogle værdier af \\(w_0, w_1\\) og \\(w_2\\), så udtrykket i (3) kommer til at svare til udtrykket i (4). Det er fordi, at i (3) indgår der kun et \\(b\\), mens der i (4) indgår et \\(b^2\\). Denne observation giver os imidlertid også en løsning på vores problem. I stedet for at fodre perceptroner med forskellige værdier af \\(b\\) og \\(c\\), så giver vi den i stedet værdier af \\(b^2\\) og \\(c\\)!\n\n\n\n\n\n\nOpgave 5: Nye træningsdata\n\n\n\n\n\n\nLav et nyt koordinatsystem og indtegn dine træningsdata med værdien af \\(b^2\\) på \\(x\\)-aksen og værdien af \\(c\\) på \\(y\\)-aksen.\nHvilken linje kan du vælge til at adskille de to grupper?"
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html",
    "href": "undervisningsforloeb/OverfitPoly.html",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nPolynomiel regression\n\nTidsforbrug: ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#introduktion",
    "href": "undervisningsforloeb/OverfitPoly.html#introduktion",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Introduktion",
    "text": "Introduktion\nMan vil ofte gerne ud fra kendte observationer i en stikprøve kunne forudsige værdier af fremtidige observationer fra den population, som stikprøven er fra. Dette kaldes prediktion. I virkeligheden vil man ofte have en stikprøve med 100 eller flere observationer, men for at undgå alt for mange beregninger, nøjes vi her med 8, selvom det i praksis er alt for lidt.\nI dette eksempel vil vi se på populationen ”danske gymnasieelever”, hvor vi, indrømmet fjollet, vil undersøge, om der en sammenhæng mellem den uafhængige variabel ”antal biografbesøg det seneste år” og den afhængige variabel ”antal venner på de sociale medier”. Vi lader som om, at vi har indsamlet en stikprøve med 8 gymnasielever med følgende resultat:\n\\(Bio = [1, 2, 3, 4, 5, 6, 7, 8]\\)\n\\(Venner = [14, 27, 11, 19, 27, 24, 12, 39]\\)\nVi ønsker ud fra disse data at opstille en model, som for nye observationer kan forudsige, hvor mange venner på de sociale medier en gymnasieelev har, hvis man kender antal biografbesøg.\nNår man opstiller en model, kan man nogle gange bygge på en forventning eller fysisk model, men andre gange har man som udgangspunkt ikke nogen bestemt ide, hvilket er tilfældet her. Vi vil derfor forsøge at modellere data vha. et polynomium, hvor vi så skal undersøge, hvilken grad af polynomiet, der ser ud til at kunne klare opgaven bedst. Her ses f.eks. resultatet af regression med et 3. gradspolynomium.\n\n\n\n\n\n\nFigur 1: 3. gradsregression på alle 8 datapunkter.\n\n\n\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\n\nOvervej og diskuter hvad den højeste grad er, man kan lave polynomiel regression med, når der er 8 punkter?\nOvervej tilsvarende, hvad den mindste grad er?\n\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\n\nLav lineær regression samt polynomiel regression fra 2. grads til 7. grads på stikprøvens data.\nTegn for hver regression punktplottet og grafen for resultatet af regression sammen, hvis dit CAS- værktøj ikke gør det af sig selv.\n\nHvilket polynomium passer bedst til de 8 punkter?\n\nSvaret bør ikke være overraskende. Desto højere grad af polynomium, desto bedre kan grafen tilpasse sig punkterne. Når graden bliver antallet af punkter minus 1, altså her graden 7, passer grafen perfekt til alle punkterne. Men betyder det så også, at det fundne 7. gradspolynomium passer godt til fremtidige observationer og dermed til at prediktere, hvor mange venner på de sociale medier andre elever har ud fra antal biografbesøg? Det vil vi undersøge nærmere i resten af forløbet."
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#krydsvalidering",
    "href": "undervisningsforloeb/OverfitPoly.html#krydsvalidering",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Krydsvalidering",
    "text": "Krydsvalidering\nDen metode, vi vil anvende, kaldes for krydsvalidering. Vi vil lave regressionen ud fra 6 af de 8 punkter og beregne, hvor godt resultatet heraf passer med de sidste 2 punkter – vi lader så at sige som om, at vi skal prediktere værdien for de 2 sidste punkter. Det vil vi gøre 4 gange – første gang anvendes punkt 1 og 2 ikke i regressionen, anden gang anvendes punkt 3 og 4 ikke, så anvendes 5 og 6 ikke og til sidst anvendes 7 og 8 ikke.\nHer er vist et eksempel, lavet med Maple, men det samme kan gøres i andre værktøjer, hvor punkt 3 og 4 er fjernet inden regressionen, og den lodrette afstand fra hver af de to punkter til grafen er beregnet.\n\n\n\n\n\n\nFigur 2: 3. gradsregression på 6 af de 8 datapunkter.\n\n\n\nSom det ses af figuren, ligger det 3. punkt ca. 24 under grafen fra regressionen uden punkt 3 og 4, mens det 4. punkt ligger ca. 13 under. Beregningerne viser de præcise værdier.\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\nHvis I er flere grupper, kan I nu passende dele opgaven op, så grupperne laver beregningerne for forskellige gradtal, gruppe 1 laver for 1. grads, gruppe 2 for 2. grads osv. op til 5. grads. (højere er ikke muligt, da der kun er 6 punkter). Hvis din gruppe er hurtigt færdig, så lav endeligt beregningerne for flere grader.\n\nLav 1., 2. 3., 4. eller 5. gradsregression ud fra 6 af punkter, idet du ikke medtager de to første punkter.\nTegn grafen fra regression og alle 8 punkter i samme koordinatsystem for visuelt at illustrere, hvor godt eller skidt de 2 punkter er predikteret af regressionen, som vist i eksemplet.\nBeregn den lodrette afstand mellem grafen og hver af de 2 punkter, som ikke var med i regression. Disse kaldes for residualer, så lad os kalde dem for \\(r_1\\) og \\(r_2\\). Skriv værdierne i en tabel som den nedenfor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nResidual\n\\(r_1\\)\n\\(r_2\\)\n\\(r_3\\)\n\\(r_4\\)\n\\(r_5\\)\n\\(r_6\\)\n\\(r_7\\)\n\\(r_8\\)\n\n\n\n\nVærdi\n\n\n\n\n\n\n\n\n\n\n\nGentag regression og beregninger for samme grad, hvor det blot er de to næste punkter, der ikke er med i regression, så de to næste og endeligt de to sidste.\nTil sidst skal der beregnes en samlet afstand for alle 8 punkter. Det gøres ved at kvadrere hver enkelt værdi og beregne summen. Altså \\({r_1}^2+{r_2}^2+ {r_3}^2+{r_4}^2+{r_5}^2+{r_6}^2+{r_7}^2+{r_8}^2\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\n\nSammenlign de samlede afstande for 1. grads, 2. grads osv. Hvilken grad er bedst til at prediktere fremtidige værdier?"
  },
  {
    "objectID": "undervisningsforloeb/OverfitPoly.html#overfitting",
    "href": "undervisningsforloeb/OverfitPoly.html#overfitting",
    "title": "Overfitting og krydsvalidering med polynomiel regression",
    "section": "Overfitting",
    "text": "Overfitting\nDet fænomen, som dette forløb illustrerer, kaldes for overfitting. Ved at tilpasse modellen for godt til observationerne, får man ikke lavet en passende generel model, men derimod en model til netop disse punkter. Så selvom et 7. gradspolynomium passer perfekt til de 8 punkter, så viste et 2. gradspolynomium sig at være bedst til prediktion ifølge undersøgelsen med krydsvalidering."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html",
    "href": "undervisningsforloeb/test_for_sygdomme.html",
    "title": "Test for sygdomme",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nSandsynlighedsregning\nBetingede sandsynligheder\n\nTidsforbrug: Ca. 2 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#sensitivitet-og-specificitet",
    "href": "undervisningsforloeb/test_for_sygdomme.html#sensitivitet-og-specificitet",
    "title": "Test for sygdomme",
    "section": "Sensitivitet og specificitet",
    "text": "Sensitivitet og specificitet\nNår man tester for en sygdom, så vil man måske umiddelbart tænke, at hvis testen er positiv, så er man syg, og hvis testen er negativ, så er man rask. Men det behøver faktisk ikke at være tilfældet. Man kan godt være rask, selvom testen er positiv (det kalder man for en falsk positiv), og man kan godt være syg, som testen er negativ (det kalder man for en falsk negativ). Det er fordi, at der ikke findes nogen test, som er helt perfekt!\nDet vil sige, at resultatet af en test vil falde i én af følgende fire kategorier:\n\n\n\n\nSyg\nRask\n\n\n\n\nPositiv test\nSand positiv (SP)\nFalsk positiv (FP)\n\n\nNegativ test\nFalsk negativ (FN)\nSand negativ (SN)\n\n\n\nDet er klart, at man selvfølgelig helst vil have en test, hvor flest mulige lander i diagonalen med sande positiver og sande negativer.\nEn god test skal derfor have følgende egenskaber:\n\nHvis testen anvendes på en syg person, så skal sandsynligheden for at testen bliver positiv være høj.\nHvis testen anvendes på en rask person, så skal sandsynligheden for at testen bliver negativ være høj.\n\nDisse to betingede sandsynligheder kaldes for henholdsvis sensitivitet og specificitet og kan skrives matematisk sådan her:\n\\[\n\\mathrm{sensitivitet } = P(\\textrm{positiv test } | \\textrm{ syg})\n\\] og\n\\[\n\\mathrm{specificitet } = P(\\textrm{negativ test } | \\textrm{ rask})\n\\]\n\n\n\n\n\n\nOpgave 1: Sensitivitet og specificitet\n\n\n\n\n\nVælg en sygdom som du vil arbejde med (eller som din lærer har bestemt, at du skal arbejde med!). Det kan for eksempel være corona, klamydia, RS virus eller influenza.\n\nUndersøg sensitivitet og specificitet for forskellige tests for den sygdom, som du har valgt.\nKan du lave en test hvor sensitiviteten er 100% (du behøver ikke at bekymre dig om specificiteten)?\nKan du lave en test hvor specificiteten er 100% (du behøver ikke at bekymre dig om sensitiviteten)?\n\n\n\n\nDet er klart, at hvis en test skal være god, så ønsker vi, at både sensitiviteten og specificiteten er tæt på 100%."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#prævalens",
    "href": "undervisningsforloeb/test_for_sygdomme.html#prævalens",
    "title": "Test for sygdomme",
    "section": "Prævalens",
    "text": "Prævalens\nBlandt alle dem, vi tester, vil en vis andel i virkeligheden være syge. Det kaldes for sygdommens prævalens. Det vil sige:\n\\[\n\\mathrm{prævalens } = P(\\textrm{syg})\n\\]\n\n\n\n\n\n\nOpgave 2: Prævalens\n\n\n\n\n\n\nUndersøg prævalensen for den sygdom, som du arbejder med.\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Sensitivitet, specificitet og prævalens\n\n\n\n\n\nVi forestiller os nu, at du tester 10000 personer for den sygdom, som du arbejder med og lad os sige, at følgende er oplyst (du må også gerne bruge de tal, som du har fundet i de foregående opgaver):\nPrævalens: \\(P(\\textrm{syg})= 5 \\%\\)\nSensitivitet: \\(P(\\textrm{positiv test } | \\textrm{ syg}) = 86 \\%\\)\nSpecificitet: \\(P(\\textrm{negativ test } | \\textrm{ rask}) = 92 \\%\\)\n\nUdfyld nedenstående tabel (start med at bestemme det samlede antal syge og raske):\n\n\n\n\n\nSyg\nRask\nI alt\n\n\n\n\nPositiv test\n\n\n\n\n\nNegativ test\n\n\n\n\n\nI alt"
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#positiv-og-negativ-prædiktiv-værdi",
    "href": "undervisningsforloeb/test_for_sygdomme.html#positiv-og-negativ-prædiktiv-værdi",
    "title": "Test for sygdomme",
    "section": "Positiv og negativ prædiktiv værdi",
    "text": "Positiv og negativ prædiktiv værdi\nHvis du bliver testet for en sygdom, så vil du enten stå med en positiv eller en negativ test, og du er dybest set slet ikke interesseret i ovenstående sandsynligheder (sensitivitet, specificitet og prævalens)! Du vil i stedet stille dig selv ét af følgende to spørgsmål:\n\nMin test er positiv - hvad er sandsygligheden for, at jeg rent faktisk er syg?\n\neller\n\nMin test er negativ - hvad er sandsygligheden for, at jeg rent faktisk er rask?\n\nDu vil jo gerne undgå, at din test enten er falsk positiv eller falsk negativ.\nOvenstående sandsynligheder kaldes for den positive prædiktive værdi og den negative prædiktive værdi. Skrevet som en betinget sandsynlighed bliver det:\n\\[\n\\text{positiv prædiktiv værdi } = P(\\textrm{syg } | \\textrm{ positiv test})\n\\] og\n\\[\n\\text{negativ prædiktiv værdi } = P(\\textrm{rask } | \\textrm{ negativ test})\n\\]\n\n\n\n\n\n\nOpgave 4: Positiv og negativ prædiktiv værdi\n\n\n\n\n\nHvis du har brugt oplysningerne fra den forrige opgave, skulle du gerne have fået følgende tabel:\n\n\n\n\nSyg\nRask\nI alt\n\n\n\n\nPositiv test\n\\(430\\)\n\\(760\\)\n\\(1190\\)\n\n\nNegativ test\n\\(70\\)\n\\(8740\\)\n\\(8810\\)\n\n\nI alt\n\\(500\\)\n\\(9500\\)\n\\(10000\\)\n\n\n\n\nBenyt ovenstående tabel til at udregne den positive og negative prædiktive værdi.\n\n\n\n\nDu undrer dig måske over, at den positive prædiktive værdi er så forholdsvis lav (36.1%), mens den negative prædiktive værdi er så tæt på 100% (99.2%). Men det er fordi, at den positive og negative prædiktive værdi ikke kun afhænger af testens sensitivitet og specificitet, men også af prævalensen af sygdommen (i den gruppe vi tester iblandt). Hvis vi ser på, hvad vi ved, inden vi overhovedet begynder at teste (det kaldes for prior sandsynligheder), så er det følgende:\n\\[P(\\textrm{syg})= 5 \\%\\]\nog dermed også at\n\\[P(\\textrm{rask})= 95 \\%\\] Det vil sige, at inden vi har taget testen, er vi ret sikre på, at vi er raske. Får vi så (som forventet) en negativ test, så bliver vi bare endnu mere sikre på, at vi er raske (svarende til en negativ prædiktiv værdi på 99.2%). Får vi derimod en positiv test, så bliver vi lidt mere sikre på, at vi er syge. Vi opjusterer altså fra en prior sandsynlighed på 5% til en positiv prædiktiv værdi på 36.1%. Men fordi at sandsynligheden for at være syg på forhånden er så lille, så vil en positiv test stadig efterlade en vis chance for, at vi rent faktisk ikke er syge alligevel!\nDet virker måske underligt, men forestil dig, at vi laver graviditetstest blandt mænd. Da ingen test er perfekt (sensitivitet og specificitet vil altid være under 100%), så vil der før eller siden ske det, at en af mændene tester positiv. Men her er det ret tydeligt, at prævalensen (det vil sige sandsynligheden for at være gravid) blandt dem vi tester (det vil sige mænd) er 0%. Derfor bliver den positive prædiktive værdi også 0%, selvom testen er positiv! Men det er selvfølgelig også lidt åndsvagt at lave graviditetstest blandt mænd…!\nHvis vi tester en hel befolkning for eksempelvis corona, så vil prævalensen være forholdsvis lav. Tester vi derimod kun blandt personer, som har symptomer på corona, så vil prævalens straks være højere. Vi skal nu undersøge, hvilken betydning det har på den positive og negative prædiktive værdi.\n\n\n\n\n\n\nOpgave 5: Positiv og negativ prædiktiv værdi og forskellige prævalenser\n\n\n\n\n\nVi forestiller os igen, at vi tester 10000 personer for den sygdom, som vi arbejder med og lad os sige, at sensitivitet og specificitet er som før, men at prævalensen varierer, som angivet nedenfor:\nPrævalens: \\(P(\\textrm{syg})\\) på henholdsvis \\(1 \\%\\), \\(5 \\%\\), \\(20 \\%\\) og \\(40 \\%\\).\nSensitivitet: \\(P(\\textrm{positiv test } | \\textrm{ syg}) = 86 \\%\\)\nSpecificitet: \\(P(\\textrm{negativ test } | \\textrm{ rask}) = 92 \\%\\)\n\nUdfyld tabeller som nedenstående for hver af de fire forskellige prævalenser (husk at du allerede har tabellen for prævalensen på 5% fra opgave 3!):\n\n\n\n\n\nSyg\nRask\nI alt\n\n\n\n\nPositiv test\n\n\n\n\n\nNegativ test\n\n\n\n\n\nI alt\n\n\n\n\n\n\n\nBeregn positiv prædiktiv værdi (\\(P(\\textrm{syg } | \\textrm{ positiv test})\\)) og negativ prædiktiv værdi (\\(P(\\textrm{rask } | \\textrm{ negativ test})\\)) for de fire forskellige prævalenser og udfyld denne tabel:\n\n\n\n\nPrævalens\nPositiv prædiktiv værdi\nNegativ prædiktiv værdi\n\n\n\n\n\\(1 \\%\\)\n\n\n\n\n\\(5 \\%\\)\n\n\n\n\n\\(20 \\%\\)\n\n\n\n\n\\(40 \\%\\)\n\n\n\n\n\n\nHvad sker der med henholdsvis den positive og den negative prædiktive værdi, når prævalensen stiger? Hvordan giver det mening?\n\n\n\n\n\n\n\n\n\n\nOpgave 6: Hurtigtest for corona\n\n\n\n\n\nLæs artiklen Antigentest gav 47% falsk negative svar.\n\nUdfyld på baggrund af artiklen tabellen med antal raske/syge og positive/negative.\nUdregn testens sensitivitet og specificitet.\nUdregn prævalensen.\nUdregn den positive og negative prædiktive værdi."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#bayes-formel-mest-for-a-niveau",
    "href": "undervisningsforloeb/test_for_sygdomme.html#bayes-formel-mest-for-a-niveau",
    "title": "Test for sygdomme",
    "section": "Bayes formel (mest for A-niveau)",
    "text": "Bayes formel (mest for A-niveau)\nHvis du har læst med her (link til Allans note om Bayes klassificer - eller måske vi skal have splittet de generelle afsnit om betingede sandsynligheder og Bayes formel ud i en note for sig selv?) så ved du, at en betinget sandsynlighed er defineret på følgende måde:\n\\[\nP(A | B) = \\frac{P(A,B)}{P(B)}\n\\]\n(er det ok at skrive \\(A,B\\) i stedet for fællesmængden - der er alligevel ingen mængdelære tilbage i gymnasiet?). Og du har lært, at hvis man bruger det lidt smart, så kan man bevise Bayes’ sætning, som siger, at\n\\[\nP(A | B) = \\frac{P(B|A) \\cdot P(A)}{P(B)}\n\\]\nDet vil vi nu udnytte til at opskrive et udtryk for den positive prædiktive værdi:\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{P(\\text{positiv test } | \\text{ syg}) \\cdot P(\\text{syg})}{P(\\text{positiv test})}\n\\]\nUdnytter vi definitionen af sensitivitet og prævalens, så kan vi omskrive tælleren til\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{\\text{sensitivitet} \\cdot \\text{prævalens}}{P(\\text{positiv test})}\n\\tag{1}\\]\nNu mangler vi at finde et udtryk for nævneren. Der må gælde, at\n\\[\nP(\\text{positiv test}) = P(\\text{positiv test, syg}) + P(\\text{positiv test, rask})\n\\] Bruger vi definitionen på betingede sandsynligheder, kan vi skrive ovenstående som\n\\[\nP(\\text{positiv test}) = P(\\text{positiv test } | \\text{ syg} ) \\cdot P(\\text{syg}) + P(\\text{positiv test } | \\text{ rask}) \\cdot P(\\text{rask})\n\\]\nVi udnytter nu, at \\[P(\\text{rask})+P(\\text{syg})=1\\] og dermed at \\[P(\\text{rask}) = 1- P(\\text{syg})\\] Tilsvarende er også \\[P(\\text{positiv test } | \\text{rask}) = 1-P(\\text{syg test } | \\text{rask})\\] Derfor er\n\\[\nP(\\text{positiv test}) = P(\\text{positiv test } | \\text{ syg} ) \\cdot P(\\text{syg}) + \\left ( 1 - P(\\text{negativ test } | \\text{ rask}) \\right )  \\cdot \\left ( 1- P(\\text{syg}) \\right )\n\\]\nMen nu er sandsynligheden for at teste positiv alene udtrykt ved hjælp af sensitiviteten, specificiteten og prævalensen:\n\\[\nP(\\text{positiv test}) = \\text{sensitivitet} \\cdot \\text{prævalens} + \\left ( 1 - \\text{specificitet} \\right )  \\cdot \\left ( 1- \\text{prævalens} \\right )\n\\] Indsætter vi dette i (1), får vi\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{\\text{sensitivitet} \\cdot \\text{prævalens}}{\\text{sensitivitet} \\cdot \\text{prævalens} + \\left ( 1 - \\text{specificitet} \\right )  \\cdot \\left ( 1- \\text{prævalens} \\right )}\n\\tag{2}\\]\nBruger vi denne formel til at udregne den positive prædiktive værdi i det tilfælde, hvor prævalensen er 5%, sensitiviteten er 86% og specificiteten er 92%, får vi\n\\[\nP(\\text{syg } | \\text{ positiv test}) = \\frac{0.86 \\cdot 0.05}{0.86 \\cdot 0.05 + (1-0.92) \\cdot (1-0.05)} = 0.361=36.1 \\%\n\\]\nDet skulle meget gerne stemme med det, du har fået i opgave 4 (men hvor den positive prædiktive værdi blev beregner på baggrund af tabelværdier).\n\n\n\n\n\n\nOpgave 7: Beregning af positiv prædiktiv værdi for forskellige prævalenser\n\n\n\n\n\nAntag, at vi bruger den samme sensitivitet, specificitet og prævalenser som tidligere:\nPrævalens: \\(P(\\textrm{syg})\\) på henholdsvis \\(1 \\%\\), \\(5 \\%\\), \\(20 \\%\\) og \\(40 \\%\\).\nSensitivitet: \\(P(\\textrm{positiv test } | \\textrm{ syg}) = 86 \\%\\)\nSpecificitet: \\(P(\\textrm{negativ test } | \\textrm{ rask}) = 92 \\%\\)\n\nBrug nu formlen i (2) til at beregn den positive prædiktiv værdi (\\(P(\\textrm{syg } | \\textrm{ positiv test})\\)) for de fire forskellige prævalenser og udfyld denne tabel:\n\n\n\n\nPrævalens\nPositiv prædiktiv værdi\n\n\n\n\n\\(1 \\%\\)\n\n\n\n\\(5 \\%\\)\n\n\n\n\\(20 \\%\\)\n\n\n\n\\(40 \\%\\)\n\n\n\n\n\nKontroller at dit resultat stemmer med det, du fik i opgave 5.\n\n\n\n\n\n\n\n\n\n\nOpgave 8: Formel for negative prædiktiv værdi (svær)\n\n\n\n\n\n\nOpstil en formel for udregning af den negative prædiktive værdi ved at følge udledningen af formlen for den positive prædiktive værdi ovenfor.\nBrug din formel til at udregne negativ prædiktiv værdi for prævalenserne fra opgave 7.\nKontroller at dit resultat stemmer med det du fik i opgave 5."
  },
  {
    "objectID": "undervisningsforloeb/test_for_sygdomme.html#videre-læsning",
    "href": "undervisningsforloeb/test_for_sygdomme.html#videre-læsning",
    "title": "Test for sygdomme",
    "section": "Videre læsning",
    "text": "Videre læsning\nEpidemimatematik: Test for smitte og sygdomme"
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html",
    "href": "undervisningsforloeb/Logistisk_regression.html",
    "title": "Logistisk regression",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nLogistisk vækst\nInvers funktion\nDen naturlige logaritme\n\nTidsforbrug: 10-12 timer."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#introduktion",
    "href": "undervisningsforloeb/Logistisk_regression.html#introduktion",
    "title": "Logistisk regression",
    "section": "Introduktion",
    "text": "Introduktion\nDette forløb anvender i stor udstrækning følgende materiale Logistisk regression .\nForløbet er inddelt i 6 dele + et eksamensspørgsmål med en cirka tidsangivelse til hver del.\nTil sidst er der en kort lærervejledning, som elever kan ignorere."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#logistisk-regression-og-odds",
    "href": "undervisningsforloeb/Logistisk_regression.html#logistisk-regression-og-odds",
    "title": "Logistisk regression",
    "section": "Logistisk regression og odds",
    "text": "Logistisk regression og odds\n\n\n\n\n\n\nDel 1 - logistisk regression\n\n\n\n\n\nForventet tid ca. 90 min.\n\nLæs afsnittet Logistisk regression og hjerte-kar-sygdom i materialet.\nHent Excelfilen med de 2000 datapunkter.\nGenskab figur 1 i materialet ud fra de første 100 punkter og overvej, hvorfor det er en dårlig ide at bruge alle 2000 punkter. Du kan enten gøre dette i dit eget CAS værktøj eller i Excel. Hvis du ikke er vant til at lave grafer i Excel, er det nok lettest at anvende det program, som du normalt bruger.\nInddel de 2000 datapunkter i intervaller som vist i tabel 1 i materialet. Dette kan f.eks. gøres vha. pivottabel i Excel som beskrevet nedenfor.\nLav lineær regression ud fra data i tabel 1 og genskab derved figur 3. Husk at bruge midtpunktet af hvert interval. Brug det program, du normalt anvender til regressionen.\n\n\n\n\n\n\n\n\n\n\nDel 1 - hjælp til Pivottabel i Excel\n\n\n\n\n\nHent Excel filen med de 2000 datapunkter.\nVælg “Indsæt pivottabel” i Excel og vælg dataområde og placering. Bemærk, at du skal gøre dette under menuen “Indsæt”, og hvis du finder “pivotdiagram” et sted, er det ikke det rigtige, det skal være pivottabel. Når du klikker på “Eksisterende regneark” skal du klikke det sted i regnearket, hvor du vil have pivottabellen placeret.\n\nIndstil pivottabellen som vist på figuren nedenfor. Bemærk, at du skal trække Blodtryk og Syg ned fra listen for oven til Kolonner, Rækker og Værdier i bunden. Under Værdier vil der i første omgang stå “Sum af Syg”, så klik på pilen, vælg “Værdifeltindstillinger” og ændr det til “Antal af syg”.\n\nHøjreklik på én af værdierne for blodtryk i pivottabellen, vælg “Grupper” og vælg indstillinger for intervallerne.\n\nHerefter skal det se således ud:\n\n\n\n\n\n\n\n\n\n\nDel 2 - Odds og første bevis\n\n\n\n\n\nForventet tid ca. 75 min\n\nLæs afsnittet “Odds” i materialet.\nLav de tilhørende opgaver i materialet, dog ikke bonus opgaven.\nLærergennemgang af, at \\(O(p)\\) er voksende vha. differentiation og monotoni."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#regressionsmodel-og-logit",
    "href": "undervisningsforloeb/Logistisk_regression.html#regressionsmodel-og-logit",
    "title": "Logistisk regression",
    "section": "Regressionsmodel og logit",
    "text": "Regressionsmodel og logit\n\n\n\n\n\n\nDel 3 - Den logistiske regressionsmodel\n\n\n\n\n\nForventet tid ca. 45 min\n\nLæs afsnittet “Den logistiske regressionsmodel” i materialet.\nLav de tilhørende opgaver i materialet. Hint til sidste spørgsmål - start med at overveje, hvilken værdi \\(e^{-a\\cdot x+b}\\) skal have, og derefter hvilken værdi \\(a\\cdot x+b\\) skal have, og til sidst \\(x\\).\n\n\n\n\n\n\n\n\n\n\nDel 4 - Logit og andet bevis\n\n\n\n\n\nForventet tid ca. 90 min\n\nRepetition af, hvad en invers funktion er.\nLæs afsnittet i materialet med fokus på at kunne isolere \\(p(x)\\) i \\(logit(x)\\).\nEfterfølgende fælles gennemgang på tavlen, da beviset er med i eksamensspørgsmået."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#fortolkning-og-bestemmelse-af-parametrene",
    "href": "undervisningsforloeb/Logistisk_regression.html#fortolkning-og-bestemmelse-af-parametrene",
    "title": "Logistisk regression",
    "section": "Fortolkning og bestemmelse af parametrene",
    "text": "Fortolkning og bestemmelse af parametrene\n\n\n\n\n\n\nDel 5 - Fortolkning\n\n\n\n\n\nForventet tid ca. 60 min\n\nLæs det meste af afsnittet “Fortolkning af parametrene i den logistiske regressionsmodel” i materialet. Stop efter eksemplet, der ender med en vækst på 22%. Det er ikke afgørende, at du får helt styr på dette afsnit, men det er vigtigt, at du prøver at tilpasse \\(a\\) og \\(b\\), så grafen passer til punkterne, og har en forståelse for, hvad der sker.\nLav de tilhørende opgaver i materialet.\n\n\n\n\n\n\n\n\n\n\nDel 6 - Maximum Likelihood Estimation\n\n\n\n\n\nForventet tid ca. 120 min\n\nLærergennemgang af teorien.\nLæs derefter afsnittet “Bestemmelse af a og b med Excels problemløser-værktøj” i materialet.\nAnvend igen Excel arket med de 2000 datapunkter, og benyt problemløsning i Excel til at vise, at \\(a=0,022\\) og \\(b=-3,9\\) optimerer løsningen.\nLav de tilhørende opgaver i materialet.\n\n\n\n\n\n\n\n\n\n\nEksamensspørgsmål: Differentialregning og logistisk regression\n\n\n\n\n\nForventet tid ca. 120 min\nDifferentialregning og logistisk regression\n\nForklar om logistisk regression, herunder odds.\nDifferentier \\(O(x)= {p \\over (1-p)}\\) og vis derved, at \\(O(x)\\) er voksende.\nIsolerer \\(p(x)\\) i \\(logit(p)\\)."
  },
  {
    "objectID": "undervisningsforloeb/Logistisk_regression.html#lærervejledning",
    "href": "undervisningsforloeb/Logistisk_regression.html#lærervejledning",
    "title": "Logistisk regression",
    "section": "Lærervejledning",
    "text": "Lærervejledning\n\n\n\n\n\n\nTil læreren\n\n\n\n\n\nI del 1 kan inddelingen i intervaller givet også ske i eleverne eget CAS værktøj, hvis det foretrækkes. Der kan dog evt. være en pointe i at lade eleverne stifte bekendtskab med begrebet pivottabel i Excel uanset.\nI del 2 i beviset for, at \\(O(p)\\) er voksende, kan differentiationen laves på forskellige måder, som det måtte passe bedst ind for det konkrete hold:\n\nVha, produktreglen og sammensat.\nVha. kvotientreglen (enten bevist eller blot gennemgået). \\(O'(p) = {p' \\cdot (1-p) - p \\cdot (1-p)' \\over (1-p)^2} = {1 \\cdot (1-p) - p \\cdot (-1) \\over (1-p)^2} = {1 \\over (1-p)^2}\\)\nVha. dobbelt sammensat.\n\nI del 4 kan det overvejes, om eleverne selv, evt i gruppe, skal læse udledningen, eller om den skal ske ved lærergennemgang.\nI del 5 er det ikke nødvendigt, at eleverne forstår alle detaljer, en rimelig forståelse af ideen kan være tilstrækkelig.\nI del 5 kan man godt lade eleverne læse hele afsnittet, men den sidste del er ikke så central, og ligner meget et kendt bevis fra eksponentielle udviklinger.\nI del 6 anvendes black-box, men der kan f.eks. sammenlignes med Newton-Raphsons metode til bestemmelse af nulpunkter."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html",
    "title": "Hvem ligner du mest?",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nAfstand mellem to punkter.\n\nTidsforbrug: Ca. 2 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#introduktion",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#introduktion",
    "title": "Hvem ligner du mest?",
    "section": "Introduktion",
    "text": "Introduktion\nVi har apps på vores telefoner eller computere, som ud fra et billede kan genkende personer eller fra nogle få strofer kan genkende en sang. Der er scannere i lufthavne og andre steder, som kan genkende farlige ting, og biler har autopiloter, der selv holder afstanden til forankørende. Vi har også apps, som går den anden vej, og forvrænger et billede af en person, så personen bliver svær at genkende, men ofte alligevel kan genkendes, selvom ansigtet er fordrejet.\nSå alle steder og hele tiden foregår der bevist eller ubevist en skelnen mellem forskellige kategorier, men hvordan foregår denne skelnen i grunden? Hvis vi skulle svare fyldestgørende på dette spørgsmål, om overhovedet muligt, ville det nok betyde et langt studie på universitetet og sikkert mere end dette, men lad os starte med et meget simpelt eksempel, og tage den derfra.\nVi får brug for din viden om afstande mellem punkter, men kommer også til senere at se på andre former for afstande. Det er en fordel af lave opgaverne i grupper, da der kan blive en del af diskutere."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#video-hvem-ligner-du-mest",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#video-hvem-ligner-du-mest",
    "title": "Hvem ligner du mest?",
    "section": "VIDEO: Hvem ligner du mest?",
    "text": "VIDEO: Hvem ligner du mest?\nI denne video gives en kort introduktion til forløbet."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-1-afstand-mellem-to-punkter",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-1-afstand-mellem-to-punkter",
    "title": "Hvem ligner du mest?",
    "section": "Case 1 – Afstand mellem to punkter",
    "text": "Case 1 – Afstand mellem to punkter\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\nPå figur 1 nedenfor er der \\(10\\) røde punkter, \\(10\\) blå punkter og \\(10\\) grønne punkter – samt et enkelt gråt punkt \\(P\\) i midten. Et af de blå punkter er særligt markeret, men da det ligger ret langt fra \\(P\\) bør det nok ikke betyde så meget for, hvilket farve \\(P\\) skal have, som de punkter, der ligger tættere på \\(P\\)\nVurdér ud fra de øvrige punkter i nærheden af \\(P\\), om du synes, at \\(P\\) bør være rødt, blåt eller grønt så det mest ligner sine naboer.\n\n\n\n\n\n\n\n\n\nFigur 1: Koordinatsystem med \\(10\\) røde punkter, \\(10\\) blå punkter og \\(10\\) grønne punkter – samt et enkelt gråt punkt \\(P\\).\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nPå figur 2 er der andre \\(31\\) punkter, samt en cirkel med radius \\(10\\) omkring det grå punkt \\(P(15,15)\\).\nTæl hvor mange røde, blå og grønne punkter, der ligger inde i cirklen. Kan det bruges til at beslutte, hvilken farve det grå punkt bør have?\n\n\n\n\n\n\n\n\n\nFigur 2: Koordinatsystem med \\(31\\) punkter, samt en cirkel med radius \\(10\\) omkring det grå punkt \\(P(15,15)\\)\n\n\n\n\n\n\n\n\n\nOpgave 2, fortsat\n\n\n\n\n\nHvilket resultat giver det, hvis cirklens radius kun var halvt så stor? Brug app’en nedenfor.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\nDet går nok ikke i længden blot at ville vurdere på øjemål, så du må til at regne lidt. I tabellen herunder er koordinater og farver på de \\(10\\) punkter, der ligger tættest på det grå punkt i opgave 2.\nUdregn afstanden fra det grå punkt \\(P(15,15)\\) til hver af disse \\(10\\) punkter.\nAfgør så, hvor mange af hver farve, der ligger indenfor en cirkel med radius \\(5\\) omkring det grå punkt. Det er nok specielt det blå punkt lige på kanten af cirklen, hvor beregningen er vigtig, men hvis en computer skal lave arbejdet automatisk, vil den jo beregne alle afstandene, da den ikke bare kan “kigge på figuren”, som et menneske kan.\nHvilken farve tyder det på, at det grå punkt bør have?\nTabellens data er punkter i kommatal. F.eks. er det første blå punkt \\((13,8 ; 19,9)\\), så det har x-koordinaten \\(13,8\\) og y-koordinaten \\(19,9\\).\n\n\n\n\n\n\n\n\n\n\n\n\n\nFarve\n1\n2\n3\n4\n\n\n\n\nBlå\n\\((13,8 ; 19,9)\\)\n\\((8,2 ; 14,9)\\)\n\\((16,4 ; 14,1)\\)\n\\((15,5 ; 13,1)\\)\n\n\nRød\n\\((10,6 ; 16,0)\\)\n\\((16,3 ; 15,2)\\)\n\\((15,6 ; 11,3)\\)\n\n\n\nGrøn\n\\((11,1 ; 18,6)\\)\n\\((16,4 ; 17,5)\\)\n\\((21,7 ; 13,4)\\)\n\n\n\n\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\nOvervej, hvad der sker, hvis cirklens radius vælges som en meget lille værdi eller som en meget stor værdi i forhold til at bruge metoden til at bestemme, hvilken farve det grå punkt bør have. Kan det give problemer?\n\n\n\n\n\n\n\n\n\nOpgave 5\n\n\n\n\n\n\nI app’en herunder er \\(27\\) andre punkter indsat i et koordinatsystem, og der er tegnet en cirkel med centrum i det grå punkt \\(P(15,15)\\). Ændr på radius af cirklen og se, om det gør en forskel.\nDiskutér, hvilken radius, der er bedst.\n\n\n\n\n\n\n\nAfslutning på case 1\nDet bliver nok klart, at der er brug for en metode til at beslutte, hvor stor radius skal være for at få det bedste resultat. Kort og lidt simpelt forklaret, involverer det noget, som man kalder træningsdata og testdata. Man har f.eks. 1000 punkter, som man kender farven på. Man lader så som om, at man ikke kender farven på f.eks. 200 af punkterne (som man så kalder testdata). Så bruger man de øvrige 800 punkter (træningsdata) til at forudsige farven af hver af de 200 punkter i testdata. Dette gør man for forskellige værdier af radius, hvorefter man vælger den radius, der forudsiger flest af de 200 punkters farve korrekt. Hvis f.eks. radius 5 forudsiger 121 punkters farve korrekt, radius 10 furudsiger 135 punkters farve korrekt, og radius 20 kun forudsiger 87 punkters farve korrekt, så har radius 10 jo klaret sig bedst."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-2-manhattan-afstand",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-2-manhattan-afstand",
    "title": "Hvem ligner du mest?",
    "section": "Case 2 – Manhattan afstand",
    "text": "Case 2 – Manhattan afstand\nI nogle situationer giver den almindelige afstand mellem punkter ikke så god mening. F.eks. er de fleste veje på Manhattan i New York enten nord-syd eller øst-vest, så man kan ikke bare gå eller køre “på skrå”, men kun lodret eller vandret.\nHvis vi ser på punkterne \\(P(2,3)\\) og \\(Q(5,7)\\), så er den almindelige afstand \\(5\\) vha. Pythagoras, mens Manhattan afstanden er \\(3+4=7\\). Dette er illustreret på figur 3.\n\n\n\n\n\n\nFigur 3: Den almindelige afstand mellem punkterne \\(P(2,3)\\) og \\(Q(5,7)\\) er \\(5\\), mens Manhattan afstanden er \\(7\\).\n\n\n\n\n\n\n\n\n\nOpgave 6\n\n\n\n\n\nIndtegn punkterne \\(A(1,7)\\), \\(B(3,4)\\) og \\(C(5,6)\\) i et koordinatsystem.\nUdregn både almindelig afstand og Manhattan afstand mellem hvert par af punkter.\n\n\n\n\n\n\n\n\n\nOpgave 7\n\n\n\n\n\nI eksemplet og i opgave 6 var Manhattan afstanden større end den almindelige afstand, men kan Manhattan afstanden være mindre end den almindelige afstand eller kan de to afstande være ens?\n\n\n\n\n\n\n\n\n\nOpgave 8\n\n\n\n\n\nSe på figur 4 fra opgave 2 igen.\nPunkterne inde i cirklen har en almindelig afstand på under \\(10\\) til det grå punkt, men hvilke af punkterne har en Manhattan afstand på under \\(10\\) til det grå punkt?\nDen almindelige afstand giver en cirkel med det grå punkt i centrum, men hvilken figur giver Manhatten afstand omkring det grå punkt?\nHvilken farve bør det grå punkt derfor have, hvis Manhattan afstanden benyttes? Giver det samme resultatet, som du fik i opgave 2?\n\n\n\n\n\n\n\n\n\nFigur 4: Koordinatsystem med \\(31\\) punkter, samt en cirkel med radius \\(10\\) omkring det grå punkt \\(P(15,15)\\)\n\n\n\n\n\n\n\n\n\nOpgave 9\n\n\n\n\n\nOpstil en formel for den almindelige afstand mellem to punkter med koordinaterne \\((x_1, y_1)\\) og \\((x_2, y_2)\\). Det er en formel, du kender i forvejen.\nOpstil tilsvarende en formel for Manhattan afstanden. Det er nok ikke en formel, du har set før.\nDu kan læse mere om Manhattan afstanden her."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-3-hvor-ens-er-to-tekster",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-3-hvor-ens-er-to-tekster",
    "title": "Hvem ligner du mest?",
    "section": "Case 3 – Hvor ens er to tekster?",
    "text": "Case 3 – Hvor ens er to tekster?\nI forbindelse med at undersøge om en tekst, f.eks. en dansk stil, er plagiat, bliver det relevant at sammenligne, hvor ens to tekster er. Helt så avanceret bliver det dog ikke her.\nVi vil kun se meget simpelt på ord med \\(5\\) bogstaver, og hvordan man f.eks. kan måle afstande mellem forskellige ord. Vi vil se på alle kombinationer af \\(5\\) bogstaver, også f.eks. xtmsp, selvom de ikke er normale ord.\n\n\n\n\n\n\nOpgave 10\n\n\n\n\n\nI tabellen herunder ses ordet “nedes” sammen med ordene “model”, “metal” og “nudts”.\n\n\n\n\n\n\n\n\n\n\n\n\n\nn\ne\nd\ne\ns\n\n\n\n\n\n\nm\no\nd\ne\nl\n\n\n\n\nm\ne\nt\na\nl\n\n\n\n\nn\nu\nd\nt\ns\n\n\n\n\nHvilket af ordene “model”, “metal” og “nudts” synes du, at ordet “nedes” ligner mest. Begrund dit svar.\n\n\n\n\n\n\n\n\n\nOpgave 11\n\n\n\n\n\nHvis vi vælger, at afstanden mellem to ord er antallet af bogstaver, som er forskellige incl. placering, så er afstanden mellem “xtmsp” og “xmtsq” \\(3\\), da kun \\(2\\) af de \\(5\\) bogstaver matcher incl. placering i de to ord, nemlig x og s.\nUdregn med den metode afstanden mellem “nedes” og hver af de \\(3\\) ord i opgave 10. Var det sådan du allerede havde gjort det i opgave 10, eller gav dette et andet resultat?\n\n\n\n\n\n\n\n\n\nOpgave 12\n\n\n\n\n\nOvervej og diskuter andre måder at regne afstand mellem to ord på hver \\(5\\) bogstaver. Det kunne f.eks. være noget, hvor ombytning af to nabobogstaver giver mindre afstand end helt tilfældige andre bogstaver, så f.eks. “kolon” og “kloon” er tættere på hinanden end “kolon” og “kston”."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-4-dna-strenge-og-alignment",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-4-dna-strenge-og-alignment",
    "title": "Hvem ligner du mest?",
    "section": "Case 4 – DNA-strenge og alignment",
    "text": "Case 4 – DNA-strenge og alignment\nUden i øvrigt at komme ind på biologien repræsenteres DNA som meget lange tekststrenge. Når mennesker og chimpanser er meget ens, kommer det til udtryk ved, at DNA-strengen for et menneske ligner den for en chimpanse meget, der er altså en kort afstand mellem DNA for et menneske og DNA for en chimpanse. Indenfor biologien kaldes dette for alignment. I stedet for at sammenligne på DNA niveau, sammenlignes også nogle gange på aminosyre niveau, hvilket vi vil bruge her,\nFølgende eksempel, der viser et meget lille udsnit af sådanne koder fra mus, rotter, mennesker og gær er taget fra Tema12-Link5.pdf (nucleus.dk), der kan anbefales, hvis man ønsker at arbejde mere med alignment.\n\n\n\nDyr\nKode\n\n\n\n\nMus\nS W A W A E G W T R Y G P\n\n\nRotte\nK W V W A E G W T R Y G P\n\n\nMenneske\nA W A W A E G W T R Y G P\n\n\nGær\nE W L R K P G W V K Y V P\n\n\n\nHvis afstanden her regnes som antal bogstaver, der er forskellige, ses det at afstanden mellem mus og rotte er på \\(2\\), som vist nedenfor.\n\n\n\nDyr\nKode\n\n\n\n\nMus\nS W A W A E G W T R Y G P\n\n\nRotte\nK W V W A E G W T R Y G P\n\n\n\n\n\n\n\n\n\nOpgave 13\n\n\n\n\n\nUdregn på tilsvarende vis afstandene mellem mus-menneske, mus-gær, rotte-menneske, rotte-gær og menneske-gær.\n\n\n\nNår resultatet sikkert virker overraskende, skyldes det, at vi kun har set på et meget lille udsnit af DNA for de fire. I figur 5 har man set på hele det protein, som udsnittet stammer fra, og her bliver resultatet mere som forventet.\n\n\n\n\n\n\nFigur 5: De faktiske afstande mellem mus-menneske, mus-gær, rotte-menneske, rotte-gær og menneske-gær."
  },
  {
    "objectID": "undervisningsforloeb/hvem_ligner_du_mest.html#case-5-hvilken-politiker-er-du-mest-enig-med",
    "href": "undervisningsforloeb/hvem_ligner_du_mest.html#case-5-hvilken-politiker-er-du-mest-enig-med",
    "title": "Hvem ligner du mest?",
    "section": "Case 5 – Hvilken politiker er du mest enig med?",
    "text": "Case 5 – Hvilken politiker er du mest enig med?\nOp til både folketingsvalg og kommunal- og regionalvalg kan man svare på en række spørgsmål, hvorefter ens svar bliver sammenlignet med politikernes svar på de samme spørgsmål. Herefter kan man så se, hvem man er mest enig med.\nHer er et eksempel fra kommunal- og regionalvalget i 2021.\nTag kandidattesten Kommunalvalg 2021 - Altinget - Alt om politik: altinget.dk\n\n\n\n\n\n\nOpgave 14\n\n\n\n\n\nKlik på linket ovenfor, vælg din egen kommune i testen og besvar spørgsmålene. Se derefter, hvem dine svar er mest enige med, og hvor mange procent enige I er.\n\n\n\nMen hvordan virker det mon? Hvordan vurderes, hvilken kandidat du er mest enig med, og hvordan udregnes, hvor mange procent enige I er?\nTil hvert spørgsmål kan der svares “helt uenig”, “uenig”, “enig” eller “helt enig”, men desuden er der en skjult “neutral” mulighed i midten, som man ikke kan vælge.\n\n\n\nHelt uenig\nUenig\nNeutral\nEnig\nHelt enig\n\n\n\nAfstanden mellem to svar regnes som antal “felter” i tabellen, så afstanden mellem Uenig og Enig er \\(2\\), mens afstanden mellem Enig og Helt enig er \\(1\\), og den største afstand er \\(4\\).\nI figur 6 ses en persons svar og et partis svar på \\(23\\) spørgsmål til kommunalvalget i 2021. Ved et partis svar forstås det svar, som flest af kandidaterne fra partiet har givet (ved lighed afgjort ud af, hvilken kandidat, der står først på listen). Så det er typetallet (typesvaret), der er anvendt for partierne, ikke gennemsnittet af svarene fra partiets kandidater. Figuren er fra testen på Altinget. Bemærk, at antallet af spørgsmål kan variere fra kommune til kommune, så du har måske færre eller flere spørgsmål.\n\n\n\n\n\n\nFigur 6: En persons svar (sort) og et partis svar (rød) på \\(23\\) spørgsmål til kommunalvalget i 2021.\n\n\n\nAfstanden i det første spørgsmål er \\(1\\), afstanden i det andet spørgsmål også \\(1\\) og afstanden i det tredje spørgsmål er \\(2\\) pga. den skjulte “neutral” mulighed i midten.\n\n\n\n\n\n\nOpgave 15\n\n\n\n\n\nDe 3 første afstand er altså 1, 1 og 2. Udregn afstanden for hver af de øvrige \\(20\\) spørgsmål.\nLæg så afstandene sammen, hvilket svarer til en form for Manhattan afstand, da afstanden regnes for hvert enkelt spørgsmål for sig. Hvilken samlet afstand giver det?\n\n\n\n\n\n\n\n\n\nOpgave 16\n\n\n\n\n\nHvad er den mindst mulig samlede afstand for de \\(23\\) spørgsmål? Hvordan skal svarene for partiet og for vælgeren se ud fra at få denne afstand?\nHvad er den størst mulige afstand, og hvordan skal svarene så se ud?\n\n\n\n\n\n\n\n\n\nOpgave 17\n\n\n\n\n\nPå figur 7 ses det, at siden angiver, at enigheden med Socialdemokratiet er på \\(79 \\%\\).\nOvervej, hvordan den afstand du udregnede i opgave 15 og den største mulige afstand, som du fandt i opgave 16, kan betyde, at enigheden er \\(79 \\%\\).\n\n\n\n\n\n\n\n\n\nFigur 7: På siden angives det, at enigheden med Socialdemokratiet er på \\(79 \\%\\).\n\n\n\n\n\n\n\n\n\nOpgave 18\n\n\n\n\n\nVend tilbage til dine egne svar på testen.\nBeregn afstand og procent i forhold til den kandidat, du var mest enig med, og den kandidat, du var mest uenig med.\nBeregn desuden afstand og procent til det parti, du var mest enig med, og til det parti, du var mest uenig med.\nPasser dine udregninger med sidens procenter?\n\n\n\n\n\n\n\n\n\nOpgave 19 (svær)\n\n\n\n\n\nDen kandidat, som svarene i opgave 15 var mest enig med, giver en procent på \\(76 \\%\\), så procenten for samtlige kandidater fra Socialdemokratiet er altså lavere end procenten for selve partiet.\nDet virker måske umiddelbart underligt. Overvej, hvorfor det faktisk er korrekt ud fra den metode, som siden anvender til beregningerne.\nDiskutér derefter, om procenten for partiet kunne være beregnet anderledes."
  },
  {
    "objectID": "undervisningsforloeb/opklar_et_mord.html",
    "href": "undervisningsforloeb/opklar_et_mord.html",
    "title": "Opklar et mord!",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDifferentialregning\nOptimering\n\nTidsforbrug: Ca. 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/opklar_et_mord.html#hvad-er-et-kunstigt-neuralt-netværk",
    "href": "undervisningsforloeb/opklar_et_mord.html#hvad-er-et-kunstigt-neuralt-netværk",
    "title": "Opklar et mord!",
    "section": "Hvad er et kunstigt neuralt netværk?",
    "text": "Hvad er et kunstigt neuralt netværk?\nSCREENCAST om neurale netværk - uden at det bliver for teknisk."
  },
  {
    "objectID": "undervisningsforloeb/opklar_et_mord.html#hvem-har-afsat-fingeraftryk-i-de-forskellige-lokaler",
    "href": "undervisningsforloeb/opklar_et_mord.html#hvem-har-afsat-fingeraftryk-i-de-forskellige-lokaler",
    "title": "Opklar et mord!",
    "section": "Hvem har afsat fingeraftryk i de forskellige lokaler?",
    "text": "Hvem har afsat fingeraftryk i de forskellige lokaler?\nI alt 10 elever er under mistanke. Det drejer sig om:\n\n\nAlexander\nBent\nCecilie\nHugo\nKaroline\nMette\nSigne\nSigurd\nValdemar\nVictoria\n\nPolitiet har taget syv forskellige fingeraftryk fra hver elev (data findes her). På skolen har man i forskellige lokaler også fundet fingeraftryk - man ved bare ikke, hvem fingeraftrykkene stammer fra (data findes her).\nAlle fingeraftryk, som er fundet i lokalerne, er nummeret fra 101-110. Fingeraftrykkene er fundet i følgende lokaler:\n\n\n\nFysik\nKemi\nBiotek\nMatematik\nBiologi\n\n\n\n\n107\n102\n101\n104\n103\n\n\n109\n106\n105\n108\n110\n\n\n\nI skal nu ud fra fingeraftrykkene hjælpe politiet med at afgøre, hvem der har befundet sig i de forskellige lokaler.\nVi skal her gøre opmærksom på, at det, vi gør her, ikke er sådan politiet arbejder med fingeraftryk. Dette er flot for at vise, hvordan man kunne bruge kunstig intelligens.\n\n\n\n\n\n\nOpgave 1: Træn forskellige neurale netværk\n\n\n\n\n\nStart med at se denne SCREENCAST, som handler om hvordan man træner et kunstigt neuralt netværk i Orange.\n\nVed hjælp af træningsdata skal I træne forskellige neurale netværk, som kan prædiktere hvem et givent fingeraftryk tilhører. Prøv med forskellige neurale netværk af forskellig dybde (dvs. et varierende antal skjulte lag) og forskellig antal neuroner i hvert skjult lag.\nSammenlign jeres forskellige modeller vha. ”Test and Score” (brug krydsvalidering - og husk at CA skal være tæt på 1). ”Test and Score” skal som input have billederne fra træningsdata og de forskellige modeller (dvs. de forskellige neurale netværk).\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Lav en prædiktion på baggrund af den valgte model\n\n\n\n\n\nSe denne SCREENCAST som viser hvordan man kan prædiktere i Orange ud fra en valgt model.\n\nVælg den bedste model og brug den til at prædiktere hvem de ti forskellige fingeraftryk (101-110) stammer fra. Brug ”Predictions” - ”Predictions” skal som input have den valgte model (og den valgte model skal have billederne som input) samt billederne i testdatasættet.\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Hvem har været hvor?\n\n\n\n\n\n\nNoter her hvem der er hvem:\n\n\n\n\nLokale\nNummer\nNavn\n\n\n\n\nFysik\n107\n\n\n\nFysik\n109\n\n\n\nKemi\n102\n\n\n\nKemi\n106\n\n\n\nBiotek\n101\n\n\n\nBiotek\n105\n\n\n\nMatematik\n104\n\n\n\nMatematik\n108\n\n\n\nBiologi\n103\n\n\n\nBiologi\n110\n\n\n\n\n\n\n\n\n\n\n\n\n\nOpgave 4: Hvem er morderen?\n\n\n\n\n\nPolitiet kan nu oplyse, at mordet blev begået i matematik… 😱\nTager du nummeret for hver af de to personer, som befandt sig i matematik, trækker 100 fra og dividerer med 2, så har du antallet af bogstaver i morderens navn.\n\nHvem er morderen?"
  },
  {
    "objectID": "sro.html",
    "href": "sro.html",
    "title": "SRO",
    "section": "",
    "text": "I arbejdet med studieretningsopgaven kan matematik og AI indgå i et samarbejde med en lang række andre fag. Konkrete forløb er beskrevet herunder."
  },
  {
    "objectID": "sro.html#samfundsfag-og-matematik",
    "href": "sro.html#samfundsfag-og-matematik",
    "title": "SRO",
    "section": "Samfundsfag og matematik",
    "text": "Samfundsfag og matematik\n\n\n\n\n\n\nUlighed\n\n\n\n\n\nDer tages afsæt i følgende holdninger til ulighed uden at sætte partier på:\n\n”Blå blok”: Øget ulighed er en drivkraft for øget vækst, som giver øget velstand for alle.\n”Rød blok”: Større lighed er et kendetegn ved de bedst fungerende demokratier og lykkeligste samfund. Det giver samtidig de bedste muligheder for alle og samlet set de bedste rammevilkår for virksomheder.\n\n\nProblemformulering\nHvad er ulighed, og er det et problem i Danmark?\n\nRedegør kort for begrebet ulighed - herunder holdninger til ulighed.\nForklar hvordan kunstig intelligens kan bruges ved kandidattests i forbindelse med valg og lav en simpel kandidattest ud fra nogle få velvalgte spørgsmål om aspekter af ulighed, som skal give en anbefaling om at stemme på enten rød eller blå blok.\nKom desuden ind på forskellige matematiske mål for ulighed herunder Gini-koefficienten.\nDiskussionsspørgsmålet er op til jer (Måske kan uligheden begrænses? Skal den begrænses? Hvordan kan den begrænses? Fordele og ulemper ved ulighed og så videre).\n\n\n\nMaterialer\nNoten om perceptroner.\nPerceptron app - under udarbejdelse.\nJensby, Jakob & Brøndum, Peter (2020): Ulighedens mange ansigter."
  },
  {
    "objectID": "apps.html",
    "href": "apps.html",
    "title": "AI apps",
    "section": "",
    "text": "Perceptron app\n\n\nHer kan du træne en perceptron med dine egne data. Der er mulighed for at vælge forskellige aktiveringsfunktioner sammen med den kvadratiske tabsfunktion.\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "AI - Aalborg Intelligence",
    "section": "",
    "text": "Her på sitet finder du materiale og undervisningsforløb om kunstig intelligens rettet mod danske gymnasieelever.\n\n\n\n\n\n\n\n\n\n\nUndervisningsforløb\n\n\nForskellige undervisningsforløb til matematik i gymnasiet, som inddrager AI. Der findes forløb til både A-, B- og C-niveau.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMaterialer\n\n\nNoter om diverse AI relaterede emner.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRO\n\n\nIdéer til hvordan AI kan inddrages i SRO.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSRP\n\n\nIdéer til hvordan AI kan inddrages i SRP.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI apps\n\n\nDiverse apps til træning af kunstig intelligens.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nReferencer\n\n\nDiverse referencer til andre AI materialer.\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items\n\n\nProjektet “AI - Aalborg Intelligence” er finansieret af Novo Nordisk Fonden og løber frem til 2026.\nSiden her er i et tidligt stadie med ganske få tilgængelige materialer på nuværende tidspunkt (2023), og mere materiale tilføjes løbende."
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html",
    "href": "undervisningsforloeb/polynomium.html",
    "title": "AI og rødder i andengradspolynomier",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nRette linjer.\nAndengradspolynomier og rødder.\n\nTidsforbrug: Ca. 90 minutter.\nVi anbefaler, at I i dette forløb arbejder i grupper på 3-4 elever."
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html#andengradspolynomier-og-rødder",
    "href": "undervisningsforloeb/polynomium.html#andengradspolynomier-og-rødder",
    "title": "AI og rødder i andengradspolynomier",
    "section": "Andengradspolynomier og rødder",
    "text": "Andengradspolynomier og rødder\nLad os lige starte med at minde om, at et andengradspolynomium er en funktion med en forskrift på formen \\[\nf(x)=ax^2 + bx + c, \\quad a \\neq 0\n\\] Grafen for et andengradspolynomium kaldes som bekendt for en parabel. I figur 1 ses tre eksempler på sådanne parabler.\n\n\n\n\n\n\nFigur 1: Graferne for tre forskellige andengradspolynomier.\n\n\n\nHvis vi løser andengradsligningen \\[\nf(x)=ax^2 + bx + c=0\n\\] finder vi andengradspolynomiets rødder. Men at løse \\(f(x)=0\\), svarer netop til at bestemme, hvor den tilhørende parabel skærer \\(x\\)-aksen. I figur 1 kan vi se, at den grønne parabel skærer \\(x\\)-aksen to steder. Det vil sige, at det tilhørende andengradspolynomium har to rødder. Den røde parabel skærer \\(x\\)-aksen ét sted – det tilhørende andengradspolynomium har altså én rod. Endelig kan vi se, at den blå parabel slet ikke skærer \\(x\\)-aksen, og det tilhørende andengradspolynomium har derfor ingen rødder.\nDu husker nok, hvordan man bestemmer antallet af rødder i et andengradspolynomium. Vi har brug for diskriminanten \\(d\\):\n\\[\nd = b^2-4ac\n\\tag{1}\\]\nOg der gælder så, at \\[\n\\begin{aligned}\n&d&lt;0: \\quad f \\text{ har ingen rødder} \\\\\n&d=0: \\quad f \\text{ har én rod} \\\\\n&d&gt;0: \\quad f \\text{ har to rødder} \\\\\n\\end{aligned}\n\\]\nIdéen er nu at undersøge, om vi kan bruge kunstig intelligens til at afgøre1, om et andengradspolynomium overhovedet har nogle rødder alene ude fra de tre koefficienter \\(a\\), \\(b\\) og \\(c\\) – og helt uden at kende noget til diskriminantformlen i (1)!\n1 Det er klart, at der er intet nyt under solen her. Vi kan jo bare selv beregne diskriminanten og svare på spørgsmålet. Men formålet er her at lære lidt om, hvad det vil sige at bruge kunstig intelligens i et tilfælde, hvor vi allerede selv kender svaret. Desuden findes der ingen lukkede løsningsformler for at bestemme rødder i et polynomium, så snart graden af polynomiet er \\(5\\) eller derover. Så idéen kan generaliseres, og så er den måske slet ikke så tosset endda!Inden vi går i gang, vil vi starte med at indse, at i stedet for at løse ligningen\n\\[\nA x^2 + Bx + C = 0, \\quad \\quad A \\neq 0\n\\tag{2}\\]\n(hvis du undrer dig, så er det med vilje, at vi lige nu bruger store bogstaver til koefficienterne), så kan vi lige så godt løse en ligning på formen\n\\[\nx^2 + bx +c =0\n\\] hvor altså \\(a=1\\). Det virker måske som en forsimpling, men da vi i (2) har antaget, at \\(A \\neq 0,\\) så kan vi dividere igennem med \\(A\\) og få\n\\[\n\\begin{aligned}\n\\frac{A}{A} x^2 + \\frac{B}{A} x + \\frac{C}{A} &= \\frac{0}{A} \\quad \\Leftrightarrow \\\\\nx^2 + \\frac{B}{A} x + \\frac{C}{A} &= 0.\n\\end{aligned}\n\\]\nDet betyder, at når vi skal bestemme rødder i andengradspolynomier, så er det tilstrækkeligt, at betragte andengradspolynomier med en forskrift på formen\n\\[\nf(x)=x^2+bx+c,\n\\] hvor \\(b=B/A\\) og \\(c=C/A\\). Man kan altså bare tage sit oprindelige andengradspolynomium \\(g(x)=Ax^2+Bx+C\\) og dividerer igennem med \\(A\\). Lad os illustrere det med et eksempel.\n\nEksempel 1 Betragt andengradspolynomiet med forskriften\n\\[\ng(x)=-4x^2+8x+12\n\\] Her har vi \\(A=-4, B=8\\) og \\(C=12\\). Løser vi ligningen \\(g(x)=0\\), finder vi ud af, at \\(g\\) har to rødder nemlig \\(-1\\) og \\(3\\). Dividerer vi forskriften for \\(g\\) igennem med \\(A=-4\\) fås et nyt andengradspolynomium \\(f\\) med forskrift\n\\[\nf(x)=x^2-2x-3\n\\] Her er koefficienterne \\(a=1, b=-2\\) og \\(c=-3\\). Men \\(f\\) har præcis samme rødder som \\(g\\) – nemlig \\(-1\\) og \\(3\\). Dette ses også illustreret i figur 2, hvor grafen for \\(g\\) og \\(f\\) begge skærer \\(x\\)-aksen i \\(-1\\) og \\(3\\).\n\n\n\n\n\n\nFigur 2: Grafen for \\(g(x)=-4x^2+8x+12\\) (den blå) og \\(f(x)=x^2-2x-3\\) (den grønne), som begge skærer \\(x\\)-aksen samme sted. Det vil sige, at \\(g\\) og \\(f\\) har de samme rødder. I dette tilfælde \\(-1\\) og \\(3\\)."
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html#træningsdata",
    "href": "undervisningsforloeb/polynomium.html#træningsdata",
    "title": "AI og rødder i andengradspolynomier",
    "section": "Træningsdata",
    "text": "Træningsdata\nI dette eksempel vil vi nøjes med at se på, om vi kan bruge en metode fra kunstig intelligens, så vi forhåbentlig kan få svar på, om et givent andengradspolynomium enten har ingen eller en eller to rødder. Vi vil altså gerne finde en metode, som for en given parabel kan svare på, om parablen skærer \\(x\\)-aksen eller ej (og altså ikke hvor mange gange den eventuelt skærer \\(x\\)-aksen).\n\n\n\n\n\n\nOpgave 1: Rødder eller ej?\n\n\n\n\n\nOvervej følgende:\n\nHvordan laver man et andengradspolynomium, der har én eller to rødder?\nHvordan laver man et andengradspolynomium, som ingen rødder har?\n\n\n\n\nFor at bruge kunstig intelligens skal vi have lavet en masse eksempler på forskellige andengradspolynomier (det vil her sige med forskellige værdier af \\(b\\) og \\(c\\)) samtidig med, at vi også finder ud af, om det tilhørende andengradspolynomium har rødder eller ej. Den værdi, der angiver om et polynomium har rødder eller ej, kalder man for en targetværdi. Man kunne for eksempel gøre det ved at sige, at hvis et andengradspolynomium har én eller to rødder, så sætter vi targetværdien til \\(1\\), og hvis et andengradspolynomium ikke har nogle rødder, så sætter vi targetværdien til \\(-1\\). Tænk på det som en lille label du sætter på hvert eksempel, hvor du fortæller, hvad det rigtige svar er – “det er altså det her, jeg gerne vil have, at du lærer!”. Samlet set kalder man de forskellige eksempler inklusiv targetværdien for træningsdata.\n\n\n\n\n\n\nOpgave 2: Træningsdata\n\n\n\n\n\nAlle i gruppen skal nu:\n\nFinde et andengradspolynomium som ikke har nogle rødder (husk at \\(a=1\\)). Notér din værdi af \\(b\\) og \\(c\\) og sæt her targetværdien \\(t\\) til \\(-1\\).\nFinde et andengradspolynomium som har én eller to rødder (husk at \\(a=1\\)). Notér din værdi af \\(b\\) og \\(c\\) og sæt her targetværdien \\(t\\) til \\(1\\).\n\nNår alle har gjort det, skal I:\n\nIndsætte jeres forskellige værdier for \\(b, c\\) og \\(t\\) i et regneark, som er opbygget på denne måde:\n\n\nDisse data er nu præcis det, man kalder for træningsdata.\n\n\n\n\n\n\n\n\n\nOpgave 3: Træningsdata, fortsat\n\n\n\n\n\nI skal nu:\n\nIndtegn jeres værdier af \\(b\\) og \\(c\\) i et koordinatsystem, hvor værdien af \\(b\\) er på \\(x\\)-aksen, og værdien af \\(c\\) er på \\(y\\)-aksen. Hvis \\((b,c)\\)-punktet svarer til et andegradspolynomium, som har rødder (det vil sige, at \\(t=1\\)), farves punktet rødt og ellers farves det blåt (det vil sige, at \\(t=-1\\)). I videoen herunder er det vist, hvordan man gør i GeoGebra:"
  },
  {
    "objectID": "undervisningsforloeb/polynomium.html#træning-af-kunstig-intelligens",
    "href": "undervisningsforloeb/polynomium.html#træning-af-kunstig-intelligens",
    "title": "AI og rødder i andengradspolynomier",
    "section": "Træning af kunstig intelligens",
    "text": "Træning af kunstig intelligens\nEn simpel metode inden for kunstig intelligens er at prøve at bestemme en ret linje, som kan bruges til at adskille de røde punkter fra de blå punkter i det punktplot, som I har lavet i opgave 3.\nHvis man skal have en computer til at gøre det, så vil man typisk starte med en hel tilfældig ret linje med en ligning på formen\n\\[y=a \\cdot x+b\\]\nog så prøve at opdatere hældningen \\(a\\) og skæring med \\(y\\)-aksen \\(b\\), sådan at linjen bliver bedre og bedre til at adskille de røde punkter fra de blå.\nNu ser vi jo på andengradspolynomier med en forskrift på formen \\(f(x)=x^2+bx+c\\). Det vil sige, at \\(b\\) allerede har en betydning. Derfor er det ikke så hensigtsmæssigt at bruge \\(b\\) igen i ligningen for en ret linje. Derfor vælger vi her at beskrive den rette linje med en ligning på formen\n\\[\ny = w_1 \\cdot x + w_0\n\\] Det vil altså sige, at \\(w_1\\) er linjens hældning, og \\(w_0\\) er linjens skæring med \\(y\\)-aksen.\n\n\n\n\n\n\nOpgave 4: Bestemmelse af en linje som kan adskille de røde punkter fra de blå\n\n\n\n\n\n\nI inputfeltet i GeoGebra skal du taste: y=w1*x+w0.\nNår GeoGebra spørger, om du vil oprette skydere for w0 og w1, svarer du \"Opret skydere\".\nTræk i skyderne for w0 og w1 og prøv om du kan finde en ret linje, som kan adskille de røde punkter fra de blå.\n\n\n\n\n\n\n\n\n\n\nOpgave 5: Flere træningsdata\n\n\n\n\n\n\nAfgør om følgende andengradspolynomier har rødder og tilføj dem til dit træningsdata (husk ingen rødder svarer til at \\(t=-1\\) og det tilhørende punkt farves blåt, mens én eller to rødder svarer til \\(t=1\\) og punktet farves rødt):\n\n\\[\n\\begin{aligned}\nf_1(x) &= x^2 + 10x + 26 \\\\\nf_2(x) &= x^2 + 10x + 24\\\\\nf_3(x) &= x^2 + 5x + 6\\\\\nf_4(x) &= x^2 + 5x + 7 \\\\\nf_5(x) &= x^2 + 2x + 1\\\\\nf_6(x) &= x^2 + 2x + 2 \\\\\n\\end{aligned}\n\\]\n\nKan det lade sig gøre at adskille de to grupper med den rette linje, du fandt i opgave 4?\nHvis ikke kan du så bestemme en ny ret linje, som kan adskille de røde punkter fra de blå?\n\n\n\n\nSom du netop har opdaget, er det en umulig opgave, vi har givet os selv! Vi kan ikke finde en ret linje, som i alle tilfælde kan bruges til at adskille de røde punkter fra de blå. 😕\nLad os se på hvorfor. Som tidligere nævnt har vores linje en ligning på formen\n\\[\ny=w_1 \\cdot x + w_0\n\\]\nMen nu har vi \\(b\\)-værdier ud af \\(x\\)-aksen og \\(c\\)-værdier op af \\(y\\)-aksen, så i virkeligheden ser ligningen sådan her ud:\n\\[\nc=w_1 \\cdot b + w_0\n\\tag{3}\\]\nhvor \\(b\\) og \\(c\\) jo svarer til koefficinter i forskellige andengradspolymonier med forskrift \\(f(x)=x^2+bx+c\\).\nVi husker nu på formlen for diskriminanten \\(d=b^2-4ac=b^2-4c\\), da \\(a=1\\) i vores eksempel. Skillelinjen for om andengradspolynomiet har ingen eller flere rødder, går netop ved \\(d=0\\). Det vil sige\n\\[\nb^2-4c =0\n\\tag{4}\\]\nsom kan omskrives til\n\\[\nc = \\frac{1}{4}b^2\n\\tag{5}\\]\nMen vi kan ikke finde nogle værdier af \\(w_0\\) og \\(w_1\\), så udtrykket i (3) kommer til at svare til udtrykket i (5). Det er fordi, at i (3) indgår der kun et \\(b\\), mens der i (5) indgår et \\(b^2\\). Denne observation giver os imidlertid også en løsning på vores problem. I stedet for at lade træningsdata bestå af \\(b\\)- og \\(c\\)-værdier, så vil vi i stedet lade træningsdata bestå af \\(b^2\\)- og \\(c\\)-værdier! Det vil sige, at vi ud af \\(x\\)-aksen vil afsætte \\(b^2\\) og op af \\(y\\)-aksen, vil vi afsætte \\(c.\\)\n\n\n\n\n\n\nOpgave 6: Transformerede træningsdata\n\n\n\n\n\n\nBrug dit regneark fra tidligere og udregn \\(b^2\\).\nIndtegn dine værdier af \\(b^2\\) og \\(c\\) i et nyt koordinatsystem, hvor værdien af \\(b^2\\) er på \\(x\\)-aksen, og værdien af \\(c\\) er på \\(y\\)-aksen. Hvis \\((b^2,c)\\)-punktet svarer til et andegradspolynomium, som har rødder, farves punktet rødt og ellers farves det blåt.\nHvilken linje kan du vælge til at adskille de to grupper?\n\n\n\n\nIdéen med at prøve at adskille to grupper af punkter med en ret linje bruges blandt andet i den AI-metode, som kaldes for perceptroner. Metoden kan bruges, når man gerne vil kunne adskille to grupper af punkter fra hinanden baseret på en række forskellige værdier – disse værdier kalder man for features. Du kender måske kandidattests, hvor man på baggrund af svarene fra en række spørgsmål gerne vil kunne forudsige, om en person vil stemme på rød eller blå blok til det næste valg. Det kunne man for eksempel bruge en perceptron til at hjælpe med at afgøre, og det kan du læse meget mere om her.\nHvis du vil prøve at bruge den metode på dine data om andengradspolynomier, kan du gøre det her."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html",
    "title": "Miljø- og klimaudfodringer",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet er et tværfagligt samarbejde med dansk og kræver kendskab til:\n\nPopulærvidenskabelige artikler som genre.\n\nTidsforbrug: ca. 4 x 90 minutter i hvert fag.\nI dette forløb skal I få en genial idé til en innovativ anvendelse af AI, som kan være med til at løse et aspekt af klimakrisen. I formidlingen af jeres innovative anvendelse af AI skal I kunne præsentere nogle af idéerne bag AI og argumentere for den fordel, det kan give.\nI skal overveje, hvor der i praksis er et område med betydning for klimakrisen og med adgang til store datamængder, hvor man eventuelt med fordel kan trække information ud af datamængderne ved at træne et kunstigt neuralt netværk."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-matematik",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-matematik",
    "title": "Miljø- og klimaudfodringer",
    "section": "Indhold og formål i matematik",
    "text": "Indhold og formål i matematik\n\nAt I bliver klædt på til at kunne skrive en formidlingsopgave i jeres kommende SRP med fagene dansk og matematik eller dansk i kombination med et naturvidenskabeligt fag.\nAt I øver jer i at skrive en smule stringent matematik med ræsonnementer baseret på et valg af et begrænset emne fra materialet her på siden (se anbefalinger nederst). I må gerne følge en kilde ret tæt, men I lære, at man demonstrerer forståelse ved at tilføje yderligere forklarende tekst og egne eksempler.\nAt I får en overordnet forståelse for matematikken bag AI og kan formidle nogle af de centrale idéer."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-dansk",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#indhold-og-formål-i-dansk",
    "title": "Miljø- og klimaudfodringer",
    "section": "Indhold og formål i dansk",
    "text": "Indhold og formål i dansk\nI dansk har eleverne fået en introduktion til faglig formidling med afsæt i den særlige udfordring, der ligger i at etablere god formidling af videnskab til den almene borger. De har læst eksempler på populærvidenskabelige artikler og SRP-opgaver, og anvendt fagets teori og metoder til at analysere teksterne med henblik på at konkretisere, hvad den gode faglige formidling indebærer. Dernæst har de produceret egne populærvidenskabelige artikler med særligt fokus på layout, sprog og kommunikationssituation, og afslutningsvis opstiller de en danskfaglig analyse af deres eget produkt.\nBogen ”Del din viden” og Katinka Paludans speciale ”At fortælle om videnskab” har dannet teoretisk afsæt for arbejdet, og Paludan opstiller tre kriterier om den gode, faglige formidling, som har været rettesnor for elevernes egne produktioner."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#opgaveformulering",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#opgaveformulering",
    "title": "Miljø- og klimaudfodringer",
    "section": "Opgaveformulering",
    "text": "Opgaveformulering\n\nRedegør for dele af matematikken bag kunstig intelligens og præsenter et forslag til en mulig innovativ anvendelse af kunstig intelligens indenfor emnet ”klimaforandringer”.\nRedegør i den forbindelse for hvilket trænings- og testdata, der skal indsamles, og for fordelene ved den efterfølgende potentielle anvendelse af kunstig intelligens.\nSkriv en populærvidenskabelig artikel om jeres emne (omfang: 3-4 sider).\nBegrund jeres valg i forbindelse med layout, sprogbrug samt nyheds- og relevanskriterier og vurdér hvordan artiklen kan bidrage til nye indsigter og handlemuligheder."
  },
  {
    "objectID": "undervisningsforloeb/klimaudfordring_innovation.html#materiale",
    "href": "undervisningsforloeb/klimaudfordring_innovation.html#materiale",
    "title": "Miljø- og klimaudfodringer",
    "section": "Materiale",
    "text": "Materiale\nDansk: Changemaker-modellen.\nMatematik: Perceptroner, simple neurale netværk, gradientnedstigning og generelle neurale netværk."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html",
    "title": "Aktiveringsfunktioner",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDifferentialregning herunder differentiation af sammensatte funktioner og produktreglen.\n\nTidsforbrug: Ca. 1-2 x 90 minutter alt efter hvor mange aktiveringsfunktioner, I ønsker at arbejde med. I kan også arbejde i grupper og lade hver gruppe arbejde med hver sin aktiveringsfunktion."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#introduktion",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#introduktion",
    "title": "Aktiveringsfunktioner",
    "section": "Introduktion",
    "text": "Introduktion\nNår man træner en AI model, sker det som regel ved, at man forsøger at minimere de fejl, som modellen laver, når den anvendes på data, hvor man allerede kender svaret.\nFor at blive lidt mere konkret så minimerer man en såkaldt tabsfunktion \\(E\\) (\\(E\\) for error function), som har til formål at \"måle\", hvor god en AI model1 er. En tabsfunktion \\(E\\) har altid den egenskab, at \\(E \\geq 0\\), og at en lille værdi af \\(E\\) svarer til en god model (der er et lille tab), mens en stor værdi af \\(E\\) svarer til en mindre god model. Derfor vælger man den model, som giver den mindste værdi af tabsfunktionen.\n1 Med AI model tænker vi her på en perceptron, et simplet neuralt netværk, et generelt neuralt netværk eller en anden form for funktion, som kan bruges til at prædiktere et eller andet.AI modellen trænes altså ved at finde minimum for tabsfunktionen. Det gøres ofte ved hjælp af gradientnedstigning – men den konkrete metode er ikke så vigtig lige nu. Det vigtige er her at forstå, at hvis man skal finde minimum for en funktion, så har man brug for at kunne differentiere.\nI tabsfunktionen indgår en særlig klasse af funktioner, som kaldes for aktiveringsfunktioner. Og det giver nok mening, at hvis man skal differentiere selve tabsfunktionen, så må man også kunne differentiere den anvendte aktiveringsfunktion \\(f\\).\nDesuden viser det sig vigtigt, at det ikke må være alt for beregningsmæssigt tungt at beregne funktionsværdierne \\(f(x)\\) og \\(f'(x)\\). Det skal simpelthen gøres så mange gange – derfor dur det ikke, at det tager for lang tid. Det er derfor ønskværdigt, hvis en aktiveringsfunktions afledede funktion \\(f'(x)\\) kan beregnes forholdvis simpelt ved hjælp af \\(f(x)\\). Det betyder nemlig, at hvis vi allerede har udregnet \\(f(x)\\), så kræver det ikke ret meget også at udregne \\(f'(x)\\).\nI det nedenstående vil vi nu behandle en række af de mest anvendte aktiveringsfunktioner. Vi finder deres afledede funktioner, og vi vil se, hvordan de afledede funktioner alle kan udtrykkes ved hjælp af den oprindelig aktiveringsfunktion."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#sigmoid",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#sigmoid",
    "title": "Aktiveringsfunktioner",
    "section": "Sigmoid",
    "text": "Sigmoid\nSigmoid-funktionen har forskrift\n\\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\nGrafen for Sigmoid-funktionen ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for sigmoid-funktionen.\n\n\n\nDet ser på figur 1 ud som om, at værdimængden for \\(f\\) er \\((0,1)\\). Hvis du vil have et lidt bedre argument for det, kan du læse i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(f\\)\n\n\n\n\n\nVi vil her argumentere for, at værdimængden for \\(f\\) er \\((0,1)\\).\nPå figuren herunder ses grafen for \\(e^{-x}\\).\n\n\n\n\n\nDa \\(e^{-x}\\) er en aftagende eksponentialfunktion vil\n\\[\ne^{-x} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\ne^{-x} \\rightarrow \\infty \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet betyder, at \\[\n\\frac{1}{1+e^{-x}} \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\]\nog\n\\[\n\\frac{1}{1+e^{-x}} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet vil sige, at værdimængden for \\(f\\) er \\((0,1)\\).\n\n\n\nDe følgende opgaver gå ud på at vise, at\n\\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og at \\(f'(x)\\) kan udtrykkes ved hjælp af \\(f(x)\\) på denne måde\n\\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af sigmoid-funktionen\n\n\n\n\n\nVi skal vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\] Vi skal starte med at se, at vi kan tænke på sigmoid-funktionen \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\] som en \"dobbelt sammensat\" funktion. Sigmoid-funktionen består nemlig af en brøk på formen \\(\\frac{1}{x}\\) og af eksponentialfunktionen \\(e^{-x}\\).\nDerfor skal du:\n\nStart med at opskrive differentialkvotienten for \\[\\frac{1}{x} \\quad \\textrm{og} \\quad e^{-x}.\\]\nBrug ovenstående til at vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Differentiation af sigmoid-funktionen – omskrivning af \\(f'(x)\\)\n\n\n\n\n\nVi skal nu vise, at \\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\] når \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\n\nStart med at udregne \\[1-f(x).\\] Hint! Sæt på fælles brøkstreg ved at skrive \\(1\\) som \\(\\frac{1+e^{-x}}{1+e^{-x}}\\).\nVis nu at \\[\nf(x)\\cdot (1-f(x)) = \\frac{e^{-x}}{(1+e^{-x})^2}=f'(x).\n\\] Husk, at man ganger to brøker med hinanden ved at gange tæller med tæller og nævner med nævner."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#softsign",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#softsign",
    "title": "Aktiveringsfunktioner",
    "section": "Softsign",
    "text": "Softsign\nSoftsign-funktionen har forskrift\n\\[\nf(x)=\\frac{x}{1+|x|}.\n\\] Husk på at \\(|x|\\) betyder den numeriske værdi af \\(x\\). Det vil sige\n\\[\n|x| =\n\\begin{cases}\nx & \\textrm{hvis } x \\geq 0 \\\\\n-x & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{1}\\] Det betyder for eksempel at \\(|7|=7\\) og \\(|-7|=7\\). Grafen for \\(|x|\\) ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for \\(|x|\\).\n\n\n\nGrafen for softsign-funktionen \\(f\\) ses i figur 3.\n\n\n\n\n\n\nFigur 3: Grafen for softsign-funktionen.\n\n\n\nDa den numeriske værdi af \\(x\\) indgår i forskriften, kunne man få den tanke, at \\(f\\) måske hverken er kontinuert eller differentiabel i \\(0\\). For eksempel kan man i figur 2 se, at \\(|x|\\) ikke er differentiabel i \\(0\\).\nMen bruger vi definitionen på \\(|x|\\), får vi\n\\[\nf(x) =\n\\begin{cases}\n\\frac{x}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\n\\frac{x}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{2}\\]\nUd fra denne omskrivning kan man vise, at \\(f\\) rent faktisk er kontinuert i \\(0\\). Det kan du læse mere om i boksen herunder, hvis du har lyst.\nPå figur 3 ser det ud som om, at værdimængden for \\(f\\) er \\((-1,1)\\) (også det argumenterer vi for i boksen). Det vil sige, at hvis vi skal bruge softsign-funktionen som aktiveringsfunktion, så skal targetværdierne være \\(\\pm 1\\).\n\n\n\n\n\n\nArgument for kontinuitet i \\(0\\) og værdimængde for \\(f\\)\n\n\n\n\n\nLad os først argumentere for, at \\(f\\) er kontinuert i \\(0\\). For det første ser vi, at \\(f(0)=0/(1+0)=0\\) og \\(f(x) \\rightarrow 0\\), når \\(x\\) nærmer sig \\(0\\) både fra højre og venstre. Det betyder, at \\(f\\) er kontinuert i \\(0\\).\nVi ser også, at for store positive værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1+x} \\approx \\frac{x}{x}=1\n\\] og for store negative værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1-x} \\approx \\frac{x}{-x}=-1\n\\] Det betyder, at \\[\nf(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\nf(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 3.\n\n\n\nI nedenstående opgaver skal vi vise, at\n\\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\tag{3}\\]\nog at den afledte kan findes ved hjælp af funktionsværdien selv på denne måde\n\\[\nf'(x)=(1-|f(x)|)^2.\n\\tag{4}\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af softsign-funktionen\n\n\n\n\n\nFor at vise at \\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\] vil vi starte med at bruge en brøkregneregel til at omskrive funktionsudtrykket i (2):\n\\[\nf(x) =\n\\begin{cases}\nx \\cdot \\frac{1}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\nx \\cdot \\frac{1}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{5}\\]\n\nAntag først, at \\(x &gt; 0\\) og vis ved hjælp af produktreglen for differentiation, at \\[\nf'(x)=\\frac{1}{(1+x)^2} = \\frac{1}{(1+|x|)^2}.\n\\] OBS! Du får på et tidspunkt brug for at sætte på fælles brøkstreg – fællesnævneren er her \\((1+x)^2\\).\nAntag nu at \\(x&lt;0\\) og vis igen ved hjælp af produktreglen for differentiation at \\[\nf'(x)=\\frac{1}{(1-x)^2} = \\frac{1}{(1+|x|)^2}.\n\\]\nTegn grafen for \\(f'\\). Synes du, at det ser ud som om, at \\(f'\\) er differentiabel?\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Differentiation af softsign-funktionen – omskrivning af \\(f'(x)\\)\n\n\n\n\n\nVi vil nu vise, at den afledede softsign-funktion kan udtrykkes ved hjælp af softsign-funktionen selv: \\[\nf'(x)=(1-|f(x)|)^2.\n\\]\n\nStart med at overvise dig selv om, at \\[\n|f(x)|=f(|x|)\n\\] ved at bruge definitionen i (1).\nVis at \\[\n(1-f(|x|))^2 = \\frac{1}{(1+|x|)^2}=f'(x)\n\\] Hint! Skriv \\(1\\) som \\(\\frac{1+|x|}{1+|x|}\\)."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#hyperbolsk-tangens",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#hyperbolsk-tangens",
    "title": "Aktiveringsfunktioner",
    "section": "Hyperbolsk tangens",
    "text": "Hyperbolsk tangens\nFunktionen hyperbolsk tangens, \\(\\tanh\\), har forskrift \\[\n\\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\]\nGrafen for hyperbolsk tangens er vist i figur 4.\n\n\n\n\n\n\nFigur 4: Grafen for hyperbolsk tangens.\n\n\n\nIfølge figuren ser det ud til, at \\(Vm(f)=(-1,1)\\). Det argumenterer vi nærmere for i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(\\tanh\\)\n\n\n\n\n\nPå figuren herunder ses grafen for den voksende eksponentialfunktion \\(e^x\\) (blå) og for den aftagende eksponentialfunktion \\(e^{-x}\\) (grøn).\n\n\n\n\n\nHer ses det, at for store positive værdier af \\(x\\) er \\(e^{-x} \\approx 0\\). Det vil sige, at for store positive værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{e^x-0}{e^x+0}=\\frac{e^x}{e^x}=1.\n\\]\nOmvendt gælder for store negative værdier af \\(x\\) er \\(e^x \\approx 0\\). Det vil sige, at for store negative værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{0-e^{-x}}{0+e^{-x}}=\\frac{-e^{-x}}{e^{-x}}=-1.\n\\] Det betyder, at \\[\n\\tanh(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\n\\tanh(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 4.\n\n\n\nI nedenstående opgave skal vi vise, at \\(\\tanh\\) differentieret er\n\\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\nFor at bevise det er det nemmeste at bruge kvotientreglen for differentiation. Måske har du hørt om den – måske har du ikke. Men her kommer den:\n\nKvotientreglen for differentiation \n\\[\n\\left ( \\frac{f(x)}{g(x)}\\right)' = \\frac{f'(x) \\cdot g(x)-f(x) \\cdot g'(x)}{(g(x))^2}, \\quad g(x) \\neq 0\n\\]\n\n\n\n\n\n\n\nOpgave 1: Differentiation af softsign-funktionen og omskrivning\n\n\n\n\n\nVi skal vise, at tangens hyperbolsk \\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\] differentieret er \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\n\nBrug kvotientreglen for differentiation til at vise, at \\[\n\\tanh'(x)= 1 - \\left (\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\right)^2\n\\] Hint! På et tidspunkt får du brug for brøkregnereglen \\(\\frac{a+b}{c}=\\frac{a}{c}+\\frac{b}{c}\\).\nBrug definitionen af tangens hyperbolsk til at indse at \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#relu",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#relu",
    "title": "Aktiveringsfunktioner",
    "section": "ReLU",
    "text": "ReLU\nAktiveringsfunktionen ReLU som står for Reflected Linear Unit har forskrift\n\\[\nf(x) =\n\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\n\\] og grafen for ReLU-funktionen ses i figur 5.\n\n\n\n\n\n\nFigur 5: Grafen for ReLU-funktionen.\n\n\n\nVærdimængden for ReLU-funktionen er \\([0, \\infty)\\).\nDet er ret tydeligt, at ReLU-funktionen ikke er differentiabel i \\(0\\). Men hvis vi definerer, at \\(f'(0)\\) skal være \\(0\\) så ses det nemt, at\n\\[\nf'(x) =\n\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}.\n\\]\nReLU-funktionen adskiller dig fra de andre aktiveringsfunktioner ved, at værdimængden er ubegrænset. Hvis man ønsker at bruge aktiveringsfunktionen til at modellere en sandsynlighed, som beskrevet tidligere, så dur det selvfølgelig ikke. Men i praktisk viser ReLU-funktionen sig at være utrolig anvendelig som aktiveringsfunktion i de skjult lag i kunstige neurale netværk. For det første kan nogle af de andre aktiveringsfunktioner resulterer i det, vi i afsnittet om valg af tabsfunktion i noten om kunstige neurale netværk, kalder for slow learning. Det betyder kort sagt, at det går for langsomt med at finde minimum for tabsfunktionen. Dét problem har ReLU-funktionen ikke. For det andet er det meget hurtigt og nemt at udregne både ReLU-funktionen selv og også dens afledede. Det er for eksempel til sammenligning beregningsmæssigt tungere, at udregne sigmoid-funktionen og dennes afledede. Hvis man har et netværk med millioner af neuroner, så er denne beregningsmæssige forskel ikke uvæsentlig.\nFor yderligere læsning henviser vi til referencerne i afsnittet videre læsning."
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#overblik",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#overblik",
    "title": "Aktiveringsfunktioner",
    "section": "Overblik",
    "text": "Overblik\nI tabellen herunder finder du et overblik over de forskellige aktiveringsfunktioner, som vi har behandlet ovenfor.\n\n\n\n\n\n\n\n\n\n\n\nNavn\n\\(f(x)\\)\nGraf\n\\(Vm(f)\\)\n\\(f'(x)\\)\n\n\n\n\n\nSigmoid\n\\(\\frac{1}{1+e^{-x}}\\)\n\n\\((0,1)\\)\n\\(f(x)\\cdot(1-f(x))\\)\n\n\n\nSoftsign\n\\(\\frac{x}{1+|x|}\\)\n\n\\((-1,1)\\)\n\\((1-|f(x)|)^2\\)\n\n\n\nHyperbolsk tangens\n\\(\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\)\n\n\\((-1,1)\\)\n\\(1-\\left ( \\tanh(x) \\right )^2\\)\n\n\n\nReLU\n\\(\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\\)\n\n\\([0,\\infty)\\)\n\\(\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\\)"
  },
  {
    "objectID": "undervisningsforloeb/aktiveringsfunktioner.html#sec-videre",
    "href": "undervisningsforloeb/aktiveringsfunktioner.html#sec-videre",
    "title": "Aktiveringsfunktioner",
    "section": "Videre læsning",
    "text": "Videre læsning\n\nActivation Functions in Neural Networks: With 15 examples\nRELU and SIGMOID Activation Functions in a Neural Network"
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html",
    "href": "undervisningsforloeb/tabsfunktioner.html",
    "title": "Tabsfunktioner",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDifferentialregning herunder differentiation af sammensatte funktioner.\n\nTidsforbrug: Ca. 1-2 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#under-udarbejdelse",
    "href": "undervisningsforloeb/tabsfunktioner.html#under-udarbejdelse",
    "title": "Tabsfunktioner",
    "section": "Under udarbejdelse!",
    "text": "Under udarbejdelse!\nHusk henvisning til forløb om aktiveringsfunktioner"
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#tabsfunktion-targetværdier-og-aktiveringsfunktioner",
    "href": "undervisningsforloeb/tabsfunktioner.html#tabsfunktion-targetværdier-og-aktiveringsfunktioner",
    "title": "Tabsfunktioner",
    "section": "Tabsfunktion, targetværdier og aktiveringsfunktioner",
    "text": "Tabsfunktion, targetværdier og aktiveringsfunktioner\nPå engelsk bliver tabsfunktioner også kaldet for error functions. Overordnet set vil vi gerne have en AI model med så lille et tab eller så lille en fejl som muligt. Derfor skal tabsfunktionen minimeres.\nNår tabsfunktionen skal minimeres bruger man såkaldte træningsdata. Det betyder, at man i træningsdata har givet en række inputværdier \\(x_1, x_2, \\dots, x_n\\) på baggrund af hvilke, man ønsker at prædiktere en såkaldt targetværdi \\(t\\), som også er en del af træningsdata.\nLad os tage et eksempel fra den virkelige verden. Vi vil gerne på baggrund af en blodprøve kunne prædiktere om en patient har kræft eller ej. Her kan inputværdierne \\(x_1, x_2, \\dots, x_n\\) være forskellige ting, man måler i blodet (spørg en biologilærer om hvad det kunne være). Targetværdien \\(t\\) kan antage to værdier:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis patienten har kræft} \\\\\n0 & \\textrm{hvis patienten ikke har kræft} \\\\\n\\end{cases}\n\\] Man kunne også have valgt: \\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis patienten har kræft} \\\\\n-1 & \\textrm{hvis patienten ikke har kræft} \\\\\n\\end{cases}\n\\] Eller noget helt tredje! Det kommer vi tilbage til senere. Lad os for nu sige at vi vælger den første mulighed, hvor \\(t \\in \\{0,1\\}\\).\nAt bestemme, om targetværdien er \\(0\\) eller \\(1\\), beror på faglig ekspertise indenfor det genstandsfelt, hvor AI modellen skal anvendes. I eksemplet med kræft vil det for eksempel være baseret på forskellige diagnostiske tests, som en læge kan bruge til at vurdere, om patienten har kræft1.\n1 Måske er disse tests først taget et stykke tid efter blodprøven, fordi det ikke er muligt at stille diagnose på tidspunktet for blodprøven. I så fald kan man måske være heldig at få udviklet en AI model, som kan prædiktere kræft tidligere end med gængse metoder.** Lille data eksempel her med én inputværdi **\nMan \"fodrer\" så sin AI algoritme med en hel masse inputværdier med tilhørende targetværdier og finder den AI model, som giver den mindste værdi af tabsfunktionen. Det kaldes for supervised learning.\nI AI modellen vil det typisk være sådan, at de forskellige inputværdier vægtes med en række vægte \\(w_0, w_1, \\dots, w_p\\). Når AI modellen trænes, er det dybest set bare disse vægte, man \"skruer\" på, sådan at modellen bliver god til at prædiktere det, den er trænet på. For store kunstige neurale netværk – for eksempel de store sprogmodeller – taler vi om milliarder af vægte!\nVi kan altså tænke på en AI model, som en funktion \\(f\\), der afhænger af vægtene \\(w_0, w_1, \\dots, w_p\\):\n\\[\nf(w_0, w_1, \\dots, w_p).\n\\] Funktionen afhænger selvfølgelig også af hele træningsdatasættet, men eftersom det er vægtene, man skal justere, alt imens træningsdata er fastlagt, vil vi blot tænke på \\(f\\) som en funktion af vægtene.\nVi forestiller os nu, at vi har bestemt minimum for tabsfunktionen og dermed fundet de værdier af vægtene, som minimerer tabsfunktionen. Det er nu disse værdier, som giver os vores endelige AI model. Spørgsmålet er nu, hvordan den bruges til prædiktion. Det kommer her:\nOfte vil værdimængden for \\(f\\) være \\((0,1)\\). Det betyder, at vi kan tolke værdien af \\(f\\) som en sandsynlighed. Vi forestiller os, at vi får et nyt sæt af inputværdier – for eksempel målingerne fra en ny blodprøve, og vi vil gerne finde ud af, om patienten har kræft eller ej. Disse værdier \"sendes\" nu ind i funktionen \\(f\\) og ud kommer en ouputværdi, som vi vil kalde for \\(o\\). Værdien af \\(o\\) betragtes nu som sandsynligheden for, at den rigtige targetværdi er \\(1\\). Det kunne for eksempel være sådan her:\n\\[\n\\textrm{prædiktion}=\n\\begin{cases}\n\\textrm{patienten har kræft} & \\textrm{hvis } o \\geq 0.5 \\\\\n\\textrm{patienten har ikke kræft} & \\textrm{hvis } o &lt; 0.5 \\\\\n\\end{cases}\n\\]\nMen hvis det skal give mening, så kræver det altså, at vi har fundet de værdier af vægtene, som gør, at denne prædiktion rent faktisk bliver god.\nVi har hele tiden sagt, at det gør vi ved at minimere tabsfunktionen, men det kræver jo, at vi har en tabsfunktion. Ofte kan man bruge denne tabsfunktion:\n\\[\nE = \\frac{1}{2} \\sum \\left (t-o \\right)^2,\n\\tag{1}\\]\n\nhvor der summeres over alle træningsdata. For det første kan vi se, at \\(E \\geq 0\\), fordi der er tale om en kvadreret sum. For det andet kan vi se, at hvis AI modellen er god, så vil den beregnede sandsynlighed \\(o\\), for at patienten har kræft være tæt på \\(1\\), når \\(t=1\\), og \\(o\\) vil være tæt på \\(0\\), når \\(t=0\\). Det betyder, at de kvadrerede forskelle \\((t-o)^2\\) i det tilfælde vil være små, og dermed vil tabsfunktionen også være lille. Altså lever \\(E\\) op til de krav, vi stiller til en tabsfunktion.\nOutputværdien \\(o\\) beregnes ofte som\n\\[\no = f(w_0+w_1x_1+w_2x_2+\\cdots+w_nx_n),\n\\]\nhvor \\(f\\) er den funktion, som vi kalder for en aktiveringsfunktion. For perceptroner og simple neurale netværk svarer \\(x_1, x_2, \\dots, x_n\\) direkte til inputværdierne, som AI modellen i sidste ende skal virke på. I et kunstig neuralt netværk er det mere kompliceret, men ovenstående er korrekt, hvis man tænker på \\(x_1, x_2, \\dots, x_n\\), som de værdier neuronerne i det sidste skjulte lag sender videre til outputlaget.\nHvis tabsfunktionen i (1) skal give mening, så kan vi nu se, at hvis targetværdien \\(t \\in \\{0,1\\}\\), så bør værdimængden for \\(f\\) tilsvarende være \\((0,1)\\). Mens hvis \\(t \\in \\{-1,1\\}\\), så bør2 værdimængden for \\(f\\) tilsvarende være \\((-1,1)\\). Forestiller man sig, at targetværdien er huspriser – det vil sige, at \\(t \\in (0,\\infty)\\) – ja så vil det give mening, at også outputværdien \\(o \\in (0,\\infty)\\). Det vigtige er altså, at værdimængden for aktiveringsfunktionen er på samme skala som targetværdierne.\n2 Når en perceptron trænes ved hjælp af Adaline, er dette faktisk ikke tilfældet. Her er targetværdien \\(t \\in \\{-1,1\\}\\), mens outputværdien \\(o \\in \\mathbb{R}\\). Det kan give nogle problemer, som er beskrevet i noten om simple neurale netværk.Når AI modellen trænes ved at finde minimum for tabsfunktionen, så gøres det ofte ved hjælp af gradientnedstigning – men den konkrete metode er ikke så vigtig lige nu. Det vigtige er at forstå, at når man skal finde minimum for en funktion, så har man brug for at kunne differentiere. Derfor er det vigtigt at kunne differentiere den anvendte aktiveringsfunktion \\(f\\).\nDesuden viser det sig vigtigt, at det ikke er alt for beregningsmæssigt tungt at beregne funktionsværdierne \\(f(x)\\) og \\(f'(x)\\). Det skal simpelthen gøres så mange gange – derfor dur det ikke, at det tager for lang tid. Det er således ønskværdigt, hvis en aktiveringsfunktions afledede funktion \\(f'(x)\\) kan beregnes forholdvis simpelt ved hjælp af \\(f(x)\\). Det betyder nemlig, at hvis vi allerede har udregnet \\(f(x)\\), så kræver det ikke ret meget også at udregne \\(f'(x)\\).\nI det nedenstående vil vi nu behandle en række af de mest anvendte aktiveringsfunktioner. Vi finder deres afledede funktioner, og vi vil se, hvordan de afledede funktioner alle kan udtrykkes ved hjælp af den oprindelig aktiveringsfunktion."
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#sigmoid",
    "href": "undervisningsforloeb/tabsfunktioner.html#sigmoid",
    "title": "Tabsfunktioner",
    "section": "Sigmoid",
    "text": "Sigmoid\nSigmoid-funktionen har forskrift\n\\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\nGrafen for Sigmoid-funktionen ses i figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for sigmoid-funktionen.\n\n\n\nDet ser på figur 1 ud som om, at værdimængden for \\(f\\) er \\((0,1)\\). Hvis du vil have et lidt bedre argument for det, kan du læse i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(f\\)\n\n\n\n\n\nVi vil her argumentere for, at værdimængden for \\(f\\) er \\((0,1)\\).\nPå figuren herunder ses grafen for \\(e^{-x}\\).\n\n\n\n\n\nDa \\(e^{-x}\\) er en aftagende eksponentialfunktion vil\n\\[\ne^{-x} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\ne^{-x} \\rightarrow \\infty \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet betyder, at \\[\n\\frac{1}{1+e^{-x}} \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\]\nog\n\\[\n\\frac{1}{1+e^{-x}} \\rightarrow 0 \\quad \\textrm{når} \\quad x \\rightarrow -\\infty.\n\\]\nDet vil sige, at værdimængden for \\(f\\) er \\((0,1)\\).\n\n\n\nDe følgende opgaver gå ud på at vise, at\n\\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}\n\\] og at \\(f'(x)\\) kan udtrykkes ved hjælp af \\(f(x)\\) på denne måde\n\\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af sigmoid-funktionen\n\n\n\n\n\nVi skal vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\] Vi skal starte med at se, at vi kan tænke på sigmoid-funktionen \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\] som en \"dobbelt sammensat\" funktion. Sigmoid-funktionen består nemlig af en brøk på formen \\(\\frac{1}{x}\\) og af eksponentialfunktionen \\(e^{-x}\\).\nDerfor skal du:\n\nStart med at opskrive differentialkvotienten for \\[\\frac{1}{x} \\quad \\textrm{og} \\quad e^{-x}.\\]\nBrug ovenstående til at vise, at \\[\nf'(x)= \\frac{e^{-x}}{(1+e^{-x})^2}.\n\\]\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Differentiation af sigmoid-funktionen – omskrivning af \\(f'(x)\\)\n\n\n\n\n\nVi skal nu vise, at \\[\nf'(x)= f(x)\\cdot (1-f(x)).\n\\] når \\[\nf(x)=\\frac{1}{1+e^{-x}}.\n\\]\n\nStart med at udregne \\[1-f(x).\\] Hint! Sæt på fælles brøkstreg ved at skrive \\(1\\) som \\(\\frac{1+e^{-x}}{1+e^{-x}}\\).\nVis nu at \\[\nf(x)\\cdot (1-f(x)) = \\frac{e^{-x}}{(1+e^{-x})^2}=f'(x).\n\\] Husk, at man ganger to brøker med hinanden ved at gange tæller med tæller og nævner med nævner."
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#softsign",
    "href": "undervisningsforloeb/tabsfunktioner.html#softsign",
    "title": "Tabsfunktioner",
    "section": "Softsign",
    "text": "Softsign\nSoftsign-funktionen har forskrift\n\\[\nf(x)=\\frac{x}{1+|x|}.\n\\] Husk på at \\(|x|\\) betyder den numeriske værdi af \\(x\\). Det vil sige\n\\[\n|x| =\n\\begin{cases}\nx & \\textrm{hvis } x \\geq 0 \\\\\n-x & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{2}\\] Det betyder for eksempel at \\(|7|=7\\) og \\(|-7|=7\\). Grafen for \\(|x|\\) ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for \\(|x|\\).\n\n\n\nGrafen for softsign-funktionen \\(f\\) ses i figur 3.\n\n\n\n\n\n\nFigur 3: Grafen for softsign-funktionen.\n\n\n\nDa den numeriske værdi af \\(x\\) indgår i forskriften, kunne man få den tanke, at \\(f\\) måske hverken er kontinuert eller differentiabel i \\(0\\). For eksempel kan man i figur 2 se, at \\(|x|\\) ikke er differentiabel i \\(0\\).\nMen bruger vi definitionen på \\(|x|\\), får vi\n\\[\nf(x) =\n\\begin{cases}\n\\frac{x}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\n\\frac{x}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{3}\\]\nUd fra denne omskrivning kan man vise, at \\(f\\) rent faktisk er kontinuert i \\(0\\). Det kan du læse mere om i boksen herunder, hvis du har lyst.\nPå figur 3 ser det ud som om, at værdimængden for \\(f\\) er \\((-1,1)\\) (også det argumenterer vi for i boksen). Det vil sige, at hvis vi skal bruge softsign-funktionen som aktiveringsfunktion, så skal targetværdierne være \\(\\pm 1\\).\n\n\n\n\n\n\nArgument for kontinuitet i \\(0\\) og værdimængde for \\(f\\)\n\n\n\n\n\nLad os først argumentere for, at \\(f\\) er kontinuert i \\(0\\). For det første ser vi, at \\(f(0)=0/(1+0)=0\\) og \\(f(x) \\rightarrow 0\\), når \\(x\\) nærmer sig \\(0\\) både fra højre og venstre. Det betyder, at \\(f\\) er kontinuert i \\(0\\).\nVi ser også, at for store positive værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1+x} \\approx \\frac{x}{x}=1\n\\] og for store negative værdier af \\(x\\) vil \\[\nf(x)= \\frac{x}{1-x} \\approx \\frac{x}{-x}=-1\n\\] Det betyder, at \\[\nf(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\nf(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 3.\n\n\n\nI nedenstående opgaver skal vi vise, at\n\\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\tag{4}\\]\nog at den afledte kan findes ved hjælp af funktionsværdien selv på denne måde\n\\[\nf'(x)=(1-|f(x)|)^2.\n\\tag{5}\\]\n\n\n\n\n\n\nOpgave 1: Differentiation af softsign-funktionen\n\n\n\n\n\nFor at vise at \\[\nf'(x)=\\frac{1}{\\left ( 1+ |x| \\right )^2}\n\\] vil vi starte med at bruge en brøkregneregel til at omskrive funktionsudtrykket i (3):\n\\[\nf(x) =\n\\begin{cases}\nx \\cdot \\frac{1}{1+x} & \\textrm{hvis } x \\geq 0 \\\\\n\\\\\nx \\cdot \\frac{1}{1-x} & \\textrm{hvis } x &lt; 0 \\\\\n\\end{cases}\n\\tag{6}\\]\n\nAntag først, at \\(x &gt; 0\\) og vis ved hjælp af produktreglen for differentiation, at \\[\nf'(x)=\\frac{1}{(1+x)^2} = \\frac{1}{(1+|x|)^2}.\n\\] OBS! Du får på et tidspunkt brug for at sætte på fælles brøkstreg – fællesnævneren er her \\((1+x)^2\\).\nAntag nu at \\(x&lt;0\\) og vis igen ved hjælp af produktreglen for differentiation at \\[\nf'(x)=\\frac{1}{(1-x)^2} = \\frac{1}{(1+|x|)^2}.\n\\]\nTegn grafen for \\(f'\\). Synes du, at det ser ud som om, at \\(f'\\) er differentiabel?\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Differentiation af softsign-funktionen – omskrivning af \\(f'(x)\\)\n\n\n\n\n\nVi vil nu vise, at den afledede softsign-funktion kan udtrykkes ved hjælp af softsign-funktionen selv: \\[\nf'(x)=(1-|f(x)|)^2.\n\\]\n\nStart med at overvise dig selv om, at \\[\n|f(x)|=f(|x|)\n\\] ved at bruge definitionen i (2).\nVis at \\[\n(1-f(|x|))^2 = \\frac{1}{(1+|x|)^2}=f'(x)\n\\] Hint! Skriv \\(1\\) som \\(\\frac{1+|x|}{1+|x|}\\)."
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#hyperbolsk-tangens",
    "href": "undervisningsforloeb/tabsfunktioner.html#hyperbolsk-tangens",
    "title": "Tabsfunktioner",
    "section": "Hyperbolsk tangens",
    "text": "Hyperbolsk tangens\nFunktionen hyperbolsk tangens, \\(\\tanh\\), har forskrift \\[\n\\tanh(x) = \\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\]\nGrafen for hyperbolsk tangens er vist i figur 4.\n\n\n\n\n\n\nFigur 4: Grafen for hyperbolsk tangens.\n\n\n\nIfølge figuren ser det ud til, at \\(Vm(f)=(-1,1)\\). Det argumenterer vi nærmere for i boksen herunder.\n\n\n\n\n\n\nArgument for værdimængden for \\(\\tanh\\)\n\n\n\n\n\nPå figuren herunder ses grafen for den voksende eksponentialfunktion \\(e^x\\) (blå) og for den aftagende eksponentialfunktion \\(e^{-x}\\) (grøn).\n\n\n\n\n\nHer ses det, at for store positive værdier af \\(x\\) er \\(e^{-x} \\approx 0\\). Det vil sige, at for store positive værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{e^x-0}{e^x+0}=\\frac{e^x}{e^x}=1.\n\\]\nOmvendt gælder for store negative værdier af \\(x\\) er \\(e^x \\approx 0\\). Det vil sige, at for store negative værdier af \\(x\\) er\n\\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\approx \\frac{0-e^{-x}}{0+e^{-x}}=\\frac{-e^{-x}}{e^{-x}}=-1.\n\\] Det betyder, at \\[\n\\tanh(x) \\rightarrow 1 \\quad \\textrm{når} \\quad x \\rightarrow \\infty\n\\] og\n\\[\n\\tanh(x) \\rightarrow -1 \\quad \\textrm{når} \\quad x \\rightarrow - \\infty\n\\] hvilket stemmer fint overens med figur 4.\n\n\n\nI nedenstående opgave skal vi vise, at \\(\\tanh\\) differentieret er\n\\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\nFor at bevise det er det nemmeste at bruge kvotientreglen for differentiation. Måske har du hørt om den – måske har du ikke. Men her kommer den:\n\nKvotientreglen for differentiation \n\\[\n\\left ( \\frac{f(x)}{g(x)}\\right)' = \\frac{f'(x) \\cdot g(x)-f(x) \\cdot g'(x)}{(g(x))^2}, \\quad g(x) \\neq 0\n\\]\n\n\n\n\n\n\n\nOpgave 1: Differentiation af softsign-funktionen og omskrivning\n\n\n\n\n\nVi skal vise, at tangens hyperbolsk \\[\n\\tanh(x)=\\frac{e^x-e^{-x}}{e^x+e^{-x}}\n\\] differentieret er \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]\n\nBrug kvotientreglen for differentiation til at vise, at \\[\n\\tanh'(x)= 1 - \\left (\\frac{e^x-e^{-x}}{e^x+e^{-x}} \\right)^2\n\\] Hint! På et tidspunkt får du brug for brøkregnereglen \\(\\frac{a+b}{c}=\\frac{a}{c}+\\frac{b}{c}\\).\nBrug definitionen af tangens hyperbolsk til at indse at \\[\n\\tanh'(x)=1-\\left ( \\tanh(x) \\right )^2.\n\\]"
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#relu",
    "href": "undervisningsforloeb/tabsfunktioner.html#relu",
    "title": "Tabsfunktioner",
    "section": "ReLU",
    "text": "ReLU\nAktiveringsfunktionen ReLU som står for Reflected Linear Unit har forskrift\n\\[\nf(x) =\n\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\n\\] og grafen for ReLU-funktionen ses i figur 5.\n\n\n\n\n\n\nFigur 5: Grafen for ReLU-funktionen.\n\n\n\nVærdimængden for ReLU-funktionen er \\([0, \\infty)\\).\nDet er ret tydeligt, at ReLU-funktionen ikke er differentiabel i \\(0\\). Men hvis vi definerer, at \\(f'(0)\\) skal være \\(0\\) så ses det nemt, at\n\\[\nf'(x) =\n\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}.\n\\]\nReLU-funktionen adskiller dig fra de andre aktiveringsfunktioner ved, at værdimængden er ubegrænset. Hvis man ønsker at bruge aktiveringsfunktionen til at modellere en sandsynlighed, som beskrevet tidligere, så dur det selvfølgelig ikke. Men i praktisk viser ReLU-funktionen sig at være utrolig anvendelig som aktiveringsfunktion i de skjult lag i kunstige neurale netværk. For det første kan nogle af de andre aktiveringsfunktioner resulterer i det, vi i afsnittet om valg af tabsfunktion i noten om kunstige neurale netværk, kalder for slow learning. Det betyder kort sagt, at det går for langsomt med at finde minimum for tabsfunktionen. Dét problem har ReLU-funktionen ikke. For det andet er det meget hurtigt og nemt at udregne både ReLU-funktionen selv og også dens afledede. Det er for eksempel til sammenligning beregningsmæssigt tungere, at udregne sigmoid-funktionen og dennes afledede. Hvis man har et netværk med millioner af neuroner, så er denne beregningsmæssige forskel ikke uvæsentlig.\nFor yderligere læsning henviser vi til referencerne i afsnittet videre læsning."
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#overblik",
    "href": "undervisningsforloeb/tabsfunktioner.html#overblik",
    "title": "Tabsfunktioner",
    "section": "Overblik",
    "text": "Overblik\nI tabellen herunder finder du et overblik over de forskellige aktiveringsfunktioner, som vi har behandlet ovenfor.\n\n\n\n\n\n\n\n\n\n\n\nNavn\n\\(f(x)\\)\nGraf\n\\(Vm(f)\\)\n\\(f'(x)\\)\n\n\n\n\n\nSigmoid\n\\(\\frac{1}{1+e^{-x}}\\)\n\n\\((0,1)\\)\n\\(f(x)\\cdot(1-f(x))\\)\n\n\n\nSoftsign\n\\(\\frac{x}{1+|x|}\\)\n\n\\((-1,1)\\)\n\\((1-|f(x)|)^2\\)\n\n\n\nHyperbolsk tangens\n\\(\\frac{e^x-e^{-x}}{e^x+e^{-x}}\\)\n\n\\((-1,1)\\)\n\\(1-\\left ( \\tanh(x) \\right )^2\\)\n\n\n\nReLU\n\\(\\begin{cases}\nx & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\\)\n\n\\([0,\\infty)\\)\n\\(\\begin{cases}\n1 & \\textrm{hvis } x &gt; 0 \\\\\n0 & \\textrm{hvis } x \\leq 0 \\\\\n\\end{cases}\\)"
  },
  {
    "objectID": "undervisningsforloeb/tabsfunktioner.html#sec-videre",
    "href": "undervisningsforloeb/tabsfunktioner.html#sec-videre",
    "title": "Tabsfunktioner",
    "section": "Videre læsning",
    "text": "Videre læsning\n\nActivation Functions in Neural Networks: With 15 examples\nRELU and SIGMOID Activation Functions in a Neural Network"
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer.html",
    "href": "undervisningsforloeb/screeningsprogrammer.html",
    "title": "Screeningsprogrammer",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nDeskriptiv statistik\nNormalfordelingen\n\nTidsforbrug i matematik: Ca. 3 x 90 minutter.\nTidsforbrug i bioteknologi: Ca. 4 x 90 minutter."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer.html#introduktion",
    "href": "undervisningsforloeb/screeningsprogrammer.html#introduktion",
    "title": "Screeningsprogrammer",
    "section": "Introduktion",
    "text": "Introduktion\nScreeningsprogrammer anvendes, når sundhedsmyndighederne til en udvalgt befolkningsgruppe tilbyder en eller anden form for test for en specifik sygdom. Testen skal helst være forholdsvis billig og nem at udføre, så man kan teste mange mennesker. Screeningsprogrammer anvendes ofte i forbindelse med kræft. For eksempel tilbydes alle danske kvinder i bestemte aldersgrupper screening for livmoderhalskræft og for brystkræft. Tilsvarende bliver alle danskere i alderen fra 50 til 74 år screenet for tarmkræft.\nMan kan arbejde med dette forløb enten i matematik alene eller i bioteknologi alene. Men det vil selvfølgelig være oplagt at lave et fælles forløb i en matematik-bioteknologi studieretning.\n\n\n\n\n\n\n\n\n\n\nScreeningsprogrammer - matematik\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nScreeningsprogrammer - bioteknologi\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "undervisningsforloeb/kNN_forlob_overvaagning.html",
    "href": "undervisningsforloeb/kNN_forlob_overvaagning.html",
    "title": "Overvågning i Monitorbian",
    "section": "",
    "text": "Forudsætninger og tidsforbrug\n\n\n\n\n\nForløbet kræver kendskab til:\n\nKoordinatsystemer\nPunkter og afstande mellem punkter\nProcentregning\n\nTidsforbrug: ca. 90 minutter (uden brug af Orange)."
  },
  {
    "objectID": "undervisningsforloeb/kNN_forlob_overvaagning.html#velkommen-til-monitorbian",
    "href": "undervisningsforloeb/kNN_forlob_overvaagning.html#velkommen-til-monitorbian",
    "title": "Overvågning i Monitorbian",
    "section": "Velkommen til Monitorbian",
    "text": "Velkommen til Monitorbian\nLandet Monitorbian ønsker at blive en vaskeægte overvågningsstat! Men efterretningstjenesten i Monitorbian ved meget lidt om overvågning. Derfor har de ansat jer som intelligence officerer til at løse denne opgave. Tillykke med jeres nye job! Lad os smøge ærmerne op og komme i gang! 😄\nI Monitorbian findes der to forskellige slags indbyggere: Nogle nedstammer fra Anders And, mens andre nedstammer fra Fedtmule. På figur 1 kan du se, hvordan de forskellige indbyggere ser ud.\n\n\n\n\n\n\nFigur 1: Billede af de to slags indbyggere i Monitorbian. Indbyggeren til venstre nedstammer fra Anders And, mens indbyggeren til højre nedstammer fra Fedtmule.\n\n\n\n\nFeatures\nFor at overvåge indbyggerne er vi nødt til at identificere nogle egenskaber ved indbyggerne, som kan bruges til at adskille dem fra hinanden. Sådan en egenskab kaldes for en feature. En feature kunne for eksempel være en indbyggers vægt. Det vil være en god feature, hvis de to forskellige slags indbyggere har forholdsvis forskellig vægt. En anden feature kunne være øjenfarve, men hvis det ikke på en eller anden måde kan være med til at skelne de to slags indbyggere fra hinanden, så vil øjenfarve være et dårlig valg af feature i denne sammenhæng.\n\n\n\n\n\n\nOpgave 1: Features\n\n\n\n\n\nSe på billedet i figur 1 og find på nogle flere features.\n\n\n\n\n\nTræningsdata\nSom I lige har set i opgave 1, er der rigtig mange egenskaber ved indbyggerne, der kan bruges som features. Men som intelligence officerer er vi nødt til at træffe et valg og beslutte os for, hvad vi vil gå videre med. I har derfor netop været til møde i sikkerhedsudvalget, hvor det er blevet besluttet, at højde (målt i \\(cm\\)) og fodareal (målt i \\(cm^2\\)) er de to features, som I skal arbejde videre med. Disse to features er forholdsvis nemme at scanne, og fremadrettet bliver det derfor sådan, at hver gang en indbygger i Monitorbian går ind i en offentlig bygning, så bliver vedkommende scannet og højde og fodareal bliver målt.\nI skal nu have lavet en algoritme1, som kan forudsige, hvilken slags indbygger der er tale om – alene baseret på viden om en given indbyggers højde og fodareal. Man siger, at vi gerne vil klassificere indbyggerne – her i to klasser: Anders And og Fedtmule.\n1 Tænk på en algoritme som en slags opskrift, som kan bruges til at forudsige hvilken slags indbygger, der er tale om.2 Man siger også, at vi gerne vil prædiktere hvilken slags indbygger, der er tale om.For at gøre det har vi brug for træningsdata. Træningsdata består af en masse data fra forskellige indbyggere, hvor de to features er blevet målt samtidig med, at det for hver indbygger er angivet om vedkommende nedstammer fra Anders And eller fra Fedtmule. Denne sidste oplysning er jo lige præcis den oplysning, som vi gerne fremadrettet vil kunne forudsige2. I træningsdata angiver vi altså den værdi, som vi gerne vil prædiktere. Derfor kalder man også denne værdi for en targetværdi.\n\n\n\n\n\n\nOpgave 2: Træningsdata\n\n\n\n\n\nNedenstående viser en tabel med træningsdata3, men targetværdien mangler. Angiv targetværdien (\"Anders And\" eller \"Fedtmule\").\n\n\n\n\n\n\n\n\n\nIndbygger\nFodareal (\\(cm^2\\))\nHøjde (\\(cm\\))\nTargetværdi\n\n\n\n\n\n197\n123\n\n\n\n\n214\n155\n\n\n\n\n255\n115\n\n\n\n\n297\n96\n\n\n\n\n213\n74\n\n\n\n\n173\n138\n\n\n\n\n272\n115\n\n\n\n\n235\n94\n\n\n\n\n311\n99\n\n\n\n\n334\n116\n\n\n\n\n276\n151\n\n\n\n\n283\n92\n\n\n\n\n234\n132\n\n\n\n\n172\n97\n\n\n\n\n278\n74\n\n\n\n\n241\n75\n\n\n\n\n220\n62\n\n\n\n\n249\n86\n\n\n\n\n138\n96\n\n\n\n\n252\n93\n\n\n\n\n\n\n\n3 Billederne er i øvrigt genereret med en AI billedgenerator i programmet craiyon.\n\nNærmeste naboer (kNN)\nDer findes en lang række af metoder til at lave klassifikation, som er det, vi har brug for her. Nogle af dem bruger meget avanceret matematik og enorme computerkræfter og kan anvendes til diagnosticering af sygdomme, klassificere dokumenter i forskellig typer, genkende objekter i billeder og videoer. Helt så avancerede metoder får vi dog ikke brug for her.\nVi vil i stedet fokusere på én af de simpleste, men alligevel effektive metoder til at klassificere observationer. Metoden kaldes på engelsk k-nearest neighbors eller på dansk k-nærmeste naboer, og forkortes ofte som kNN. kNN er baseret på den simple antagelse, at observationer, som er tæt på hinanden, også ligner hinanden. I vores eksempel vil det være, at indbyggere, som har cirka samme højde og fodareal, vil vi antage, hører til i den samme klasse.\nFor at bestemme hvilke naboer, der ligger tæt på hinanden, er vi nødt til at kunne beregne afstanden mellem to punkter. Du husker nok, at afstanden \\(d\\) mellem punktet \\(P(x_1,y_1)\\) og punktet \\(Q(x_2,y_2)\\) er\n\\[\nd = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\n\\tag{1}\\]\nPå figur 2 nedenfor ser I de træningsdata, som I selv angav en targetværdi for i den foregående opgave. Måske var det for nogle af indbyggerne svært at afgøre oprindelsen alene ved at se på billedet – og måske var det nemt nok, men her ses i hvert tilfælde den korrekte klassificering4.\n4 Man kan forestille sig, at en sådan klassificering er baseret på yderligere test og undersøgelser, som man normalvis ikke vil have til rådighed.\n\n\n\n\n\nFigur 2: Datasættet med fodareal ud af \\(x\\)-aksen og højde op af \\(y\\)-aksen. De røde punkter svarer til Fedtmule-indbyggere, mens de blå svarer til Anders And-indbyggere.\n\n\n\n\n\n\n\n\n\nOpgave 3: Afstande\n\n\n\n\n\nBeregn afstanden fra det grå punkt til de syv punkter, som er markeret i figur 3 herunder. Sørg for at skrive de beregnede afstande ned – du skal bruge dem senere!\n\n\n\n\n\n\n\n\n\nFigur 3: Et udsnit af data med et nyt gråt punkt indsat. De røde punkter svarer til Fedtmule-indbyggere, mens de blå svarer til Anders And-indbyggere.\n\n\n\nNår \\(k\\)-nærmeste naboer bruges til at klassificere en ny indbygger benyttes en flertalsafstemning (også kaldet majoritetsbeslutning). Det vil sige, at en ny indbygger bliver prædikteret til at tilhøre den klasse, som de fleste af indbyggerens \\(k\\)-nærmeste naboer tilhører. Hvis for eksempel \\(k=5\\), og vi har en ny indbygger, som vi gerne vil afgøre klassen for, så ser vi simpelthen på de 5 nærmeste naboer til denne indbygger og tæller op, hvilke klasser de tilhører. Hvis to af dem nedstammer fra Anders And og tre fra Fedtmule, så vil en flertalsafstemning sige, at den nye indbygger nok er i Fedtmule-klassen. Man kan komme ud for, at præcis halvdelen af de \\(k\\) nærmeste naboer nedstammer fra Anders And, mens præcis den anden halvdel nedstammer fra Fedtmule. I det tilfælde vil vi sige, at klassifikationen er uafklaret.\nDenne idé vil vi nu bruge.\n\n\n\n\n\n\nOpgave 4: Afstand til ny og ukendt indbygger\n\n\n\n\n\nI figur 3 svarer det grå punkt til en ny indbygger, som skal klassificeres, og de nærmeste naboer svarer til de punkter, som du lige har beregnet afstanden til. Baseret på en flertalsafstemning blandt de fem nærmeste naboer (det vil sige, at \\(k=5\\)) vil du så sige, at den nye indbygger stammer fra Fedtmule eller fra Anders And?\n\n\n\n\n\n\n\n\n\nOpgave 5: Flertalsafstemning for forskellige værdier af \\(k\\)\n\n\n\n\n\nDer er ingen, som siger, at vi skal se på de fem nærmeste naboer. Vi kan lige så godt se på dén nærmeste nabo, på de to nærmeste naboer eller på de tre nærmeste naboer. Vi vil nu se på, hvad der sker, hvis vi ændrer på antallet af nærmeste naboer \\(k\\).\nSe igen på figur 3 og de afstande, som du beregnede i opgave 3. Du skal nu for forskellige værdier af \\(k\\) afgøre, om den nye indbygger skal klassificeres som en Fedtmule- eller en Anders And-indbygger.\nUdfyld en tabel som nedenstående (med \"andel\" mener vi den andel, som afgør flertalsafstemningen – hvis for eksempel der er tre ud af fire punkter, som er blå eller røde, skal andelen sættes til 3/4).\n\n\n\n\\(k\\)\nBlå/Rød/Uafklaret (prædiktion)\nAndel\n\n\n\n\n1\n\n\n\n\n2\n\n\n\n\n3\n\n\n\n\n4\n\n\n\n\n5\n\n\n\n\n\n\n\n\n\n\nValg af \\(k\\) og testdata\nSom du har set ovenfor, vil forskellige valg af \\(k\\) give forskellige resultater. Så hvordan vælger vi mon den bedst mulige værdi af \\(k\\)? For at afgøre det vil vi opdele vores data i to dele: træningsdata og testdata. Det kunne for eksempel være sådan, at af alle de data vi har, så bruger vi 80% som træningsdata. Det er træningsdata, som vi bruger til at lave prædiktionen med. De resterende 20% af data vil vi lade være testdata, hvor vi bruger testdata til at måle, hvor nøjagtig vores algoritme er.\nIdéen er nu denne:\n\nVi vælger en værdi af \\(k\\) – det kunne for eksempel være \\(k=5\\).\nVi ser så på hver eneste indbygger i testdata og lader som om, at vi ikke kender denne indbyggers oprindelse. Det vil sige, at vi lader som om, at vi ikke kender targetværdien. Vi vil nu bruge træningsdata til at lave en prædiktion for denne indbygger baseret på den valgte værdi af \\(k\\). Men da vi jo i virkeligheden godt kender denne indbyggers oprindelse, så får vi nu mulighed for at afgøre, om prædiktionen er rigtig eller forkert.\n\nLad os forestille os, at vi har 500 data i alt, og at vi lader 20% af disse være testdata. Det vil sige, at testdata består af 100 datapunkter. For hvert af disse datapunkter laver vi en prædiktion. Så enten prædikterer vi, at datapunktet er blåt eller rødt baseret på en flertalsafstemning af de \\(k\\) nærmeste naboer i træningsdatasættet. Holder vi denne prædiktion op mod den faktiske værdi, kan vi opstille en såkaldt confusion tabel. Et eksempel på en sådan ses her:\n\n\n\n\nPrædikteret blå\nPrædikteret rød\n\n\n\n\nFaktisk blå\n56\n9\n\n\nFaktisk rød\n7\n68\n\n\n\n\nDer er 140 datapunkter i alt, og vi kan her se, at 56 datapunkter blev prædikteret til at være blå og faktisk også er blå. Tilsvarende er 68 af datapunkterne prædikteret til at være røde, mens de faktiske også er røde. I alt 7+9=16 datapunkter har fået prædikteret en forkert farve sammenlignet med deres faktiske farve. Altså kan vi her se, at med den valgte værdi af \\(k\\) har vores kNN algoritme lavet en fejl i \\[\n\\frac{16}{140} \\approx 11.4 \\%\n\\] af tilfældene, mens den har prædikteret korrekt i \\[\n\\frac{56+68}{140} = \\frac{124}{140} \\approx 88.6 \\%\n\\] af tilfældene. Vi kan nu lave tilsvarende beregninger for forskellige værdier af \\(k\\) og helt enkelt vælge den værdi af \\(k\\), som giver den mindste fejlprocent, når vi tester på vores testdata.\nVi ser nu igen på vores simple datasæt, og deler det op i et træningsdatasæt og et testdatasæt. På figur 4 er testdata markeret med et kryds. Vi vil for forskellige værdier af \\(k\\) prædiktere farven på testdata (samtidig med at vi jo godt kender den faktiske værdi).\n\n\n\n\n\n\nFigur 4: Testdata er markeret med et kryds.\n\n\n\n\n\n\n\n\n\nOpgave 6: Valg af \\(k\\)\n\n\n\n\n\n\nBrug app’en herunder til at afgøre den prædikterede værdi af hvert testdata for \\(k=1, 2, 3, 4, 5\\). Du kan for hvert testdatapunkt få tegnet en cirkel rundt om (hvor du kan justere på radius), som kan hjælpe dig med at finde de nærmeste naboer. Udfyld en tabel som nedenstående (husk at den prædikterede farve kan være blå, rød eller uafklaret) – skriv den enten ned på et stykke papir eller brug Prædiktion for forskellige værdier af k.\n\n\n\n\n\n\n\n\n\n\n\n\n\nTestdata\nFaktisk\nPrædiktion \\(k=1\\)\nPrædiktion \\(k=2\\)\nPrædiktion \\(k=3\\)\nPrædiktion \\(k=4\\)\nPrædiktion \\(k=5\\)\n\n\n\n\n1\nRød\n\n\n\n\n\n\n\n2\nRød\n\n\n\n\n\n\n\n3\nBlå\n\n\n\n\n\n\n\n4\nBlå\n\n\n\n\n\n\n\n\n\nUdfyld for hver værdi af \\(k\\) en confusion tabel. Hvis den prædikterede farve er uafklaret, skal det tælle som en fejl. Skriv igen ned på papir eller brug Confusion tabeller.\nUdregn for hver værdi af \\(k\\) fejlprocenten. Hvilken værdi af \\(k\\) giver den mindste fejlprocent?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBonusopgave (svær og kan springes over): Hvilke muligheder er der?\n\n\n\n\n\nSe på tabellen i opgave 5 Flertalsafstemning for forskellige værdier af \\(k\\)  ovenfor.\n\nFår man altid den samme prædiktion for alle værdier af \\(k\\)?\n\nVi forestiller os nu, at vi har et nyt datasæt, som vi ikke har lavet beregninger på.\n\nEr det muligt, at der kommer til at stå blå ved \\(k=1\\) og samtidig rød ved \\(k=2\\)?\nFor hvilke værdier af \\(k\\) kan der stå uafklaret?\nHvilke mulige andele kan optræde i tabellen for \\(k=1, 2, 3, 4, 5\\)?\nPrøv at opstille alle muligheder for tabeller (for \\(k=1, 2, 3\\)).\n\n\n\n\n\n\nkNN i programmet Orange\nHer til sidst skal vi lege lidt med et program, som hedder Orange. Du kan få hjælp til at installere programmet her.\nStart med at se denne video:\n\n\n\n\n\n\n\nOpgave 7: kNN i Orange baseret på features\n\n\n\n\n\n\nInstaller Orange.\nOpbyg modellen, som det er vist i videoen ovenfor. For at gøre det får du brug for de træningsdata og testdata, som vi har brugt i det foregående.\nPrøv at ændre på værdien af \\(k\\) (\\(k=1, 2, 3, 4, 5\\)) og se om du i Orange kan genskabe resultaterne fra opgave 6.\n\n\n\n\nDet er også muligt at bruge kNN uden selv at udvælge features. I stedet kan man bruge billederne fra tabellen i opgave 2 direkte. Se her hvordan man gør det:\n\n\n\n\n\n\n\nOpgave 8: kNN i Orange baseret på billeder\n\n\n\n\n\n\nFind selv på en værdi som du gerne vil prædiktere ud fra billeder.\nTag billeder som kan bruges som træningsdata og opbyg en model, som det er vist i videoen ovenfor.\n\n\n\n\n\n\nVidere overvejelser\nDer er flere ting, man kunne overveje at arbejde videre med. For eksempel kunne man sagtens forestille sig, at det kunne give mening med mere end to features. Afstandsformlen i (1) kan faktisk sagtens udvides til flere dimensioner end to. Man finder eksempelvis afstanden mellem to punkter \\((x_1,y_1,z_1)\\) og \\((x_2,y_2,z_2)\\) i et tredimentionelt koordinatsystem på denne måde: \\[\nd = \\sqrt{(x_2-x_1)^2+(y_2-y_1)^2+(z_2-z_1)^2}\n\\] Og det er nok ikke svært at forestille sig, at man kan udvide denne formel yderligere. Det betyder, at man stadig kan bruge \\(k\\) nærmeste naboer som metode i det tilfælde, hvor man har mere end to features.\nEn anden ting at overveje er den skala, vi måler features på. Vi har for eksempel valgt at måle i \\(cm^2\\) og i \\(cm\\). Men hvad hvis vi havde målt i \\(m^2\\) og i \\(m\\)? Det er faktisk ikke helt ligegyldigt hvilken skala, man bruger, og derfor vælger man som regel også at skalere alle ens data, så de kommer på en sammenlignelig skala. Det kan du læse meget mere om i vores materiale om feature-skalering."
  },
  {
    "objectID": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_matematik.html",
    "href": "undervisningsforloeb/screeningsprogrammer/screeningsprogrammer_matematik.html",
    "title": "Screeningsprogrammer - matematik",
    "section": "",
    "text": "I dette forløb tages der udgangspunkt i artiklen Novel Blood-Based, Five-Gene Biomarker Set for the Detection of Colorectal Cancer, som du kan finde arbejdsspørgsmål til under bioteknologi delen - modul 3.\nKort fortalt handler artikel om screening for tarmkræft ved brug af fem genetiske markører, som samlet set har vist sig at være tilstrækkeligt forskellige fra syge til raske personer til at kunne danne baggrund for et screeningsprogram.\nArtiklen er meget teknisk, men den præsenterer også nogle relevante overvejelser omkring screeningsprogrammer generelt. De behøver ikke være ufejlbarlige på individniveau for at forbedre folkesundheden, men skal fange mange syge tidligt i forløbet, så behandling er mulig. De skal også være enkle og helst ikke invasive, så mange vælger screeningen til.\nVi har ikke tid og ressourcer til at etablere et datagrundløb fra en stor klinisk undersøgelse af mange mennesker, så vi vil kunstigt og med brug af matematik generere et tilsvarende datamateriale, som vi kan bruge som eksempel. Vi vil i den forbindelse bruge de indbyrdes forhold mellem syge og raske for de fem udvalgte genetiske markører fra artiklens tabel 2. Det giver forhåbentlig et realistisk bud på, hvor store forskelle mellem raske og syge, man kan forvente at finde ved genundersøgelser i forbindelse med andre alvorlige sygdomme.\nFra artiklens har vi følgende forhold syge/raske for de fem udvalgte genetiske markører:\n\n\n\nTabel 1: Tabel med forholdet mellem syge og raske for de fem udvalgte genetiske markører.\n\n\n\n\n\nGenmarkør\nForhold syge/raske\n\n\n\n\nGen1\n\\(0.43\\)\n\n\nGen2\n\\(0.42\\)\n\n\nGen3\n\\(1.34\\)\n\n\nGen4\n\\(1.29\\)\n\n\nGen5\n\\(0.42\\)\n\n\n\n\n\n\nBemærk, at nogle i gennemsnit er højere for de syge og nogle er lavere (fra \\(0.42\\) til \\(1.34\\)).\nVi vil generere talværdier for genmarkørerne ved at sample en normalfordeling, hvor vi har valgt en middelværdi som den gennemsnitlige værdi for den pågældende genmarkør og en spredning som et mål for den biologiske variation.\n\n\n\n\n\n\nAktivitet 1 - Sampling fra en normalfordeling\n\n\n\n\n\nNIKOLAJ: Jeg synes, at vi skal lade dette være en del af forudsætningerne. Vores forløb henvender sig pt direkte til eleverne.\nRepeter lidt deskriptiv statistik fra ugrupperede observationer til grupperede observationer og histogrammer. Brug elevernes højder som eksempel.\nBemærk, at histogrammer ofte har en klokkeform, og inddrag flere eksempler blandt andet med afsæt i biologisk variation.\nPræsenter tæthedsfunktioner fra normalfordelingen som en model for klokkeformen, som har vist sig at passe godt i mange anvendelser. Sandsynligheder er arealer under grafen.\nVis hvordan man kan sample data med normalfordelingen. Brug f.eks. højder af værnepligtige N(μ,σ) med middelværdi μ=180,7cm og spredning σ=6,8cm.\nFor raske har vi valgt at bruge middelværdien \\(\\mu=10\\) og spredningen \\(\\sigma=5\\) – altså normalfordelingen \\(N(10,5)\\).\nFor syge ændrer vi middelværdien afhængig af det angivne forhold i tabel 1 for den pågældende genmarkør, men beholder en spredning på \\(5\\).\n\n\n\nGenmarkør\nAnvendt fordeling\n\n\n\n\nGen1\n\\(N(4.3,5)\\)\n\n\nGen2\n\\(N(4.2,5)\\)\n\n\nGen3\n\\(N(13.4,5)\\)\n\n\nGen4\n\\(N(12.9,5)\\)\n\n\nGen5\n\\(N(4.2,5)\\)\n\n\n\nVi kan nu generere vores kunstige kliniske data ved at sample fra disse normalfordelinger. Her skal Ege lave noget smart, så vi kan undgå Maple.\n\n\n\n\n\n\n\n\n\nAktivitet 2 - Generering af fiktive kliniske data\n\n\n\n\n\n\nGenerer kunstige kliniske data for raske og for syge ved at sample fra normalfordelingerne ovenfor.\nPrøv også generere data, hvor spredningen er sat ned fra \\(5\\) til \\(2\\). Det bør give en større forskel på de kliniske data for syge og for raske. Overvej hvorfor.\nPrøv tilsvarende at generere data, hvor spredningen er sat op fra \\(5\\) til \\(10\\). Det bør give en mindre forskel på de kliniske data for syge og for raske. Overvej hvorfor.\n\nBemærk, at vi har valgt at bruge normalfordelingerne \\(N(10,5)\\) som udgangspunkt. Det er blot for at illustrere metoden. Det har altså ikke afsæt i kendte biologiske parametre. At sætte middelværdien til \\(10\\) svarer blot til at vælge en enhed, hvor talværdien bliver \\(10\\), så det er ret uproblematisk. At sætte spredningen til \\(5\\) kan være mere problematisk, da det svarer til at angive information om den biologiske variation for den pågældende genmarkør.\nI en virkelig anvendelse med brug af rigtige kliniske data for raske og for syge ville man sikkert se, at normalfordelinger er en god model for de kliniske data, men at middelværdi og spredning er forskellig for hver af de fem genmarkører.\n\n\n\n\n\n\n\n\n\nAktivitet 3 - Træning af kunstigt neuralt netværk\n\n\n\n\n\nScreencast her med brug enten af app eller af Orange.\nVi vil nu illustrere, hvordan de kliniske data kan bruges til at træne et neuralt net, som efterfølgende kan bruges i vores screeningsprogram for den pågældende sygdom. Vi lader de første syv raske og syv syge personer udgøre vores træningsdata.\n…\nFør vi kan bruge det i et screeningsprogram, skal vi bruge de resterende seks personer fra vores fiktive kliniske data til at teste, om det virker efter hensigten.\n…\nVi ser, at modellen stort set ser ud til at virke, men dog ikke fanger, at personF er syg. PersonD og personE ville imidlertid være blevet opdaget ved en screening.\nKvaliteten af en AI anvendelse afhænger voldsomt af kvaliteten og mængden af træningsdata.\n\n\n\n\n\n\n\n\n\nAktivitet 4 - Lav jeres eget screeningsprogram\n\n\n\n\n\nBrug nogle af jeres egne fiktive kliniske data fra aktivitet 2 som træningsdata og andre af jeres kliniske data som testdata.\nDefiner og træn et kunstigt neuralt net med jeres træningsdata, som det blev vist i aktivitet 3.\nAfprøv derefter med jeres testdata om screeningen for sygdommen med AI virker.\nEvt. også noget med at prøve på de data, hvor der har været ændret på spredningen."
  },
  {
    "objectID": "undervisningsforlob.html",
    "href": "undervisningsforlob.html",
    "title": "Undervisningsforløb",
    "section": "",
    "text": "Hvem ligner du mest?\n\n\n\n\n\n\nEvnen til at skelne mellem forskellige kategorier er helt central for os som mennesker. Vi kan langt oftest kende forskel på et æble og en pære, på en cykel og en knallert eller på om en person er en kvinde eller en mand. Men hvordan får man en computer til at gøre det samme?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOvervågning i Monitorbian\n\n\n\n\n\n\nNogle lande overvåger deres borgere. Men hvordan gør man mon det? I dette forløb bliver I ansat af efterretningstjenesten i landet Monitorbian for at hjælpe dem med at overvåge deres borgere.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAI og rødder i andengradspolynomier\n\n\n\n\n\n\nEt andengradspolynomium kan have enten ingen, én eller to rødder. I skal her lære om, hvordan man kan bruge kunstig intelligens til at bestemme antallet af rødder i et andengradspolynomium.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nOverfitting og krydsvalidering med polynomiel regression\n\n\n\n\n\n\nIntroduktion til begreberne overfitting og krydsvalidering vha. polynomiel regression. Som eksempel ses på en fiktiv sammenhæng mellem antal biografbesøg og antal venner på de sociale medier.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLogistisk regression\n\n\n\n\n\n\nEt længere forløb om logistisk regression som supplerende stof på A-niveau inklusiv spørgsmål til mundtlig eksamen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAktiveringsfunktioner\n\n\n\n\n\n\nI opbygningen af kunstige neurale netværk er aktiveringsfunktioner helt centrale. Og aktiveringsfunktioner skal differentieres – det handler dette forløb om.\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html",
    "title": "Simple neurale netværk",
    "section": "",
    "text": "Vi vil her beskrive simple neurale netværk (også kaldt for Sigmoid neuroner), som er en udvidelse af den klassiske perceptron og dermed en trædesten på vej mod at forstå generelle neurale netværk."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#medlemsapp-til-good-food",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#medlemsapp-til-good-food",
    "title": "Simple neurale netværk",
    "section": "Medlemsapp til Good Food",
    "text": "Medlemsapp til Good Food\nLad os tage udgangspunkt i et fiktivt eksempel. Vi forestiller os, at dagligvare kæden Good Food er ved at udvikle en ny medlemsapp, som kunderne kan hente og bruge til at aktivere forskellige tilbud, når de handler i Good Food. Når kunderne opretter en profil i app’en, oplyser de deres navn, fødselsdato og køn. Samtidig registrer app’en løbende, hvilke køb kunden foretager, hvilken ugedag de handler med videre. For at undgå at app’en bliver for uoverskuelig for kunderne, skal app’en kun vise et begrænset udvalg af tilbud, som kunden kan aktivere. For eksempel skal en midaldrende mand, som i den seneste måned har købt for 10000 kr. i app’en, have vist nogle andre tilbud end en teenagepige, som kun sjældent handler i Good Food.\n\n\n\n\n\nGood Food sætter derfor en undersøgelse i gang. Om alle deres kunder, som har app’en, registrerer de:\n\n\\(x_1\\): kundens alder målt i år\n\\(x_2\\): kundens forbrug i Good Food den seneste måned målt i kr.\n\nDisse to værdier \\(x_1\\) og \\(x_2\\) kaldes for inputværdier. Samtidig har de i en periode for hver kunde registreret, om kunden har aktiveret et bestemt tilbud. Denne information gemmes på denne måde:\n\\[\nt=\n\\begin{cases}\n1 & \\textrm{hvis tilbudet aktiveres} \\\\\n0 & \\textrm{hvis tilbudet ikke aktiveres} \\\\\n\\end{cases}\n\\]\nVærdien \\(t\\) kaldes for en targetværdi, fordi det er denne værdi, vi gerne i fremtiden vil kunne forudsige baseret på kundens alder og forbrug. Hvis Good Food kan forudsige, om en given kunde med stor sandsynlighed vil aktivere et bestemt tilbud, så vil det være en god idé at vise lige præcis dét tilbud fremfor et alternativ, som kunden måske er mindre tilbøjelig til at aktivere.\nEt datasæt, som for hver kunde består af inputværdierne \\(x_1\\), \\(x_2\\) og den tilhørende targetværdi \\(t\\), kaldes for et træningsdatasæt. I figur 1 ses et fiktivt eksempel på sådan et træningsdatasæt. Her er et punkt farvet rødt, hvis targetværdien er \\(1\\) (det vil sige, at tilbudet er aktiveret) og blåt, hvis targetværdien er \\(0\\) (og tilbudet er ikke aktiveret).\n\n\n\n\n\n\n\n\nFigur 1: Fiktivt datasæt som viser 100 Good Food kunders alder og forbrug. Hvert punkt, som repræsenterer en kunde, er farvet rødt, hvis kunden har aktiveret tilbudet og blåt ellers.\n\n\n\n\n\nFor at forudsige – eller med et fint ord: at prædiktere – om tilbudet aktiveres eller ej, vil vi prøve, om vi kan beregne en værdi \\(o\\) (\\(o\\) kaldes også for outputværdien), som kunne være et bud på sandsynligheden for, at en kunde med en given alder og et givent forbrug vil aktivere tilbudet. En måde at modellere en sandsynligheden på er at bruge en såkaldt sigmoid-funktion. Forskriften for sigmoid-funktionen er\n\\[\n\\sigma(x)=\\frac{1}{1+e^{-x}}\n\\tag{1}\\]\nog grafen ses i figur 2.\n\n\n\n\n\n\nFigur 2: Grafen for sigmoid-funktionen med forskrift \\(\\sigma(x)=\\frac{1}{1+e^{-x}}\\).\n\n\n\nDefinitionsmængden for sigmoid-funktionen er alle reelle tal, mens værdimængden er intervallet \\((0,1)\\). Det kan skrives sådan her:\n\\[\n\\sigma: \\mathbb{R} \\rightarrow (0,1).\n\\]\nDa værdimængden er \\((0,1)\\), kan sigmoid-funktionen netop bruges til at modellere sandsynligheden for om tilbudet aktiveres. Spørgsmålet er nu, hvordan man gør det.\nFor det første skal sigmoid-funktionen selvfølgelig på en eller anden måde afhænge af vores inputværdier \\(x_1\\) og \\(x_2\\). Det kan man gøre på mange måder, men en ofte anvendt metode er, at \"sende\" en linearkombination af inputværdierne ind i sigmoid-funktionen, så outputværdien \\(o\\) beregnes sådan her:\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2).\n\\tag{2}\\]\nHer kaldes \\(w_0, w_1\\) og \\(w_2\\) for vægte, og opgaven bliver nu, at finde værdier af disse vægte sådan, at outputværdien \\(o\\) for givne værdier af \\(x_1\\) og \\(x_2\\) bliver god til at modellere sandsynligheden for, om tilbudet aktiveres eller ej.\nDet er her, at træningsdata kommer i spil, fordi vi for en lang række af inputværdier \\(x_1\\) og \\(x_2\\) jo faktisk ved, om tilbudet blev aktiveret eller ej (husk på at den oplysning er gemt i targetværdien \\(t\\)).\nForestil dig for en stund at vi på en eller anden måde har bestemt værdier af \\(w_0, w_1\\) og \\(w_2\\). Vi kan nu sammenligne værdien af \\(o\\) (vores pt bedste bud på sandsynligheden) og targetværdien (som er den værdi, vi gerne vil kunne forudsige). Hvis \\(t=0\\) vil vi også gerne have, at \\(o\\) er tæt på \\(0\\), og omvendt hvis \\(t=1\\) vil vi gerne have, at \\(o\\) er tæt på \\(1\\). Det vil sige, at differensen\n\\[\nt-o = t-\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2)\n\\] ønskes tæt på \\(0\\). Nu kan differensen både være positiv og negativ, og for at slippe for fortegn vælger vi i stedet at se på den kvadrerede differens: \\[\n\\left ( t-\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2) \\right )^2\n\\]\nDer er ikke bare ét, men rigtig mange træningsdata og derfor vælger man, at summere (det vil sige, \"at lægge sammen\") alle disse kvadrerede differenser:\n\\[\nE = \\frac{1}{2} \\sum \\left ( t-\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2) \\right )^2,\n\\]\nhvor der altså her summeres over alle træningsdata. Vi har lige ganget med \\(\\frac{1}{2}\\) foran. Det kan virke lidt mærkeligt, men du ser fidusen senere.\nHvis vægtene \\(w_0, w_1\\) og \\(w_2\\) er valgt, så sigmoid-funktionen er god til at prædiktere, om tilbudet aktiveres eller ej, så vil ovenstående udtryk være tæt på \\(0\\). Det vil sige, at hvis \\(E\\) er tæt på \\(0\\), så har vi valgte gode værdier af vægtene, mens hvis \\(E\\) er langt væk fra \\(0\\), så har vi valgt mindre gode værdier af vægtene (i forhold til det overordnede ønske om at være i stand til at prædiktere om tilbudet aktiveres eller ej). Denne funktion \\(E\\), som jo afhænger af vægtene \\(w_0, w_1\\) og \\(w_2\\), kaldes for en tabsfunktion (eller på engelsk error function).\nNu er vægtene jo ikke givet på forhånd, men det er lige præcis tabsfunktionen, man bruger til at bestemme \"gode\" værdier af vægtene. Det gøres ved at bestemme de værdier af vægtene, som minimerer tabsfunktionen. Det er altså et optimeringsproblem, vi står overfor. Hvordan det løses, kan du læse om i næste afsnit."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#hvordan-bestemmes-vægtene",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#hvordan-bestemmes-vægtene",
    "title": "Simple neurale netværk",
    "section": "Hvordan bestemmes vægtene?",
    "text": "Hvordan bestemmes vægtene?\nInden vi går i gang med at finde ud af, hvordan vægtene bestemmes, så værdien af tabsfunktionen bliver så lille som mulig, vil vi lige gør det lidt mere generelt. For det første har man i virkelighedens verden sjældent kun to inputværdier \\(x_1\\) og \\(x_2\\). Vi siger derfor helt generelt, at vi har \\(n\\) inputværdier \\(x_1, x_2, \\cdots, x_n\\). Det betyder, at outputværdien \\(o\\) nu beregnes sådan her:\n\\[\no = \\sigma (w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2 + \\cdots + w_n \\cdot x_n).\n\\]\nSamtidig forestiller vi os, at vi har \\(M\\) træningsdata. Det vil sige, \\(M\\) forskellige sæt af inputværdier med tilhørende targetværdi. Det kan opskrives sådan her:\n\\[\n\\begin{aligned}\n&\\text{Træningseksempel 1:} \\quad (x_{1,1}, x_{1,2}, \\dots, x_{1,n}, t_1) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel m:} \\quad (x_{m,1}, x_{m,2}, \\dots, x_{m,n}, t_m) \\\\\n&  \\quad \\quad \\quad \\quad \\vdots \\\\\n&\\text{Træningseksempel M:} \\quad (x_{M,1}, x_{M,2}, \\dots, x_{M,n}, t_M) \\\\\n\\end{aligned}\n\\]\nog tabsfunktionen bliver da\n\\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) \\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2.\n\\end{aligned}\n\\]\nDet er en funktion af flere variable. I princippet kan man bestemme minimum ved at sætte alle de partielle afledede lig med \\(0\\) og dernæst overbevise sig selv om, at man har fundet et minimum. Det vil give et ligningssystem med \\(n+1\\) ligninger, som alle er koblet med hinanden. Det viser sig, at være en beregningsmæssig tung opgave at løse dette ligningssystem analytisk. Derfor bruger man i stedet for den metode, som kaldes for gradientnedstigning. Gradientnedstigning går ud på først at vælge tilfældige værdier af vægtene \\(w_0, w_1, \\cdots, w_n\\). Det viser sig så, at den negative gradient vil pege i den retning, hvor funktionsværdien falder mest. Derfor er idéen at bevæge sig et lille stykke i den negative gradients retning – fordi vi så kommer lidt tættere på minimum. Når vi har gjort det, beregner vi gradienten igen, og bevæger os igen et lille stykke i den negative gradients retning. Det forsætter vi med indtil værdien af tabsfunktionen ikke ændrer sig særlig meget, hvilket svarer til, at vi har fundet minimum.\nNår vi for alle vægtene bevæger os et lille stykke i den negative gradients retning, kan opdateringen af vægtene skrives sådan her:\n\\[\n\\begin{aligned}\nw_0 \\leftarrow & w_0 - \\eta \\cdot \\frac{\\partial E }{\\partial w_0} \\\\\nw_1 \\leftarrow & w_1 - \\eta \\cdot \\frac{\\partial E }{\\partial w_1} \\\\\n&\\vdots  \\\\\nw_n \\leftarrow & w_n - \\eta \\cdot \\frac{\\partial E }{\\partial w_n} \\\\\n\\end{aligned}\n\\]\nhvor \\(\\eta\\) (udtales \"eta\") kaldes for en learning rate. Det er \\(\\eta\\), som bestemmer hvor stort et skridt i gradientens retning, vi tager. Pilene til venstre illustrerer opdatering af vægtene.\nFor at foretage opdateringerne har vi altså brug for at bestemme den partielle afledede for hver af vægtene. Den partielle afledede for den \\(i\\)’te vægt kan findes ved at bruge sum- og kædereglen:\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{m=1}^{M} \\frac{\\partial}{\\partial w_i}\\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2 \\\\\n&= \\frac{1}{2} \\sum_{m=1}^{M} 2 \\cdot \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\\\\n& \\quad  \\quad \\quad  \\quad  \\cdot \\frac{\\partial}{\\partial w_i} \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n} ) \\right) \\\\\n&=  \\sum_{m=1}^{M} \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\\\\n& \\quad  \\quad \\quad  \\quad  \\cdot \\frac{\\partial}{\\partial w_i} \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n} ) \\right) \\\\\n\\end{aligned}\n\\tag{3}\\]\nBemærk, at \\(\\frac{1}{2}\\) forkortede ud – det var derfor, at vi gangede \\(\\frac{1}{2}\\) på tabsfunktionen til at starte med.\nBetragter vi nu kun den sidste faktor og bruger kædereglen igen, får vi\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t_m &- \\sigma(w_0 +  w_1 \\cdot x_{m,1} + \\cdots   + w_n \\cdot x_{m,n} )) = \\\\\n&- \\sigma'(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\\cdot  \\\\ & \\qquad \\qquad \\qquad\n\\qquad \\frac{\\partial}{\\partial w_i} \\left (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n} \\right)\n\\end{aligned}\n\\] Nu er \\[\n\\frac{\\partial}{\\partial w_i} \\left (w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_i \\cdot x_{m,i} + \\cdots  + w_n \\cdot x_{m,n} \\right) = x_{m,i}\n\\]\nSå \\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t_m -\n\\sigma(w_0 &+ w_1 \\cdot x_{m,1}  + \\cdots  + w_n \\cdot x_{m,n} )) = \\\\ &- \\sigma'(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\\cdot x_{m,i}\n\\end{aligned}\n\\]\nVi mangler nu bare at finde den afledede sigmoid-funktion. Man kan vise – se forløbet om aktiveringsfunktioner – at\n\\[\n\\sigma'(x)=\\sigma(x)\\cdot(1-\\sigma(x))\n\\]\nDerfor bliver\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t_m -\n\\sigma(w_0 &+ w_1 \\cdot x_{m,1} + \\cdots  + w_n \\cdot x_{m,n} )) = \\\\\n&- \\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\cdot \\\\ & (1-\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots  + w_n \\cdot x_{m,n} )) \\cdot x_{m,i}\n\\end{aligned}\n\\]\nNu kaldte vi jo \\(\\sigma(w_0 + w_1 \\cdot x_1 + w_2 \\cdot x_2)\\) for outputværdien \\(o\\) (se (2)). For at gøre ovenstående lidt mere læsevenligt vil vi derfor kalde outputværdien hørende til det \\(m\\)’te træningseksempel for \\(o_m\\):\n\\[\no_m = \\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\n\\]\nVi får så\n\\[\n\\begin{aligned}\n\\frac{\\partial}{\\partial w_i} (t_m -\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots  &+ w_n \\cdot x_{m,n} )) = \\\\ &- o_m\\cdot (1-o_m) \\cdot x_{m,i}\n\\end{aligned}\n\\]\nIndsættes dette i (3) samtidig med at vi bruger, at\n\\[o_m = \\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\\]\nfår vi\n\\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} = - \\sum_{m=1}^{M} \\left (t_m-o_m \\right) \\cdot o_m\\cdot (1-o_m) \\cdot x_{m,i}\n\\end{aligned}\n\\]\nDette gælder for \\(i \\in \\{1, 2, \\dots, n \\}\\). Når \\(i=0\\) er det ikke svært at overbevise sig selv om, at\n\\[\n\\frac{\\partial E}{\\partial w_0} = - \\sum_{m=1}^{M} \\left (t_m-o_m \\right) \\cdot o_m\\cdot (1-o_m) \\cdot 1\n\\]\nDerfor ender vi med:\n\n\n\n\n\n\nOpdateringsregler for simple neurale netværk\n\n\n\n\\[\n\\begin{aligned}\nw_0 \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\left (t_m-o_m \\right) \\cdot o_m\\cdot (1-o_m) \\\\\nw_1 \\leftarrow & w_1 + \\eta \\cdot \\sum_{m=1}^{M} \\left (t_m-o_m \\right) \\cdot o_m\\cdot (1-o_m) \\cdot x_{m,1}\\\\\n&\\vdots  \\\\\nw_n \\leftarrow & w_n + \\eta \\cdot \\sum_{m=1}^{M} \\left (t_m-o_m \\right) \\cdot o_m\\cdot (1-o_m) \\cdot x_{m,n}\n\\end{aligned}\n\\]\nhvor \\(o_m = \\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\\).\n\n\nI praktisk vil man som sagt blive ved med at opdatere vægtene, indtil værdien af tabsfunktionen ikke ændrer sig særlig meget.\nNår vi på den måde har bestemt værdien af vægtene, kan vi bruge outputværdien \\(o\\) til at forudsige, om en kunde vil aktivere tilbudet eller ej. Det vil vi gøre på denne måde:\n\\[\n\\textrm{Kunden aktiverer tilbudet: }\n\\begin{cases}\n\\textrm{JA} & \\textrm{hvis } o \\geq 0.5\\\\\n\\textrm{NEJ} & \\textrm{hvis } o &lt; 0.5\\\\\n\\end{cases}\n\\tag{4}\\]\nhvor\n\\[\no = \\sigma(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n).\n\\] Bemærk, at når vi tænker på \\(o\\) som sandsynligheden for, at kunden vil aktivere tilbudet, så giver det god mening, at vi vil prædiktere, at kunden vil aktivere tilbudet, hvis \\(o \\geq 0.5\\) og ellers ikke.\nSkillelinjen, som afgører, om vi prædikterer, at kunden aktiverer tilbudet eller ej, går ved\n\\[\n\\sigma(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n) = 0.5.\n\\]\nSer på definitionen af sigmoid-funktionen i (1) svarer det til, at\n\\[\n\\frac{1}{1+e^{-(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n)}} = 0.5.\n\\]\nNu giver brøken til venstre præcis \\(0.5\\), hvis\n\\[\ne^{-(w_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n)} = 1.\n\\] Det vil sige, at\n\\[\nw_0 + w_1\\cdot x_1 + \\cdots + w_n \\cdot x_n = 0.\n\\]\nI vores eksempel om Good Food app’en havde vi kun to inputværdier. Det betyder, at ovenstående kan reduceres til\n\\[\nw_0 + w_1\\cdot x_1 + w_2 \\cdot x_2 = 0.\n\\] Det er lige præcis ligningen for en ret linje. Hvis vi i vores eksempel prøver at finde vægtene ved hjælp af gradientnedstigning, som beskrevet ovenfor, så ender vi med\n\\[\nw_0 = -0.298, \\quad  w_1 = -0.0375 \\quad \\textrm{ og } \\quad  w_2=0.000769\n\\] Det giver ligningen \\[\n-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2=0\n\\] hvilket også kan omskrives til\n\\[\nx_2 = 48.7 \\cdot x_1 +387\n\\]\neller måske den lidt mere velkendte skrivemåde:\n\\[\ny = 48.7 \\cdot x+387\n\\]\nIndtegnes denne linje sammen med datasættet fra Good Food får vi:\n\n\n\n\n\n\n\n\nFigur 3: Fiktivt datasæt som viser 100 Good Food kunders alder og forbrug. Hvert punkt, som repræsenterer en kunde, er farvet rødt, hvis kunden har aktiveret tilbudet og blåt ellers. Samtidig er den linje indtegnet, som fås ved at bruge et simpelt neuralt netværk på data.\n\n\n\n\n\nDet vil nu være sådan, at for alle punkter \\((x_1,x_2)\\), som ligger over linjen i figur 3, vil\n\\[\n-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2 &gt; 0.\n\\] Det vil sige, at (se eventuelt figur 2) \\[\no = \\sigma (-0.298 - 0.0375\\cdot x_1 + 0.000769\\cdot x_2) &gt; 0.5.\n\\] Ifølge (4) betyder det, at for alle punkter, som ligger over linjen, vil vi prædiktere, at den tilhørende kunde, vil aktivere tilbudet. Og det omvendte gælder så selvfølgelig for alle punkter, som ligger under linjen: her vil vi prædiktere, at de tilhørende kunder ikke aktiverer tilbudet."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#aktiviteringsfunktioner",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#aktiviteringsfunktioner",
    "title": "Simple neurale netværk",
    "section": "Aktiviteringsfunktioner",
    "text": "Aktiviteringsfunktioner\nSigmoid-funktionen, som er anvendt her, kaldes for en aktiveringsfunktion. Her brugte vi den, fordi den har den egenskab, at værdimængden er \\((0,1)\\), og derfor kan outputværdien fra sigmoid-funktionen fortolkes som en sandsynlighed. Men man behøver ikke nødvendigvis at bruge sigmoid-funktionen som aktiveringsfunktion. Der findes en lang række andre aktiveringsfunktioner, som kan bruges i stedet for. Hvis du har lyst til at lære mere, kan du se på vores forløb om andre aktiveringsfunktioner."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#smartere-end-adaline",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#smartere-end-adaline",
    "title": "Simple neurale netværk",
    "section": "Smartere end ADALINE?",
    "text": "Smartere end ADALINE?\nHvis du har læst noten om perceptroner er du blevet præsenteteret for den klassiske perceptron (det var den, som vi også kaldte for Rosenblatts perceptron). Her forklarede vi to forskellige måder at opdatere vægtene på: perceptron learning algoritmen og ADALINE. Perceptron learning algoritmen dur kun, hvis data er lineært separable. Det problem klarede ADALINE. Men faktisk er det simple neurale netværk, som vi har præsenteret her, smartere end ADALINE. Hvis du vil blive klogere på hvorfor, kan du læse mere her."
  },
  {
    "objectID": "materialer/simple_neurale_net/simple_neurale_net.html#overblik",
    "href": "materialer/simple_neurale_net/simple_neurale_net.html#overblik",
    "title": "Simple neurale netværk",
    "section": "Overblik",
    "text": "Overblik\nPerceptron learning algoritmen, ADALINE og simple neurale netværk – det kan være svært at holde tungen lige i munden. Hvad er forskellene, og hvordan peger det videre hen mod de helt generelle kunstige neurale netværk. Vi vil i dette afsnit prøve at skabe det overblik.\nI alle tilfælde har vi at gøre med træningsdata, som består af en række inputværdier \\(x_1, x_2, \\cdots, x_n\\) med en tilhørende targetværdi \\(t\\). Ønsket i alle tilfælde er også, at kunne beregne en outputværdi \\(o\\), som skal bruges til at prædiktere targetværdien i fremtidige data.\n\nPerceptron learning algoritmen\nI perceptron learning algortimen kan targetværdien1 antage værdierne \\(-1\\) og \\(1\\):\n1 I virkeligheden er det ikke så afgørende her. Men i forhold til de opdateringsregler, som vi præsenterer her, skal targetværdierne bare være symmetriske omkring \\(0\\).\\[\nt \\in \\{-1,1\\}.\n\\] Outputværdien \\(o\\) defineres ved \\[\n\\begin{aligned}\n    o = \\begin{cases}\n    1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n \\geq 0 \\\\\n    -1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n &lt; 0. \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nDenne outputværdi kan selvsagt ikke fortolkes som en sandsynlighed, men blot som en angivelse af, om vi forventer, at et nyt punkt er rødt eller blåt (altså om den ukendte targetværdi er \\(-1\\) eller \\(1\\)).\nDer er ikke knyttet nogen tabsfunktion til perceptron learning algoritmen, men den \\(i\\)’te vægt opdateres på denne måde: \\[\nw_i \\leftarrow w_i +  \\eta \\cdot  (t-o) \\cdot x_i\n\\]\n\n\nADALINE\nI ADALINE er targetværdierne igen \\(-1\\) eller \\(1\\): \\[\nt \\in \\{-1,1\\}.\n\\] Outputværdien \\(o\\) defineres igen ved \\[\n\\begin{aligned}\n    o = \\begin{cases}\n    1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n \\geq 0 \\\\\n    -1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n &lt; 0. \\\\\n    \\end{cases}\n\\end{aligned}\n\\]\nIgen kan outputværdien her ikke fortolkes som en sandsynlighed.\nI ADALINE bestemmes vægtene ved at minimere tabsfunktionen:\n\\[\n\\begin{aligned}\nE(w_0, w_1, \\dots, w_n) = \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2.\n\\end{aligned}\n\\tag{5}\\]\nGør man det, bliver opdateringsreglerne\n\\[\nw_i \\leftarrow w_i + \\eta \\cdot  \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\cdot \\left (x_{m,i} \\right).\n\\]\n\n\nSimple neurale netværk\nI det simple neurale netværk er targetværdierne \\(0\\) eller \\(1\\):\n\\[\nt \\in \\{0,1\\}.\n\\] Her beregner vi en outputværdi \\(o\\) som\n\\[\no = \\sigma(w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n).\n\\]\nHvis vi sammenligner med reglen i (4) vil vi sige, at hvis denne outputværdi \\(o \\geq 0.5\\), så vil vi prædiktere2, at den ukendte targetværdi er \\(1\\) og \\(0\\) ellers. Her kan man altså tænke på \\(o\\), som sandsynligheden for, at den ukendte targetværdi er \\(1\\).\n2 Der er faktisk ingen, som siger, at vi skal skære ved \\(0.5\\). Hvis man er i gang med at screene for en meget alvorlig sygdom, som det er vigtigt at opdage hurtigt, kunne der være god grund til at vælge en lavere værdi end \\(0.5\\).I det simple neurale netværk er tabsfunktionen \\[\n\\begin{aligned}\nE(w_0, w_1, &\\dots, w_n) \\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n\\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2\n\\\\ &= \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\no_m \\right)^2,\n\\end{aligned}\n\\tag{6}\\]\nhvor \\(o_m = \\sigma(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\\).\nOpdateringsreglen for den \\(i\\)’te vægt er: \\[\nw_i \\leftarrow w_i + \\eta \\cdot \\sum_{m=1}^{M} \\left (t_m-o_m \\right) \\cdot o_m\\cdot (1-o_m) \\cdot x_{m,i}.\n\\]\nSer vi på tabsfunktionen for ADALINE i (5) og sammenligner den med tabsfunktionen for det simple neurale netværk i (6), kan vi se, at i ADALINE bruges sigmoid-funktionen ikke som aktiveringsfunktion. I stedet bruges den funktion \\(f\\), som man kalder for identiteten. Den har forskrift \\[\nf(x)=x.\n\\]\nForskellen på ADALINE og det simple neurale netværk er altså, at aktivieringsfunktionen i ADALINE er identiteten, mens den i det simple neurale netværk er sigmoid-funktionen.\n\n\nGenerelle neurale netværk\nEt generelt neuralt netværk består egentlig bare af en masse simple neurale netværk, som er sat sammen. Det kunne se sådan her ud:\n\n\n\n\n\n\nFigur 4: Et generelt kunstigt neuralt netværk (som dog stadig er forholdsvist simpelt!).\n\n\n\nHer repræsenterer de fire lilla cirkler fire inputværdier \\(x_1, x_2, x_3\\) og \\(x_4\\). De fire grønne cirkler i midten svarer til en neuron – altså et simpelt neuralt netværk – som det er beskrevet her. Den blå cirkel svarer til den outputværdi, som netværket ender med at beregne. Hver pil i figuren svarer til en vægt, som skal beregnes. Man siger, at det netværk, som er illustreret på figur 4 har to skjulte lag (svarende til de to søjler med grønne cirkler), fordi der er to lag af neuroner fra input til output. Til sammenligning har et simpelt neuralt netværk ingen skjulte lag, fordi man direkte fra inputværdierne beregner outputværdien. Når mængden af skjulte lag bliver tilpas stor, taler man om deep learning.\nTabsfunktion og opdateringsregler bliver noget mere kompliceret for generelle neurale netværk, men du kan læse meget mere om det i vores note om kunstige neurale netværk.\nMen alt i alt kan man altså tænke på det simple neurale netværk, som byggesten til det generelle neurale netværk.\n\n\nSamlet skematisk overblik\nI tabellen herunder finder du et samlet overblik over perceptron learning algoritmen, ADALINE, simple neurale netværk og generelle neurale netværk.\n\n\n\n\n\n\n\n\n\n\n\nAI metode\nSkal data være lineært separable\nAktiveringsfunktion\nGraf\nTargetværdi\nAntal skjulte lag\n\n\n\n\nPerceptron learning algoritmen\nJa\nIngen\n–\n\\(\\{-1,1\\}\\)\n\\(0\\)\n\n\nADALINE\nNej\nIdentiteten\n\n\\(\\{-1,1\\}\\)\n\\(0\\)\n\n\nSimple neurale netværk\nNej\nSigmoid eller andre\n\n\\(\\{0,1\\}\\)\n\\(0\\)\n\n\nGenerelle neurale netværk\nNej\nSigmoid eller andre\n\n\\(\\{0,1\\}\\)\n\\(\\geq 1\\)"
  },
  {
    "objectID": "materialer/perceptron/perceptron.html",
    "href": "materialer/perceptron/perceptron.html",
    "title": "Perceptroner",
    "section": "",
    "text": "Forløberen til kunstige neurale netværk er perceptroner, som du kan læse mere om her i denne note."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#sec-kandidattest",
    "href": "materialer/perceptron/perceptron.html#sec-kandidattest",
    "title": "Perceptroner",
    "section": "Eksempel: Hvem skal jeg stemme på ved næste valg?",
    "text": "Eksempel: Hvem skal jeg stemme på ved næste valg?\nDe senere år er det blevet populært, at diverse medier laver forskellige kandidattests. Sådan nogle tests kan laves på mange forskellige måder - man kunne blandt andet bruge perceptroner! Testene fungerer som regel på den måde, at man bliver stillet en række forskellige spørgsmål og så skal man svare på en skala fra meget uenig til meget enig. Disse kategorier af svar kunne f.eks. oversættes til matematik på denne måde:\n\n\n\n\n\n\n\n\n\n\n\n\nHelt enig\nOvervejende enig\nHverken/eller\nOvervejende uenig\nHelt uenig\n\n\n\n\n2\n1\n0\n-1\n-2\n\n\n\n\n\nLad os prøve at gøre det helt simpelt. I stedet for at komme med et bud på hvem man skal stemme på, så vil vi blot forsøge at komme med et bud på, om man skal stemme på rød eller blå blok (det er sikkert en håbløs simplificering, men det må du tale med din samfundsfagslærer om ).\nLad os sige at vi vil basere vores bud på to spørgsmål:\n\nJeg synes, at indkomstskatten skal sættes ned.\nJeg synes ikke, at danske virksomheder skal pålægges en CO2-afgift.\n\nVi kan sikkert hurtigt blive enige om, at hvis man er meget enig i begge spørgsmål, så hører man formentlig til i blå blok og modsat, hvis man er meget uenig i begge spørgsmål, så hører man nok mere hjemme i rød blok. Så at lave en perceptron, som kan hjælpe os med at forudsige det, er nok ikke raketvidenskab, men det kan ikke desto mindre hjælpe os med at forstå de bagvedliggende principper og hvordan disse sidenhen kan generaliseres.\nLad os prøve at blive lidt mere specifikke og indføre to variable \\(x_1\\) og \\(x_2\\), hvor\n\n\\(x_1\\): svaret på Jeg synes, at indkomstskatten skal sættes ned angivet på en skala fra -2 til 2\n\n\\(x_2\\): svaret på Jeg synes ikke, at danske virksomheder skal pålægges en CO2-afgift angivet på en skala fra -2 til 2.\n\nVores beslutning vil vi nu også kvantificere vha. en variabel \\(t\\), som kan antage to værdier, nemlig \\(-1\\) og \\(1\\). Hvis vi hører hjemme i blå blok, vil vi sætte \\(t=1\\), mens vi vil sætte \\(t=-1\\), hvis vi vil sætte vores krydset ved et rødt parti. Altså:\n\\[\n\\begin{aligned}\nt&=-1: &\\text{Rød blok} \\\\\nt&=1: &\\text{Blå blok} \\\\\n\\end{aligned}\n\\]\nNu forestiller vi os, at vi har bedt seks personer (som godt ved, hvem de vil stemme på - måske er det ligefrem politikere vi har spurgt) om at svare på de to spørgsmål og samtidig tilkendegive, om de vil stemme på blå eller rød blok. Lad os f.eks. sige, at den første person er meget enig i at indkomstskatten skal sættes ned (dvs. \\(x_1=2\\)), og at denne person er overvejende enig i at danske virksomheder ikke skal pålægges en CO2-afgift (dvs. \\(x_2=1\\)). Desuden oplyser denne person, at han/hun vil stemme på blå blok (dvs. \\(t=1\\)). Det kan udtrykkes sådan her: \\[\n(x_1,x_2)=(2,1) \\quad \\Rightarrow \\quad  t=1\n\\tag{1}\\]\nOg sådan kunne man opstille andre eksempler: \\[\n\\begin{aligned}\n&(x_1,x_2)=(-1,1) \\quad \\Rightarrow \\quad  t=-1 \\\\\n&(x_1,x_2)=(-1,-1) \\quad \\Rightarrow \\quad  t=-1 \\\\\n&(x_1,x_2)=(1,1) \\quad \\Rightarrow \\quad  t=1 \\\\\n&(x_1,x_2)=(2,2) \\quad \\Rightarrow \\quad  t=1 \\\\\n&(x_1,x_2)=(-2,-1) \\quad \\Rightarrow \\quad t=-1 \\\\\n\\end{aligned}\n\\] Det første eksempel siger for eksempel, at en person har været overvejende uenig i at sætte indkomstskatten ned (\\(x_1=-1\\)), overvejende enig i at danske virksomheder ikke skal pålægges en CO2-afgift (\\(x_2=1\\)) og samtidig vil denne person stemme på rød blok (\\(t=-1\\)).\nVi kan prøve at indtegne \\((x_1,x_2)\\)-punkterne i et koordinatsystem og samtidig angive den tilhørende værdi af \\(t\\) med en farve. Det vil se sådan her ud:\n\n\n\n\n\n\n\n\nFigur 1: Illustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blå blok.\n\n\n\n\n\nDet kunne godt se ud som om, at det vil være muligt at indtegne en ret linje på en sådan måde, at alle punkter som ligger over linjen skulle farves blå (svarende til \"her stemmer vi på blå blok\"), mens alle punkter under linjen skulle farves røde (svarende til \"her stemmer vi på rød blok\"). En tilfældig indtegnet linje ses på figur 2.\n\n\n\n\n\n\n\n\nFigur 2: Illustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blå blok. En tilfældig linje er indtegnet.\n\n\n\n\n\nHerunder ser du et bud på en linje, som ser ud til at være god til at adskille de blå punkter fra de røde – faktisk er der jo uendeligt mange linjer, som vil kunne adskille de blå punkter fra de røde:\n\n\n\n\n\n\n\n\nFigur 3: Illustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blå blok. Her er indtegnet en linje, som kan separere de blå punkter fra de røde.\n\n\n\n\n\nLinjen på figur 3 har ligning \\[\\begin{aligned}\ny=-1.2 \\cdot x+1.5.\\end{aligned}\\] Men nu kaldte vi jo faktisk ikke de to variable for \\(x\\) og \\(y\\), men derimod for \\(x_1\\) og \\(x_2\\). Med denne notation får vi altså, at \\[\n\\begin{aligned}\nx_2=-1.2 \\cdot x_1+1.5\n\\end{aligned}\n\\] Hvis vi bruger denne ligning til at skelne imellem blå og røde punkter, så vil vi sige, at alle punkter, som ligger over linjen skal være blå. Det vil være det samme som at sige, at alle de blå punkter opfylder uligheden \\[\n\\begin{aligned}\nx_2&gt;-1.2 \\cdot x_1+1.5.\n\\end{aligned}\n\\] Eller skrevet på en anden måde: \\[\n\\begin{aligned}\n1.2 \\cdot x_1+ 1 \\cdot x_2&gt;1.5.\n\\end{aligned}\n\\] Her kalder man værdi \\(1.5\\) på højreside for threshold værdien (på dansk: tærskelværdi), fordi det er denne værdi, som afgør, om vi skal farve et punkt rødt eller blåt. Værdierne \\(1.2\\) og \\(1\\) kaldes for vægte, fordi de bestemmer, hvor meget inputværdierne \\(x_1\\) og \\(x_2\\) skal vægtes i forhold til hinanden.\nEn helt tredje måde at skrive det samme på vil være \\[\n\\begin{aligned}\n-1.5+1.2 \\cdot x_1+ 1 \\cdot x_2&gt;0.\n\\end{aligned}\n\\] Nu kalder man så bare værdien \\(-1.5\\) for en bias, men i virkeligheden er det jo bare threshold værdien med modsat fortegn1.\n1 Der er forskellige overvejelser i forhold til valget af denne skrivemåde. For det første er vi gået væk fra \\(x\\) og \\(y\\) og over til \\(x_1\\) og \\(x_2\\). Det giver mening, fordi vi ofte tænker på \\(y\\) som den afhængige variabel og \\(x\\) som den uafhængige variabel. Denne fortolkning af de to variable giver ikke mening i denne sammenhæng. Derudover kan vi beskrive en vilkårlig linje i planen ved hjælp af ligningen \\(ax_1+bx_2+c=0\\) – også de lodrette linjer. Holder vi derimod fast i \\(y=ax+b\\), så kan vi ikke “fange” de lodrette linjer.Vi har nu faktisk udledt en regel, som for tid og evighed kan hjælpe os med at afgøre, om vi skal stemme på rød eller blå blok. Den kan opsummeres sådan her:\n\n\n\n\n\n\nHvem skal jeg stemme på?\n\n\n\nSvar på en skala fra -2 til 2 på følgende spørgsmål:\n\\(x_1\\): \"Jeg synes, at indkomstskatten skal sættes ned\"\n\\(x_2\\): \"Jeg synes ikke, at danske virksomheder skal pålægges en CO2-afgift\"\nhvor 2 svarer til \"Meget enig\" og -2 svarer til \"Meget uenig\".\nBeregn nu \\(o\\) (for outputværdi) på denne måde \\[\\begin{aligned}\no = \\begin{cases}\n1 & \\text{hvis } -1.5+1.2 \\cdot x_1+ 1 \\cdot x_2 \\geq 0 \\\\\n-1 & \\text{hvis } -1.5+1.2 \\cdot x_1+ 1 \\cdot x_2 &lt; 0. \\\\\n\\end{cases}\\end{aligned}\\] Reglen er nu: \\[\\begin{aligned}\n&\\text{Hvis } o=1: \\quad &\\text{Stem blå blok.}\\\\\n&\\text{Hvis } o=-1: \\quad &\\text{Stem rød blok.}\\\\\\end{aligned}\\]\n\n\nMan siger også, at man på baggrund af inputværdierne kan lave en klassificering (eller kategorisering). Det betyder, at vi på baggrund af inputværdierne kan beregne, om vi er i kategorien \"Blå blok\" (\\(o=1\\)) eller i kategorien \"Rød blok\" (\\(o=-1\\)). Grafisk svarer det til, at man indtegner sit \\((x_1, x_2)\\)-punkt i koordinatsystemet i figur 3 og ser så på om punkt ligger over eller under linjen (ligger det over skal vi stemme blå blok).\n\nEksempel 1 Lad os sige at en vælger hverken er enig eller uenig i, at indkomstskatten skal sættes ned. Det vil sige, at \\(x_1=0\\). Samtidig er denne vælger meget enig i, at danske virksomheder ikke skal pålægges en CO2-afgift. Altså er \\(x_2=2\\). Vi udregner nu: \\[\n-1.5+1.2 \\cdot x_1+x_2=-1.5+1.2 \\cdot 0+2=0.5\n\\] Og da denne værdi er større end \\(0\\), sætter vi \\(o=1\\). Det vil sige, at vi vil anbefale denne vælger at stemme blå blok.\n\nDet er da smart! Og det her er faktisk lige præcis idéen bag perceptroner, som den amerikanske psykolog Frank Rosenblatt foreslog helt tilbage i \\(1958\\). Den klassiske perceptron er defineret ved, at perceptronen kan modtage input \\[\n\\begin{aligned}\nx_1, x_2, \\dots, x_n,\n\\end{aligned}\n\\] hvor hver enkel inputværdi i princippet kan være et vilkårligt reelt tal. I vores eksempel har vi dog begrænset inputværdierne til \\(x_1, x_2 \\in \\{-2,-1,0,1,2 \\}\\). Vi beregner så en outputværdi \\(o\\) vha. vægtene \\(w_1, w_2, \\dots, w_n\\) og en biasværdi, som vi her vil kalde for \\(w_0\\) på denne måde: \\[\n\\begin{aligned}\no = \\begin{cases}\n1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n \\geq 0 \\\\\n-1 & \\text{hvis } w_0 + w_1 \\cdot x_1 + \\cdots + w_n \\cdot x_n &lt; 0. \\\\\n\\end{cases}\n\\end{aligned}\n\\] Grafisk kan det illustreres sådan her:\n\n\n\n\n\n\nFigur 4: Grafisk illustration af en perceptron.\n\n\n\nHer illustrerer sumtegnet i cirklen, at vi tager en vægtet sum af alle inputværdierne (inklusiv et input (\\(x_0\\)), som altid er \\(1\\), og som vægtes med \\(w_0\\) svarende til, at vi får vores bias med), mens grafen af trappefunktionen i firkanten viser, at vi diskretiserer denne vægtede sum, sådan at outputværdien enten er \\(-1\\) eller \\(1\\)."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-hvad-er-en-perceptron",
    "href": "materialer/perceptron/perceptron.html#video-hvad-er-en-perceptron",
    "title": "Perceptroner",
    "section": "VIDEO: Hvad er en perceptron?",
    "text": "VIDEO: Hvad er en perceptron?\nI denne video forklarer vi ovenstående, men med udgangspunkt i et andet eksempel."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-perceptron-learning-algoritmen",
    "href": "materialer/perceptron/perceptron.html#video-perceptron-learning-algoritmen",
    "title": "Perceptroner",
    "section": "VIDEO: Perceptron Learning Algoritmen",
    "text": "VIDEO: Perceptron Learning Algoritmen\nI denne video forklarer vi perceptron learning algoritmen."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-perceptron-learning-versus-adaline",
    "href": "materialer/perceptron/perceptron.html#video-perceptron-learning-versus-adaline",
    "title": "Perceptroner",
    "section": "VIDEO: Perceptron Learning versus ADALINE",
    "text": "VIDEO: Perceptron Learning versus ADALINE\nI denne video forklarer vi idéen bag ADALINE og indfører tabsfunktionen."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#sec-ADALINE_gradientnedstigning",
    "href": "materialer/perceptron/perceptron.html#sec-ADALINE_gradientnedstigning",
    "title": "Perceptroner",
    "section": "Gradientnedstigning",
    "text": "Gradientnedstigning\nFor at gøre det bruges en metode, som kaldes for gradientnedstigning. For at forklare hvad det går ud på, er det nemmest at se på en tabsfunktion, som kun afhænger af to vægte \\(w_0\\) og \\(w_1\\). I det tilfælde får vi \\[\n\\begin{aligned}\nE(w_0, w_1) = \\frac{1}{2} \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1}) \\right)^2.\n\\end{aligned}\n\\] Da tabsfunktionenkun afhænger af to variable, kan vi tegne grafen for den. Et eksempel herpå ses i figur 9.\n\n\n\n\n\n\nFigur 9: Grafen for en tabsfunktion som afhænger af vægtene \\(w_0\\) og \\(w_1\\).\n\n\n\nIdéen er nu, at vi gerne vil bestemme vægtene \\(w_0\\) og \\(w_1\\), sådan at tabsfunktionen minimeres. Tænk lidt over det. Det giver god mening, at bestemme vægtene sådan at den samlede fejl, perceptronen begår på træningsdata, bliver så lille som mulig. Vi ved faktisk godt, hvordan man bestemmer minimum for en funktion af to variable. Løs ligningerne \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_0} = 0 \\quad \\text{og} \\quad \\frac{\\partial E}{\\partial w_1} = 0.\\end{aligned}\n\\] Det er en overkommelig opgave at finde de partielle afledede og sætte dem lig med \\(0\\) i det tilfælde, hvor tabsfunktionen kun afhænger af to vægte. Men vi skal senere se, at perceptroner bliver fundamentale byggesten i kunstige neurale netværk, og her viser det sig, at denne fremgangsmåde med at sætte de partielle afledede lig \\(0\\), er helt håbløs! Derfor bruger man gradientnedstigning.\nForestil dig at grafen for tabsfunktionen i figur 9 er et landskab med en dal. Dit mål er at finde ned i dalen. Du er blevet placeret et tilfældigt sted i landskabet svarende til tilfældige værdier af \\(w_0\\) og \\(w_1\\). Hvad gør du? Jo, du kommer i tanke om, at du har lært, at hvis du går i gradientens \\[\n\\begin{aligned}\n\\nabla E(w_0,w_1) = \\begin{pmatrix} \\frac{\\partial E }{\\partial w_0}(w_0,w_1) \\\\ \\\\ \\frac{\\partial E }{\\partial w_1}(w_0,w_1) \\end{pmatrix}\n\\end{aligned}\n\\] retning, så kommer du til at gå i den retning, hvor det går allermest opad bakke! Men hov det er jo ikke det, vi vil! Vi vil gå allermest nedad bakke, så vi ender i dalen. Hvad gør vi så? Vi vender os da bare \\(180^{\\circ}\\) og går i den modsatte retning - så ender vi nede i dalen! Det vil sige, at vi går i retning af minus gradienten: \\[\n\\begin{aligned}\n- \\nabla E(w_0,w_1) = \\begin{pmatrix} - \\frac{\\partial E }{\\partial w_0}(w_0,w_1) \\\\ \\\\ - \\frac{\\partial E }{\\partial w_1}(w_0,w_1) \\end{pmatrix}\n\\end{aligned}\n\\] Fremgangsmåden bliver derfor den, at vi starter i nogle tilfældige \\((w_0, w_1)\\)-værdier og så bevæger vi os et lille skridt i den negative gradients retning. Så ender vi i et nyt punkt, hvor vi igen beregner gradienten og går igen et lille skridt i den negative gradients retning. Sådan fortsætter vi indtil værdien af tabsfunktionen ikke rigtig ændrer sig mere – det svarer til, at vi har ramt dalen. Derfor bliver vores opdateringsregler med denne metode \\[\n\\begin{aligned}\nw_0 \\leftarrow & w_0 - \\eta \\cdot \\frac{\\partial E }{\\partial w_0} \\\\\nw_1 \\leftarrow & w_1 - \\eta \\cdot \\frac{\\partial E }{\\partial w_1} \\\\\n&\\vdots  \\\\\nw_n \\leftarrow & w_n - \\eta \\cdot \\frac{\\partial E }{\\partial w_n} \\\\\n\\end{aligned}\n\\] Her er \\(\\eta\\) igen en learning rate f.eks. \\(0.05\\), som sørger for, at vi hele tiden bare tager et lille skridt i den negative gradients retning. Man vælger værdien af \\(\\eta\\) lille for ikke at lave alt for store justeringer af vægtene ad gangen. Det svarer grafisk til, at vi lige så stille går ned af den bakke, som tabsfunktionen giver (se figur 9). Hvis vi tager for store skridt, risikerer vi helt, at komme til at “træde forbi” det minimum, som vi gerne vil lande i. Omvendt vil alt for små skridt føre til, at vi alt for langsomt nærmer os minimum. Så værdien af \\(\\eta\\) angiver altså, hvor meget vi er villige til at justere vægtene og dermed hvor hurtige eller hvor langsomme, vi bevæger os ned mod minimum. Af den grund giver det god mening, at \\(\\eta\\) kaldes for en learning rate - fordi den afgører, hvor hurtigt vi lærer af vores træningsdata.\nNu mangler vi bare at få bestemt de partielle afledede. Ved at bruge sumreglen og kædereglen for differentiation får vi fra (3), at \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_i} &= \\frac{1}{2} \\sum_{m=1}^{M} \\frac{\\partial}{\\partial w_i}\\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)^2 \\\\\n&= \\frac{1}{2} \\sum_{m=1}^{M} 2 \\cdot \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\\\ & \\quad  \\quad \\quad  \\quad \\quad  \\quad \\cdot \\frac{\\partial}{\\partial w_i} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n} ) \\right) \\\\\n&= \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\cdot \\left (-x_{m,i} \\right)\n\\end{aligned}\n\\] for \\(i \\in \\{1, 2, \\dots, n\\}\\).\nLæg mærke til at når vi differentierer den indre funktion \\[\n\\begin{aligned}\nt_m-(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n})\n\\end{aligned}\n\\] med hensyn til \\(w_i\\), så vil alle led være at betragte som konstanter bortset fra leddet \\[\n\\begin{aligned}\n-w_i \\cdot x_{m,i}\n\\end{aligned}\n\\] og når vi differentierer dette led med hensyn til \\(w_i\\) får vi netop \\(- x_{m,i}\\). Læg også mærke til at hvis vi differentierer med hensyn til \\(w_0\\), så får vi, \\[\n\\begin{aligned}\n\\frac{\\partial E}{\\partial w_0} = \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\cdot \\left (-1 \\right).\n\\end{aligned}\n\\] Altså bliver vores opdateringsregler \\[\n\\begin{aligned}\nw_0 \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right)  \\\\\nw_1 \\leftarrow & w_1 + \\eta \\cdot  \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\cdot \\left (x_{m,1} \\right)\\\\\n&\\vdots  \\\\\nw_n \\leftarrow & w_n + \\eta \\cdot  \\sum_{m=1}^{M} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\cdot \\left (x_{m,n} \\right)\\\\\n\\end{aligned}\n\\] Vi kan altså sammenfatte gradientnedstigningsalgoritmen på denne måde:\n\nSæt alle vægte \\(w_0, w_1, \\dots, w_n\\) til et tilfældigt tal (f.eks. \\(0.5\\)).\nVælg en værdi af \\(\\eta\\) (f.eks. \\(0.05\\)).\nUdregn på baggrund af alle træningsdata fejlene: \\[\n\\begin{aligned}\nerror_0 &= \\sum_{m=1}^{M} \\left (t_m-(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\right) \\\\\nerror_1 &= \\sum_{m=1}^{M} \\left (t_m-(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\cdot x_{m,1} \\right) \\\\\n&\\vdots \\\\\nerror_n &= \\sum_{m=1}^{M} \\left (t_m-(w_0 + w_1 \\cdot x_{m,1} + \\cdots + w_n \\cdot x_{m,n}) \\cdot x_{m,n} \\right)\n\\end{aligned}\n\\]\nOpdatér alle vægtene: \\[\n\\begin{aligned}\nw_0  \\leftarrow & w_0 + \\eta \\cdot error_0 \\\\\nw_1  \\leftarrow & w_1 + \\eta \\cdot error_1 \\\\\n& \\vdots \\\\\nw_n  \\leftarrow & w_n + \\eta \\cdot error_n\n\\end{aligned}\n\\]\nStart forfra indtil værdien af tabsfunktionen ikke ændrer sig (særlig meget)."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#eksempel-på-gradientnedstigning",
    "href": "materialer/perceptron/perceptron.html#eksempel-på-gradientnedstigning",
    "title": "Perceptroner",
    "section": "Eksempel på gradientnedstigning",
    "text": "Eksempel på gradientnedstigning\nLad os prøve at bruge gradientnedstigning på vores eksempel omkring kandidattest. I dette simple eksempel bliver vores opdateringsregler nu \\[\n\\begin{aligned}\nw_0 \\leftarrow & w_0 + \\eta \\cdot \\sum_{m=1}^{6} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + w_2 \\cdot x_{m,2}) \\right)  \\\\\nw_1 \\leftarrow & w_1 + \\eta \\cdot  \\sum_{m=1}^{6} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1} + w_2 \\cdot x_{m,2}) \\right) \\cdot \\left (x_{m,1} \\right)\\\\\nw_2 \\leftarrow & w_2 + \\eta \\cdot  \\sum_{m=1}^{6} \\left (t_m-\n(w_0 + w_1 \\cdot x_{m,1}  + w_2 \\cdot x_{m,2}) \\right) \\cdot \\left (x_{m,2} \\right)\n\\end{aligned}\n\\] Hvis man bruger disse opdateringsregler på dataene fra tabel 1, så ender man med følgende værdier af vægtene \\[\n\\begin{aligned}\nw_0 =-0.0769 , w_1=0.6410, w_2=-0.0598\n\\end{aligned}\n\\] hvor vi startede med værdierne \\(w_0=0.5, w_1=0.5\\), \\(w_2=0.5\\) og \\(\\eta=0.05\\). Perceptronen kan trænes ved hjælp af denne app (sæt stop-kriteriet til \\(0\\), maksimalt antal iterationer til \\(200\\) og vælg identitet som aktiveringsfunktion).\nDette svarer til linjen med ligning \\[\n\\begin{aligned}\n-0.0769 + 0.6410 \\cdot x_1 - 0.0598 \\cdot x_2 = 0.\n\\end{aligned}\n\\] Linjen er indtegnet sammen med træningsdata i figur 10.\n\n\n\n\n\n\n\n\nFigur 10: Ilustration af svaret på spørgsmål 1 (\\(1.\\) aksen) og spørgsmål 2 (\\(2.\\) aksen) med en markering af om man vil stemme på rød eller blok blå. Her er den linje indtegnet, som stammer fra gradientnedstigningsalgoritmen (med startværdier \\(w_0=0.5, w_1=0.5, w_2=0.5\\) og \\(\\eta=0.05\\)).\n\n\n\n\n\nBemærk, at til forskel fra perceptron learning algoritmen så ender man med de samme værdier af vægtene, selvom man vælger andre startværdier. Det er fordi, vi finder et globalt minimum for tabsfunktionen, som er uafhængig af det punkt, hvor vi starter med at lede. Det svarer til, at ligegyldigt hvor du bliver placeret i landskabet i figur 9, så vil du til sidst ende i dalen, hvis du hele tiden går små skridt i den negative gradients retning.\n\nEksempel 3 Vi ser igen på eksempel 1 og eksempel 2, hvor \\(x_1=0\\) og \\(x_2=1\\). Baseret på vægtene fra gradientnedstigning, får vi: \\[\n\\begin{aligned}\n-0.0769+0.6410 \\cdot x_1 &-0.0598 \\cdot x_2= \\\\&-0.0769+0.6410 \\cdot 0 -0.0598 \\cdot 1=-0.1367\n\\end{aligned}\n\\] Da denne værdi er mindre end \\(0\\), sætter vi \\(o=-1\\). Altså er vi tilbage til at anbefale vælgeren at stemme på rød blok."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#forskel-på-perceptron-learning-og-gradientnedstigning",
    "href": "materialer/perceptron/perceptron.html#forskel-på-perceptron-learning-og-gradientnedstigning",
    "title": "Perceptroner",
    "section": "Forskel på perceptron learning og gradientnedstigning",
    "text": "Forskel på perceptron learning og gradientnedstigning\nDer er flere forskelle på perceptron learning algoritmen og gradientnedstigning. Vi har allerede været inde på, at perceptron learning algoritmen går i kuk, hvis data ikke er lineært separable, som i figur 8. Mere formelt vil perceptron learning algoritmen ikke konvergere. I det tilfælde vil gradientnedstigning alligevel komme med et bud på værdier af vægtene, som kan bruges til at kategorisere træningsdata, selvom alle træningsdata ikke vil blive klassificeret korrekt (fordi de netop ikke er lineært separable). En anden forskel ligger i hvornår vægtene opdateres. I perceptron learning algoritmen opdateres vægtene efter hvert træningseksempel. I gradientnedstigning bruger man alle træningsdata for at lave en enkelt opdatering af vægtene. Hvis man har mange træningsdata, kan det godt blive lidt tungt. Så kan man i stedet for vælge at bruge et mindre, tilfældigt udvalg af data (for eksempel \\(10\\%\\)) til hver opdatering og så til næste opdatering bruge et nyt tilfældigt udvalg af data. Denne fremgangsmåde kaldes for stokastisk gradientnedstigning. En anden mulighed er at lave online gradientnedstigning, hvor man opdaterer vægtene for hvert træningseksempel, som i perceptron learning algoritmen. Selvom det kun er en tilnærmelse til rigtig gradientnedstigning, så har det alligevel en række fordele: 1) Det er meget hurtigere at opdatere vægtene. 2) I nogle anvendelser vil man have brug for løbende at opdatere vægtene på baggrund af nye træningsdata. I stedet for at gemme alle de mange træningsdata kan man bare opdatere vægtene, hver gang man får et nyt træningseksempel til rådighed og så eventuelt slette træningseksemplet igen, når vægtene er blevet opdateret. Det er både hurtigere og mere pladsbesparende."
  },
  {
    "objectID": "materialer/perceptron/perceptron.html#video-adaline",
    "href": "materialer/perceptron/perceptron.html#video-adaline",
    "title": "Perceptroner",
    "section": "VIDEO: ADALINE",
    "text": "VIDEO: ADALINE\nI denne video forklarer vi, hvad gradientnedstigning går ud på, og hvordan gradientnedstigning bruges til at opdatere vægtene i ADALINE."
  },
  {
    "objectID": "materialer/gradientnedstigning/bevis_geometrisk_argument.html",
    "href": "materialer/gradientnedstigning/bevis_geometrisk_argument.html",
    "title": "Geometrisk argument for at de retningsafledede kan udregnes med et prikprodukt",
    "section": "",
    "text": "Her på siden vil vi give et geometrisk argument for, at de retningsafledede kan skrives som et prikprodukt:\n\\[\nD_{\\vec{u}}f\\left( x_{0},y_{0} \\right) = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\] Vi antager her, at alle snitfunktioner er differentiable således, at alle de retningsafledede eksisterer.\nAlle planer gennem \\(P(x_0,y_0,f(x_0,y_0))\\), som er parallelle med \\(z\\)-aksen, har retningsvektorer \\[\\vec k =\n\\begin{pmatrix}\n0 \\\\\n0 \\\\\n1 \\\\\n\\end{pmatrix}\n\\qquad \\textrm{og} \\qquad \\vec u =\n\\begin{pmatrix}\nu_1 \\\\\nu_2 \\\\\n0 \\\\\n\\end{pmatrix}\\]\nDette er illustreret i figur 1, hvor man ved at trække i skyderen kan ændre på den retning, \\(\\vec u\\) peger i.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 1: Plan parallel med \\(z\\)-aksen med retningsvektor \\(\\vec k\\) og \\(\\vec u\\).\n\n\n\nDet er disse planer, vi snitter grafen for \\(f\\) med. Et eksempel er vist i figur 2. Ved at trække i skyderen kan man igen ændre på planen, som er parallel med \\(z\\)-aksen.\n\n\n\n\n\n\n\n\nFigur 2: Grafen for en funktion \\(f\\) (grøn) sammen med en plan gennem \\(P(x_0,y_0,f(x_0,y_0))\\) som er parallelle med \\(z\\)-aksen (blå). Snitkurven mellem grafen og planen er markeret med sort.\n\n\n\nHældningen for tangenten til snitkurven svarer netop til den retningsafledede \\(D_{\\vec{u}}f ( x_{0},y_{0} )\\). Vi sørger nu for at vælge \\(\\vec u\\), så denne vektor har længde \\(1\\). Så har snitkurven i \\(P\\) tangentvektor\n\\[\n\\begin{pmatrix}\nu_1 \\\\\nu_2 \\\\\nD_{\\vec{u}}f ( x_{0},y_{0} ) \\\\\n\\end{pmatrix}.\n\\]\nNu er det sådan at hvis tangenterne til alle snitkurverne ligger i en plan, så kaldes denne plan for tangentplanen. Et eksempel herpå ses i figur 3. Her er det tydeligt, at de indtegnede tangenter alle ligger i den samme plan.\n\n\n\n\n\n\n\n\nFigur 3: Grafen for en funktion \\(f\\) (grøn) sammen med forskellige tangenter til snitkurverne i et punkt \\(P(x_0,y_0,f(x_0,y_0))\\). Den plan, som alle disse tangenter ligger i, kaldes for tangentplanen og er indtegnet med blå.\n\n\n\nDenne plan har retningsvektorer \\[\n\\begin{pmatrix}\n1 \\\\\n0 \\\\\nf_x(x_0,y_0) \\\\\n\\end{pmatrix}\n\\qquad \\textrm{og} \\qquad\n\\begin{pmatrix}\n0 \\\\\n1 \\\\\nf_y(x_0,y_0) \\\\\n\\end{pmatrix}\\]\nog normalvektoren til planen bliver derfor\n\\[\n\\vec{n} =\n\\begin{pmatrix}\n1 \\\\ 0 \\\\ f_x(x_0,y_0)\n\\end{pmatrix}\n\\times\n\\begin{pmatrix}\n0 \\\\ 1 \\\\ f_y(x_0,y_0)\n\\end{pmatrix}\n\\]\nDet giver\n\\[\n\\begin{aligned}\n\\vec{n}&=\n\\begin{pmatrix}\n0 \\cdot f_y(x_0,y_0) - f_x(x_0,y_0) \\cdot 1\n\\\\\nf_x(x_0,y_0) \\cdot 0 - 1 \\cdot f_y(x_0,y_0)\n\\\\\n1 \\cdot 1 - 0 \\cdot 0\n\\end{pmatrix} =\n\\begin{pmatrix}\n- f_x(x_0,y_0)\n\\\\\n-f_y(x_0,y_0)\n\\\\\n1\n\\end{pmatrix}\n\\end{aligned}\n\\] Vi så tidligere, at tangenten til snitkurven i \\(P\\) har retningsvektor \\[\n\\vec{r}=\n\\begin{pmatrix}\nu_1 \\\\ u_2 \\\\ D_{\\vec{u}}f ( x_{0},y_{0} ).\n\\end{pmatrix}\n\\]\nDenne retningsvektor ligger per definition i tangentplanen og derfor står den vinkelret på enhver normalvektor. Derfor er\n\\[\n\\vec r \\cdot \\vec n = 0.\n\\]\nDet giver \\[\n\\begin{aligned}\n\\vec r \\cdot \\vec n &= \\begin{pmatrix}\nu_1 \\\\ u_2 \\\\ D_{\\vec{u}}f ( x_{0},y_{0} ).\n\\end{pmatrix}\n\\cdot\n\\begin{pmatrix}\n- f_x(x_0,y_0)\n\\\\\n-f_y(x_0,y_0)\n\\\\\n1\n\\end{pmatrix} \\\\\n&= - f_x(x_0,y_0) \\cdot u_1 -f_y(x_0,y_0) \\cdot u_2+D_{\\vec{u}}f ( x_{0},y_{0} )=0.\n\\end{aligned}\n\\]\nDerfor fås \\[\nD_{\\vec{u}}f ( x_{0},y_{0} ) = f_x(x_0,y_0) \\cdot u_1 +f_y(x_0,y_0) \\cdot u_2 = \\nabla f(x_{0},y_{0}) \\cdot \\vec{u}\n\\] Nu har vi så, fra dette geometriske argument, at den retningsafledte i retning \\(\\vec u\\) fås som skalarproduktet mellem gradienten og \\(\\vec u\\), hvilket netop var det, vi gerne ville vise."
  },
  {
    "objectID": "materialer/gradientnedstigning/kontinuitet.html",
    "href": "materialer/gradientnedstigning/kontinuitet.html",
    "title": "Kontinuitet for funktioner af to variable",
    "section": "",
    "text": "Vi har lige påstået, at en funktion \\(f\\) af to variable siges at være kontinuert i \\((x_0,y_0)\\), hvis følgende gælder\n\\[\n\\lim_{(x,y) \\rightarrow (x_{0},y_{0})}{f\\left( x,y \\right) = f(x_{0},y_{0})}\n\\]\nMen der er faktisk grund til at dvæle lidt ved denne definition, for hvad vil det overhovedet sige, at \\((x,y) \\rightarrow (x_{0},y_{0})\\)? Forestil dig at du har været i byen, og at \\((x_0,y_0)\\) er dit hjem. Så kan man jo gå hjem på rigtig mange måder. Det kan være, at man går langs en ret linje, det kan være, at man går i zig-zag hjem eller noget helt tredje. Ovenstående definition på kontinuitet giver kun mening, hvis \\(f(x,y)\\) nærmer sig \\(f(x_0,y_0)\\) uanset på hvilken måde \\((x,y)\\) nærmer sig \\((x_0,y_0)\\).\nVi skal nu se på et eksempel, hvor en funktion \\(f\\) ikke er kontinuert i \\((0,0)\\), fordi man kan “gå hjem” på nogle måder, så \\(f(x,y)\\) ikke altid nærmer sig \\(f(0,0)\\)! Det kan godt være lidt svært at forestille sig, men her kommer eksemplet."
  },
  {
    "objectID": "materialer/gradientnedstigning/kontinuitet.html#skiferien",
    "href": "materialer/gradientnedstigning/kontinuitet.html#skiferien",
    "title": "Kontinuitet for funktioner af to variable",
    "section": "Skiferien",
    "text": "Skiferien\nVi forestiller os, at grafen for funktionen \\(f(x,y)\\) beskriver et landskab. Står vi på en flad mark er \\(f(x,y)\\) bare \\(0\\) for alle værdier af \\((x,y)\\), og det er jo ærlig talt lidt kedeligt. Men nu er din klasse taget på skiferie i et spændende land, hvor skibakkerne kan beskrives som grafen for funktionen \\(f\\) med følgende forskrift:\n\\[\nf(x,y)=\n\\begin{cases}\n\\frac{y \\cdot x^2}{y^2+x^4} \\quad \\textrm{hvis } (x,y) \\neq (0,0) \\\\\n0 \\quad \\textrm{hvis } (x,y) = (0,0)\n\\end{cases}\n\\] Jeres hotel ligger i origo – det vil sige i punktet \\((0,0,0)\\). I kan se skibakken i app’en herunder.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nI skal nu i gang med at undersøge, om denne funktion er kontinuert i \\((0,0)\\). I gør det ved at stille jer forskellige steder på skibakken og gå af forskellige ruter hjem. De fleste af jer går langs rette linjer (i \\(xy\\)-planen) og rapporterer, at funktionen er kontinuert (og faktisk også differentiabel) i \\((0,0)\\). I kan se nogle af de forskellige ruter herunder:\n\n\n\nNu er der et par elever, der rapporterer, at de kom vandrende ind mod origo på grafen og hele tiden var i højde \\(1/2\\) lige indtil, de faldt i et hul, da de nåede origo. Hvis det er rigtigt betyder det, at funktionen ikke er kontinuert i origo. De elever, der faldt i et hul, er kendt for ikke at gå den lige vej hjem. Denne gang afslører de, at de gik på grafen, mens de i \\(xy\\)-planen fulgte parablen med ligning \\(y=x^2\\). Du kan se disse elevers rute i app’en herunder.\n\n\n\nMen kan alle eleverne mon have ret? Vi prøver at regne på det.\n\n\n\n\n\n\nOpgave 1: Gå langs \\(y=x\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs linjen med ligning \\(y=x\\). Det vil sige bestem \\(f(x,x)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\n\n\n\n\n\n\nOpgave 2: Gå langs \\(y=ax\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs linjen med ligning \\(y=ax\\). Det vil sige bestem \\(f(x,ax)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\n\n\n\n\n\n\nOpgave 3: Gå langs \\(y\\)-aksen\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs \\(y\\)-aksen.\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\nI de tre foregående opgaver skulle du gerne komme frem til at \\(f(x,y) \\rightarrow f(0,0)=0\\), når \\((x,y) \\rightarrow (0,0)\\), så længe vi går langs rette linjer. Vi skal nu undersøge, hvad der sker, hvis vi går langs parabler.\n\n\n\n\n\n\nOpgave 4: Gå langs parablen med ligning \\(y=x^2\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs parablen med ligning \\(y=x^2\\). Det vil sige bestem \\(f(x,x^2)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\nHvis du har regnet rigtigt i ovenstående opgave, så har du fået, at\n\\[\n\\lim_{(x,y) \\rightarrow (0,0)}{f\\left( x,y \\right)} = 1/2\n\\]\nnår \\((x,y) \\rightarrow (0,0)\\) langs parablen med ligning \\(y=x^2\\). Da \\(f(0,0)=0\\) har vi altså fundet en måde at nærme os \\((0,0)\\) så\n\\[\n\\lim_{(x,y) \\rightarrow (0,0)}{f\\left( x,y \\right) \\neq f(0,0)}\n\\]\nog derfor er \\(f\\) ikke kontinuert i \\((0,0)\\), selvom det i første omgang så sådan ud (da vi gik langs rette linjer)!\nFor sjov skyld kan vi jo prøve at undersøge, om det gælder langs alle parabler.\n\n\n\n\n\n\nOpgave 5: Gå langs parablen med ligning \\(y=ax^2\\)\n\n\n\n\n\n\nFind forskriften for snitfunktionen langs parablen med ligning \\(y=ax^2\\), hvor \\(a \\neq 0\\). Det vil sige bestem \\(f(x,ax^2)\\).\nHvilken værdi går denne snitfunktion imod, når \\(x\\) går mod \\(0\\)?\n\n\n\n\nHvis du har regnes rigtig i ovenstående, har du fået, at \\[\n\\lim_{(x,y) \\rightarrow (0,0)}{f\\left( x,y \\right)} = \\frac{a}{a^2+1} \\neq 0\n\\] når \\(a \\neq 0\\). Igen har vi altså set, at\\(f\\) ikke kontinuert i \\((0,0)\\)."
  },
  {
    "objectID": "materialer/afstande/index_afstande.html",
    "href": "materialer/afstande/index_afstande.html",
    "title": "Afstande og feature-skalering",
    "section": "",
    "text": "Det er ikke altid helt klart, hvordan man skal bestemme afstanden mellem to datapunkter, hvis koordinaterne i hvert datapunkter beskriver vidt forskellige ting. Det er faktisk ikke en gang entydigt, hvad man overhovedet skal forstå ved en afstand – eller det som man i matematik vil kalde for en metrik. Her på siden behandler vi nogle af disse problemstillinger. Vi vil se nærmere på, hvilke problemer, der kan opstå, hvis man ikke tænker sig om – og hvad man kan gøre for at løse dem.\nLæs mere i noterne herunder.\n\n\n\n\n\n\n\n\n\n\nFeature-skalering\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstande mellem punkter i planen\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstande mellem ord\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAfstand mellem DNA- og RNA-strenge\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDefinition af en metrik – det abstrakte afstandsbegreb\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html",
    "href": "materialer/afstande/feature_scaling.html",
    "title": "Feature-skalering",
    "section": "",
    "text": "Hvis de data, man arbejder med, måler vidt forskellige ting – måske endda på vidt forskellige skalaer – så vil man som oftest have brug for at \"justere\" data, så de er på samme skala."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#afstand-med-hovedet-under-armen",
    "href": "materialer/afstande/feature_scaling.html#afstand-med-hovedet-under-armen",
    "title": "Feature-skalering",
    "section": "Afstand med hovedet under armen",
    "text": "Afstand med hovedet under armen\nDet er ikke altid helt klart, hvordan man skal bestemme afstanden mellem to datapunkter, hvis koordinaterne i hvert datapunkter beskriver vidt forskellige ting. Vi vil her se nærmere på, hvilke problemer, der kan opstå, hvis man ikke tænker sig om – og hvad man kan gøre for at løse dem.\nLad os forestille os, at data består af vægt og højde for nogle personer, så hvert datapunkt er på formen \\[(v,h)\\] hvor \\(v\\) er den pågældende persons vægt og \\(h\\) er højden. Her er det faktisk ikke klart, hvad afstanden mellem to punkter \\((v_1,h_1)\\) og \\((v_2,h_2)\\) skal være. Altså, hvornår to punkter ligger tæt på hinanden.\nEt første bud kunne være at bestemme den euklidiske afstand mellem de to punkter – det der bare svarer til at bruge Pythagoras. Gør vi det får vi følgende afstandsmål mellem punkterne \\((v_1,h_1)\\) og \\((v_2,h_2)\\):\n\\[\\sqrt{(v_2-v_1)^2+(h_2-h_1)^2}\\]\nVi prøver at regne lidt på det, og forestiller os, at tre personer er givet som datapunkter i nedenstående tabel.\n\n\n\nPerson\n(vægt, højde)\n\n\n\n\nA\n\\((70 \\ kg, 165 \\ cm)\\)\n\n\nB\n\\((90 \\ kg, 180 \\ cm)\\)\n\n\nC\n\\((80 \\ kg, 190 \\ cm)\\)\n\n\n\nBruger vi Pythagoras på tallene, der står her, er:\n\\[\\begin{align*}\n&\\text{Afstanden mellem A og B: } \\sqrt{20^2+15^2}=25 \\\\\n&\\text{Afstanden mellem A og C: } \\sqrt{10^2+25^2}\\simeq 27 \\\\\n&\\text{Afstanden mellem B og C: } \\sqrt{10^2+10^2}\\simeq 14\n\\end{align*}\\]\nMed dette afstandsmål er der altså længst fra \\(A\\) til \\(C\\).\nSkifter vi nu enhed og udtrykker højden i meter får vi følgende datapunkter:\n\n\n\nPerson\n(vægt, højde)\n\n\n\n\nA\n\\((70 \\ kg, 1.65 \\ m)\\)\n\n\nB\n\\((90 \\ kg, 1.80 \\ m)\\)\n\n\nC\n\\((80 \\ kg, 1.90 \\ m)\\)\n\n\n\nNu er\n\\[\\begin{align*}\n&\\text{Afstanden mellem A og B: } \\sqrt{20^2+0.15^2} \\simeq 20 \\\\\n&\\text{Afstanden mellem A og C: } \\sqrt{10^2+0.25^2} \\simeq 10 \\\\\n&\\text{Afstanden mellem B og C: } \\sqrt{10^2+0.10^2} \\simeq 10\n\\end{align*}\\]\nDer er nu længst fra \\(A\\) til \\(B\\).\nDet er ikke ret smart. Skal man finde de datapunkter, som ligger tættest på hinanden, er svaret tilsyneladende som vinden blæser og afhængig af hvilken enhed, vi har valgt at måle i.\nMen selv hvis begge variable er i samme enhed, kan Pythagoras brugt med hovedet under armen være uheldigt, som nedenstående eksempel illustrerer.\nVi forestiller os, at vi har data for, hvor meget familierne \\(A\\), \\(B\\) og \\(C\\) bruger på bolig og på mælk om måneden. Begge variable kan være i kroner. I tabellen ses et eksempel:\n\n\n\nFamilie\n(bolig, mælk)\n\n\n\n\nA\n\\((7500 \\ kr, 200 \\ kr)\\)\n\n\nB\n\\((7500 \\ kr, 1700 \\ kr)\\)\n\n\nC\n\\((6000 \\ kr, 200 \\ kr)\\)\n\n\n\nDet vil altså for eksempel sige, at familie \\(A\\) bruger \\(7500\\) kr på bolig og \\(200\\) kr på mælk. Her er afstanden udregnet med Pythagoras:\n\\[\\begin{align*}\n&\\text{Afstanden mellem A og B: } \\sqrt{0^2+1500^2} = 1500 \\\\\n&\\text{Afstanden mellem A og C: } \\sqrt{1500^2+0^2} = 1500 \\\\\n&\\text{Afstanden mellem B og C: } \\sqrt{1500^2+1500^2} \\simeq 2121\n\\end{align*}\\]\nAltså er der samme afstand fra \\(A\\) til \\(B\\) som fra \\(A\\) til \\(C\\), men vi vil nok mene, at \\(B\\) afviger mere fra \\(A\\) end \\(C\\) gør, fordi mælkeforbruget i familie \\(B\\) er usædvanligt.\nHar vi data for mange familier, kan vi kvantificere idéen om, hvad der er usædvanligt og bruge det til at lave en mere passende afstand."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#første-naive-tilgang-min-max-skalering",
    "href": "materialer/afstande/feature_scaling.html#første-naive-tilgang-min-max-skalering",
    "title": "Feature-skalering",
    "section": "Første naive tilgang: Min-Max skalering",
    "text": "Første naive tilgang: Min-Max skalering\nEksemplet ovenfor illustrerer, at det nok vil være smart at prøve at inddrage i hvilket interval \\(x\\)- og \\(y\\)-værdierne varierer. For eksempel er et udsving på \\(500\\) kr i boligudgifter ikke lige så voldsomt, som et udsving på \\(500\\) kr i mælkeudgifter. Problemet er, at den absolutte forskel på henholdsvis \\(x\\)- og \\(y\\)-værdierne ikke er sammenlignelige her.\nLad os sige, at vi betragter datapunkter \\((x_i,y_i)\\) i planen, hvor \\(x\\)-værdierne ligger mellem \\(a\\) og \\(b\\), mens \\(y\\)-værdierne ligger mellem \\(c\\) og \\(d\\). Situationen er illustreret i figur 1.\n\n\n\n\n\n\nFigur 1: Datapunkter i planen, hvor \\(x\\)-værdierne ligger mellem \\(a\\) og \\(b\\), mens \\(y\\)-værdierne ligger mellem \\(c\\) og \\(d\\).\n\n\n\nIdéen er nu, at vi skalerer, så afstandene langs \\(x\\)-aksen får samme vægt som afstandene langs \\(y\\)-aksen.\nDet vil sige, at vi definerer afstanden fra \\((x_1,y_1)\\) til \\((x_2,y_2)\\) som\n\\[\\sqrt{\\left ( \\frac{x_2-x_1}{b-a} \\right )^2+ \\left ( \\frac{y_2-y_1}{d-c} \\right )^2} \\tag{1}\\]\nDet får den betydning, at hvis \\(x\\)-værdierne f.eks. kan varierer i et langt bredere interval end \\(y\\)-værdierne (dvs. at \\(b-a&gt;d-c\\)), så bliver forskellen på \\(x\\)-værdierne i ovenstående afstandsmål skaleret mere ned (fordi vi kommer til at dividere med et større tal).\nEn anden måde at forstå dette afstandsmål på, er ved at erstatte hvert punkt \\((x_i,y_i)\\) med et nyt skaleret punkt:\n\\[(x_i,y_i)_{Norm}=\\left(\\frac{x_i-a}{b-a}, \\frac{y_i-c}{d-c}\\right) \\tag{2}\\]\nResultatet af at lave denne skalering af punkterne fra figur 1 ses i figur 2.\n\n\n\n\n\n\nFigur 2: Datapunkterne fra figur 1, men hvor alle punkter er blevet min-max skaleret ved at bruge formlen i (2).\n\n\n\nBemærk, at datapunkterne nu er skaleret på en sådan måde, at alle \\(x\\)- og \\(y\\)-værdier ligger mellem \\(0\\) og \\(1\\). Derfor giver det mening, at bruge Pythagoras på disse skalerede punkter – og gør vi det, får vi\n\\[\\sqrt{\\left(\\frac{x_2-a}{b-a}-\\frac{x_1-a}{b-a}\\right)^2 +\\left(\\frac{y_2-c}{d-c}-\\frac{y_1-c}{d-c}\\right)^2}=\\sqrt{\\left(\\frac{x_2-x_1}{b-a}\\right)^2+\\left(\\frac{y_2-y_1}{d-c}\\right)^2}\\]\nBemærk, at det præcis er afstandsmålet i (1), som vi startede ud med."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#mindre-naivt-mere-bøvlet-feature-skaling",
    "href": "materialer/afstande/feature_scaling.html#mindre-naivt-mere-bøvlet-feature-skaling",
    "title": "Feature-skalering",
    "section": "Mindre naivt, mere bøvlet: Feature-skaling",
    "text": "Mindre naivt, mere bøvlet: Feature-skaling\nDen skalering vi har præsenteret i (2) benytter ikke som sådan information om data, men kun om den mindste og største værdi, som henholdsvis \\(x\\)- og \\(y\\)-værdierne ligger imellem (nemlig \\(a\\) og \\(b\\) for \\(x\\)-værdierne og \\(c\\) og \\(d\\) for \\(y\\)-værdierne).\nEt alternativ til dette er at bruge alle data til at bestemme skaleringen (og ikke kun den største og den mindste værdi). Dette kaldes for feature-skaling, når vi arbejder med perceptroner eller neurale netværk.\nHvis de data, der skal læres fra – det vil sige træningsdata – er \\[(x_1,y_1), (x_2,y_2),\\ldots, (x_n,y_n)\\] så skalerer vi langs førsteaksen ved, at\n\nudregne et estimat for middelværdien af \\(x\\): \\[\\bar{x}=\\frac{x_1 + x_2 + \\cdots + x_n}{n}=\\frac{\\Sigma_{i=1}^nx_i}{n} \\tag{3}\\]\nog et estimat for denne variabels spredning: \\[s_x=\\sqrt{\\frac{\\Sigma_{i=1}^n(x_i-\\bar{x})^2}{n-1}} \\tag{4}\\]\n\nFeature-skaling af \\(x_i\\) er da \\[\\hat{x}_i=\\frac{x_i-\\bar{x}}{s_x} \\tag{5}\\]\nTilsvarende estimeres middelværdi og spredning for \\(y\\) og feature-skaling udregnes: \\[\\hat{y}_i= \\frac{y_i-\\bar{y}}{s_y} \\tag{6}\\]\nResultatet af at lave denne feature skalering af punkterne fra figur 1 ses i figur 3.\n\n\n\n\n\n\nFigur 3: Datapunkterne fra figur 1, men hvor alle punkter er blevet feature skaleret ved at bruge formlerne i (5) og (6).\n\n\n\nBemærk, hvordan de feature skalerede datapunkter har \\(x\\)- og \\(y\\)-værdier, som alle1 ligger mellem \\(-2\\) og \\(2\\).\n1 I virkelighedens verden kan der godt være værdier, som er mindre end \\(-2\\) eller større end \\(2\\), men som oftest vil det være sådan, at omkring \\(95 \\%\\) af værdierne vil ligge mellem \\(-2\\) og \\(2\\) efter feature skalering.Da alle \\(x\\)- og \\(y\\)-værdier nu er på samme skala, giver det igen mening at beregne den euklidiske afstand mellem disse nye punkter. Betragter vi de skalerede punkter \\((\\hat{x}_1,\\hat{y}_1)\\) og \\((\\hat{x}_2,\\hat{y}_2)\\) så bliver den euklidiske afstand mellem dem\n\\[\\begin{align*}\n\\sqrt{(\\hat{x}_2-\\hat{x}_1)^2+(\\hat{y}_2-\\hat{y}_1)^2} &= \\sqrt{\\left(\\frac{x_2-\\bar{x}}{s_x}-\\frac{x_1-\\bar{x}}{s_x}\\right)^2 +\\left(\\frac{y_2-\\bar{y}}{s_y}-\\frac{y_1-\\bar{y}}{s_y}\\right)^2}\\\\\n& =\\sqrt{\\left(\\frac{x_2-x_1}{s_x}\\right)^2+\\left(\\frac{y_2-y_1}{s_y}\\right)^2}\n\\end{align*}\\]\nHvis vi sammenligner med den naive tilgang i (1), er den ikke helt skæv. Der skal bare skaleres med \\(s_x\\) i stedet for \\(b-a\\) og med \\(s_y\\) i stedet for \\(c-d\\).\nBemærk, at den feature skalering, som foretages i (5) og (6), svarer til at standardisere en normalfordelt stokastisk variabel \\(X \\sim N(\\mu, \\sigma)\\):\n\\[ Z = \\frac{X-\\mu}{\\sigma}\\] Derfor vil det også være sådan, at hvis de oprindelige data er normalfordelte, så vil de nye feature skalerede data være standard normalfordelte (dvs. normalfordelte med middelværdi \\(0\\) og spredning \\(1\\)). Heraf følger også, at cirka \\(95 \\%\\) af de feature skalerede data vil ligge mellem \\(-2\\) og \\(2\\), som bemærket ovenfor."
  },
  {
    "objectID": "materialer/afstande/feature_scaling.html#eksempel-min-max-og-feature-skalering",
    "href": "materialer/afstande/feature_scaling.html#eksempel-min-max-og-feature-skalering",
    "title": "Feature-skalering",
    "section": "Eksempel: Min-max og feature skalering",
    "text": "Eksempel: Min-max og feature skalering\nVi vil prøve at se på et udvidet eksempel om udgifter til bolig og mælk. Se nedenstående tabel:\n\n\n\n\n\n\nFamilie\n(bolig, mælk)\n\n\n\n\nA\n\\((7500 \\ kr, 200 \\ kr)\\)\n\n\nB\n\\((7500 \\ kr, 1700 \\ kr)\\)\n\n\nC\n\\((6000 \\ kr, 200 \\ kr)\\)\n\n\nD\n\\((5200 \\ kr, 300 \\ kr)\\)\n\n\nE\n\\((8100 \\ kr, 250 \\ kr)\\)\n\n\nF\n\\((6200 \\ kr, 350  \\ kr)\\)\n\n\nG\n\\((7700 \\ kr, 400 \\ kr)\\)\n\n\nH\n\\((5800 \\ kr, 350 \\ kr)\\)\n\n\nI\n\\((7200 \\ kr, 250 \\ kr)\\)\n\n\nJ\n\\((6800 \\ kr, 400  \\ kr)\\)\n\n\n\n\n\nTabel 1: Udvidet eksempel om udgifter til bolig og mælk.\n\n\n\nDatapunkterne fra tabellen ses indtegnet i figur 4. De tre første familier \\(A\\), \\(B\\) og \\(C\\) fra det tidligere eksempel er markeret. Bemærk, at vi tidligere har beregnet, at afstanden mellem \\(A\\) og \\(B\\) er den samme som afstanden mellem \\(A\\) og \\(C\\), hvilket også fremgår af figur 4.\n\n\n\n\n\n\nFigur 4: Datapunkterne fra eksemplet i tabel 1 omkring udgifter til bolig og mælk.\n\n\n\nVi vil nu lave både min-max skalering samt feature skalering af punkterne i tabel 1. For at lave min-max skalering får vi brug for mindste- og størsteværdi for både \\(x\\)- (bolig) og \\(y\\)-værdierne (mælk). De er: \\[\\begin{align}\na&=5200 \\quad  &\\text{og} \\quad \\quad &b=8100 \\\\\nc&=200 \\quad  &\\text{og} \\quad \\quad &d=1700 \\\\\n\\end{align}\\] Bruges disse værdier samt formlerne i (2) fås punkterne som ses i figur 5.\n\n\n\n\n\n\nFigur 5: Datapunkterne fra eksemplet omkring udgifter til bolig og mælk efter min-max skalering.\n\n\n\nLæg mærke til hvordan afstanden mellem \\(A\\) og \\(C\\) med denne skalering er blevet mindre end afstanden mellem \\(A\\) og \\(B\\), som ønsket.\nVi vil nu prøve at lave en feature skalering af punkterne i tabel 1. Vi får derfor brug for et estimat for middelværdien af henholdvis \\(x\\) og \\(y\\). De kan beregnes ved hjælp af (3) til:\n\\[\\begin{align}\n\\bar{x} &= 6800 \\\\\n\\bar{y} &= 440\n\\end{align}\\]\nBruges (4) fås et estimat for spredningen for henholdsvis \\(x\\) og \\(y\\):\n\\[\\begin{align}\n\\bar{s_x} &= 954.52 \\\\\n\\bar{s_y} &= 448.95\n\\end{align}\\]\nAnvendes formlerne i (5) og (6) til feature skalering af punkterne i tabel 1 fås punkterne, som ses i figur 6.\n\n\n\n\n\n\nFigur 6: Datapunkterne fra eksemplet omkring udgifter til bolig og mælk efter feature skalering.\n\n\n\nLæg her mærke til at afstanden mellem \\(A\\) og \\(B\\) nu er blevet endnu større end afstanden mellem \\(A\\) og \\(C\\). Det ses også, at \\(y\\)-værdien for det skalerede punkt for familie \\(B\\) er cirka \\(2.8\\). Sammenlignes dette med standard normalfordelingen, kan vi se, at der er tale om en forholdsvis ekstrem værdi2. Det vil sige, at vi ud fra de skalerede værdier kan se, at familien \\(B\\)’s mælkeforbrug på \\(1700\\) kroner rent faktisk er usædvanligt sammenlignet med de andre families mælkeforbrug.\n\n\n2 Husk på at for en standard normalfordelt stokastisk variabel vil omkring \\(95 \\%\\) af værdierne ligge mellem \\(-2\\) og \\(2\\)."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemStrenge.html",
    "href": "materialer/afstande/AfstandeMellemStrenge.html",
    "title": "Afstande mellem ord",
    "section": "",
    "text": "Et ord er en følge eller en streng af bogstaver eller tal. Det kunne for eksempel være 12DvbdN34fdg eller hnaikgoh (nej, det behøver ikke give mening). Det kunne også være en DNA-sekvens, et ord i en tekst eller noget helt andet1. Man siger, at længden af en streng er antallet af bogstaver i strengen.\n1 Ofte gør man det desuden binært, så det er en streng af \\(0\\) og \\(1\\) såsom \\(00110110.\\) Det er fornuftigt nok, eftersom computere opererer med den slags strenge.Vi vil i det følgende se på såkaldte edit-afstande, som basalt set tæller, hvor mange ændringer, man skal lave, for at komme fra den ene streng til den anden. Det kommer naturligvis til at afhænge af, hvilke typer ændringer, man tillader. Lad os her se på nogle af dem.\n\nHammingafstanden\nHammingafstanden mellem to lige lange strenge er antallet af pladser, hvor de to strenge er forskellige. Afstanden fra sne til sno er derfor \\(1\\). Afstanden fra sne til neg er \\(3\\), fordi de to strenge er forskellige på alle pladser. Det svarer til, at man må ændre et bogstav ad gangen:\n\\[ sne \\rightarrow nne \\rightarrow nee \\rightarrow neg\\] Dette er illustreret i figur 1 ved de tre grønne kanter fra sne til neg.\n\n\n\n\n\n\nFigur 1: Hver knude i figuren svarer til et ord. En kant imellem to knuder svarer til, at der findes et \"move\" mellem de to ord enten ved hjælp af Hamming-, Levenshtein- eller Damerau-Levenshteinafstanden (angivet med henholdsvis grøn, lilla og pink).\n\n\n\n\n\nLevenshteinafstanden\nLevenshteinafstanden har flere tilladte ændringer: Man må ændre bogstaver, som i Hamming, men man må også indsætte og fjerne bogstaver. Levenshteinafstanden er det mindste antal sådanne ændringer, man skal lave for at nå fra det ene ord til det andet. Ordene/strengene behøver ikke have samme længde - man kan jo indsætte og fjerne bogstaver.\nSe på figur 1:\n\nAfstanden fra sne til see er \\(1\\), ligesom Hammingafstanden.\nAfstanden fra sne til sneg er også \\(1\\), fordi vi blot har tilføjet et g – og her er Hammingafstanden slet ikke meningsfuld. Den er simpelthen ikke defineret.\nAfstanden fra sne til neg er \\(2\\) – via disse ændringer:\n\\[sne \\rightarrow sneg \\rightarrow neg\\]\nHammingafstanden, som vi fandt ovenfor, er \\(3\\).\n\nBemærk, at vi i ovenstående eksempel også kunne have valgt\n\\[sne \\rightarrow ne \\rightarrow neg\\] som også har \\(2\\) \"moves\".\nJo flere tilladte ændringer, jo kortere afstand. Der er algoritmer, der finder den mindste vej mellem to ord – det er dog ikke helt så klart, hvordan man regner den ud, som det er for Hammingafstanden.\n\n\nDamerau-Levenshteinafstanden\nDamerau-Levenshteinafstanden er som Levenshtein, men man tillader nu også ombytning af to bogstaver, som står ved siden af hinanden. Hvis man skriver teskt på en telefon eller pc, er det let at bytte om på den måde. Hvis man så har en liste over ord, der giver mening, kan man opdage, at teskt ikke giver mening, men at ordet tekst ligger meget tæt på - afstand \\(1\\) i Damerau-Levenshteinafstand – og \\(2\\) i Hamming- eller Levenshteinafstand. Ordet teske har også Hammingafstand \\(1\\) til teskt, så man kan ikke være sikker på, hvad det oprindelige var.\nI figur 2 ses et eksempel på hvilke \"moves\", der er tilladt mellem forskellige ord ved hjælp af Hamming-, Levenshtein- eller Damerau-Levenshteinafstanden.\n\n\n\n\n\n\nFigur 2: Hver knude i figuren svarer til et ord. En kant imellem to knuder svarer til, at der findes et \"move\" mellem de to ord enten ved hjælp af Hamming-, Levenshtein- eller Damerau-Levenshteinafstanden (angivet med henholdsvis grøn, lilla og pink).\n\n\n\n\n\nAfstande mellem navne\nNavne som Peter, Pieter, Pietro, Petrus, Peder, Per, Pelle, Pekka, Peer, Petur, Pedro, Pierre, Pjotr, Pyotr, Petar eller måske Katarina, Katharina, Katrina, Katrine, Katrin, Cathryn, Kathryn, Catherine har samme oprindelse. Der er stor forskel på, hvor hyppigt, de optræder i forskellige lande. Overvej, om edit-afstandene ovenfor kan bruges til for eksempel at afsløre, hvor tæt på hinanden lande med Peter som hyppigst, er på lande med Pyotr."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html",
    "title": "Afstande mellem punkter i planen",
    "section": "",
    "text": "Du har ikke nødvendigvis tænkt over det før, men hvordan måler man egentlig afstanden mellem to punkter i planen? “Ja, man finder afstanden mellem dem”, vil du måske sige, men det er jo ikke rigtigt et brugbart svar på spørgsmålet. Den afstand, du tænker på, er formentlig længden af det linjestykke, som forbinder de to punkter, men der findes faktisk mange andre måder at definere afstanden på. Det vil vi give et par eksempler på her.\nFor at blive lidt mere præcis forestiller vi os, at vi har to punkter i planen, som vi kalder for \\(P(x_1,y_1)\\) og \\(Q(x_2,y_2)\\)."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-euklidisk_afstand",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-euklidisk_afstand",
    "title": "Afstande mellem punkter i planen",
    "section": "Euklidisk afstand",
    "text": "Euklidisk afstand\nDen euklidisk afstand mellem \\(P\\) og \\(Q\\) er \\[\\sqrt{(x_2-x_1)^2+(y_2-y_1)^2}\\] Det er det, vi kender mest – og som formentlig er den afstand, du lige har tænkt på. Formlen ovenfor fremkommer ved at bruge Pythagoras.\nI app’en herunder er den euklidiske afstand illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-manhattan_afstand",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#sec-manhattan_afstand",
    "title": "Afstande mellem punkter i planen",
    "section": "Manhattanafstanden",
    "text": "Manhattanafstanden\nManhattanafstanden er den afstand, man får, når man er tvunget til at bevæge sig langs akserne, som vi kender det fra vejene i mange amerikanske byer, herunder på Manhattan. Den kaldes også taxi-afstanden. Formlen for at bestemme Manhattanafstanden er: \\[|x_2-x_1|+|y_2-y_1|\\] I app’en herunder er Manhattanafstanden illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#max-afstanden",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#max-afstanden",
    "title": "Afstande mellem punkter i planen",
    "section": "Max-afstanden",
    "text": "Max-afstanden\nMax-afstanden er maksimum mellem den vandret og lodrette afstand mellem \\(P\\) og \\(Q\\). Det vil sige, maksimum af \\(|x_2-x_1|\\) og \\(|y_2-y_1|\\).\nDen kaldes også skak-konge afstanden. Kongen i skak kan gå diagonalt eller langs de to akser. Et diagonalt move fra \\((a,b)\\) til \\((a+k,b+k)\\) tænkes at have længde \\(k\\) – som i skak. Skal man fra eksempelvis \\(A(1,4)\\) til \\(B(3,7)\\) kan skakkongen gå fra \\(A(1,4)\\) til \\(C(3,6)\\) – det stykke har længde \\(2\\) og derefter fra \\(C(3,6)\\) til \\(B(3,7)\\) langs \\(y\\)-aksen - et stykke på længde \\(1\\). Samlet afstand er \\(3\\), maksimum af \\(|3-1|\\) og \\(|7-4|\\). Idéen er illustreret i figur 1.\n\n\n\n\n\n\nFigur 1: Kongen i skak skal fra \\(A\\) til \\(B\\) via \\(C.\\) Bemærk, at der også er andre veje fra \\(A\\) til \\(B\\) med afstand \\(3\\). For eksempel kan kongen gå fra \\(A(1,4)\\) til \\((1,5)\\) (det giver en afstand på \\(1\\)) og dernæst lave et diagonalt move fra \\((1,5)\\) til \\(B(3,7)\\) med en afstand på \\(2\\). Den samlede afstand bliver igen \\(1+2=3\\). Der er altså flere korteste veje fra \\(A\\) til \\(B\\).\n\n\n\nI app’en herunder er max-afstanden illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig."
  },
  {
    "objectID": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#posthusafstanden",
    "href": "materialer/afstande/AfstandeMellemPunkteriPlanen.html#posthusafstanden",
    "title": "Afstande mellem punkter i planen",
    "section": "Posthusafstanden",
    "text": "Posthusafstanden\nPosthusafstanden1 mellem \\(P\\) og \\(Q\\) finder man, ved at tænke på, at der ligger et posthus i origo \\(O(0,0)\\), og vi skal sende et brev fra \\(P\\) til \\(Q\\). Det bliver transporteret fra \\(P\\) til posthuset først og derefter fra posthuset til \\(Q\\). Hvis man anvender Pythagoras to gange, kan man se, at formlen for denne afstand er: \\[\\sqrt{x_1^2+y_1^2}+\\sqrt{x_2^2+y_2^2}\\] I app’en herunder er posthusafstanden illustreret. Du kan flytte rundt på punkterne og se, hvordan afstanden ændrer sig.\n1 Den hedder også British Rail afstanden eller, hvis man er fransk, SNCF (Société Nationale des Chemins de fer Français) -afstanden. Man tænker sig, at man altid skal rejse via London (eller Paris) for at komme med tog fra et sted til et andet."
  },
  {
    "objectID": "materialer/logistisk/data/figur_til_www.html",
    "href": "materialer/logistisk/data/figur_til_www.html",
    "title": "Figur til www",
    "section": "",
    "text": "## Data\ndatadir &lt;- here::here(\"materialer\", \"logistisk\", \"data\")\ndat_navn &lt;- file.path(datadir, \"blodtryk.xlsx\")\ndat &lt;- readxl::read_xlsx(dat_navn)\ndat &lt;- head(dat, n = 200)\nnames(dat) &lt;- c(\"x\", \"y\")\nfit &lt;- glm(y~x, family = binomial(), data = dat)\na_mle &lt;- coef(fit)[2]\nb_mle &lt;- coef(fit)[1]\np &lt;- function(x,a,b){exp(a*x + b)/(1+exp(a*x+ b))}\nlibrary(ggplot2)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\np_dat &lt;- tibble(x = seq(50, 300, by = .2), \n                p = p(x, a_mle, b_mle))\ndat |&gt; \n  ggplot(aes(x = x)) +\n  geom_point(aes(y=y), col = \"blue\", size = 2, alpha = .5) + \n  geom_line(data = p_dat, aes(y = p)) +\n  labs(x = \"\", y = \"\") +\n  theme_grey()"
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html",
    "href": "materialer/krydsvalidering/krydsvalidering.html",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "",
    "text": "Hvordan vælger man den bedste model til beskrivelse af data? Skal man bare vælge den mest komplicerede? Eller kan der mon gå noget galt? Det handler overfitting og krydsvalidering om.\nMere præcis handler denne note om, hvad man kan gøre, når man har flere forskellige modeller for data at vælge imellem og gerne vil vælge den bedste. Noten introducerer først polynomiel regression, der bruges som gennemgående eksempel. Mod slutningen diskuteres, hvordan de samme principper kan bruges i forbindelse med nogle af de andre algoritmer, der er gennemgået her på siden."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#polynomiel-regression",
    "href": "materialer/krydsvalidering/krydsvalidering.html#polynomiel-regression",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Polynomiel regression",
    "text": "Polynomiel regression\n\nLineær regression\nFra gymnasieundervisningen kender I lineær regression. Lad os sige, at vi har datapunkter \\((x_i,y_i)\\), hvor \\(i=1,2,\\ldots,n\\). Vi vil gerne finde den rette linje, der bedst beskriver punkterne. I denne note kalder vi linjens skæring for \\(a_0\\) og hældningen for \\(a_1\\). Linjen har altså funktionsforskriften1\n1 Du er vant til, at forskriften for en lineær funktion er på formen \\(f(x)=ax+b\\). Men lige om lidt viser skrivemåden \\(f(x)=a_0+a_1x\\) sig nyttig. I forhold til det, du kender, svarer det til, at \\(a_0=b\\) og \\(a_1=a\\).\\[f(x) = a_0 + a_1x.\\]\nFor at finde den bedste linje til at beskrive vores data, søger vi de værdier \\(a_0\\) og \\(a_1\\), som gør, at \\(a_0 + a_1x_i\\) er så tæt på \\(y_i\\) som muligt. Vi vil altså gerne gøre afvigelserne fra linjen \\(y_i - (a_0 + a_1 x_i)\\) så små som muligt. Disse afvigelser svarer til det, man kalder for residualerne:\n\\[\nr_i=y_i - (a_0 + a_1 x_i).\n\\]\nSom et samlet mål for hvor store disse afvigelser er for alle vores punkter, kigger vi på kvadratsummen af afvigelserne/residualerne\n\\[\n\\begin{aligned}\nE &= \\left(y_1 - (a_0 + a_1 x_1) \\right)^2 + \\left(y_2 - (a_0 + a_1 x_2) \\right)^2 + \\cdots + \\left(y_n - (a_0 + a_1 x_n) \\right)^2 \\\\\n& = r_1^2 + r_2^2 + \\cdots + r_n^2\n\\end{aligned}\n\\]\nNu er det lidt omstændeligt at skrive summen ud, som vi har gjort det ovenfor. I matematik vil man ofte skrive en sådan sum lidt mere kompakt ved hjælp af et summationstegn. Gør vi det, ser det sådan her ud:\n\\[\n\\begin{aligned}\nE &=\\sum_{i=1}^n \\left(y_i - (a_0 + a_1x_i) \\right)^2 \\\\\n&= \\sum_{i=1}^n r_i^2 .\n\\end{aligned}\n\\]\nVi vælger så de værdier \\(a_0\\) og \\(a_1\\), der gør \\(E\\) mindst mulig. Dette kaldes mindste kvadraters metode.\n\n\nKvadratisk regression\nHvad nu hvis det slet ikke ligner, at der er en lineær sammenhæng, når vi tegner vores datapunkter ind i et koordinatsystem? Er det så overhovedet en god idé at forsøge med en lineær regression? På figur 1 ser det for eksempel ikke ud til at punkterne følger en ret linje.\n\n\n\n\n\n\n\n\nFigur 1: Til venstre ses et punktplot af et datasæt. Til højre er den bedste rette linje indtegnet.\n\n\n\n\n\n\n\n\n\n\n\nDatasættet\n\n\n\n\n\nDatasættet fra figur 1 ses i tabellen herunder, hvis du selv vil prøve at lave lineær regression på data. Data kan også hentes som en Excel-fil her.\n\n\n\n\n\n\n\n\n\n\\(x\\)\n\\(y\\)\n\n\n\n\n0.125\n1.71\n\n\n0.25\n1.95\n\n\n0.375\n1.877\n\n\n0.5\n1.914\n\n\n0.625\n2.341\n\n\n0.75\n1.692\n\n\n0.875\n2.473\n\n\n1\n2.217\n\n\n1.125\n2.199\n\n\n1.25\n1.962\n\n\n1.375\n2.125\n\n\n1.5\n2.595\n\n\n1.625\n2.021\n\n\n1.75\n1.894\n\n\n1.875\n1.309\n\n\n2\n1.545\n\n\n2.125\n0.7685\n\n\n2.25\n0.638\n\n\n2.375\n0.7456\n\n\n2.5\n0.1396\n\n\n\n\n\n\n\n\nI figur 2 ses et såkaldt residualplot. Her kan vi tydeligt se, at der er et mønster i den måde, residualerne fordeler sig omkring \\(x\\)-aksen. Det er altså tegn på, at en ret linje ikke er velegnet til at beskrive datapunkterne.\n\n\n\n\n\n\n\n\nFigur 2: Residualplottet for den bedste rette linje indtegnet i figur 1.\n\n\n\n\n\nNår \\(x\\) ligger mellem 0 og 1, kunne der godt se ud til at være en svagt stigende tendens i figur 1, mens der ser ud til at være en aftagende tendens for \\(x&gt;1.5\\). Det svarer til, at residualerne i figur 2 først er negative, så positive og dernæst negative igen. Den rette linje i figur 1 ser heller ikke ud til at følge punkterne særlig godt. Måske en parabel passer bedre på data?\n\n\n\n\n\n\n\n\nFigur 3: Datasættet fra figur 1, men nu med en parabel indtegnet.\n\n\n\n\n\nDet ser ud til, at parablen i figur 3 følger datapunkterne langt bedre. Vi kunne således prøve at modellere \\(y\\) ved hjælp af et andengradspolynomium i \\(x\\). Lad \\(f\\) betegne andengradspolynomiet2\n2 I gymnasiet skriver vi som regel forskriften for et andengradspolynomium på formen \\(f(x)=ax^2+bx+c\\). Med notationen, som vi bruger her, svarer det til, at \\(a_0=c, a_1=b\\) og \\(a_2=a\\).\\[\nf(x) = a_0 + a_1x + a_2x^2\n\\]\nmed koefficienter \\(a_0,a_1,a_2\\in \\mathbb{R}\\).\nHvordan finder man så det andengradspolynomium, der bedst beskriver datapunkterne? Tilgangen er faktisk den samme som den mindste kvadraters metode, I kender fra lineær regression. Vi søger de værdier \\(a_0, a_1\\) og \\(a_2\\), som gør, at \\(f(x_i)\\) kommer så tæt på \\(y_i\\) som muligt. Vi vil altså gerne gøre forskellene \\(y_i - f(x_i)\\) så små som muligt. Vi kigger derfor på kvadratsummen af disse forskelle \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2 = \\sum_{i=1}^n \\left(y_i - (a_0 + a_1x_i + a_2x_i^2)\\right)^2.\\] Vi søger så de værdier \\(a_0,a_1\\) og \\(a_2\\), der minimerer \\(E\\).\nGør man det i vores lille dataeksempel, fås netop den parabel, der er tegnet ind i koordinatsystemet i figur 3. Vi ser, at den beskriver data langt bedre end den rette linje.\nEksemplet viser vigtigheden af at tegne et residualplot for at vurdere anvendeligheden af den lineære model. Ellers kan man nemt komme til at overse en eventuel ikke-lineær sammenhæng.\n\n\nPolynomiel regression generelt\nMen hvordan kan vi nu vide, at et andengradspolynomium er det bedste til at beskrive data? Måske et polynomium af endnu højere grad ville være bedre? Man kan tilpasse tredje- og højeregradspolynomier til data på en helt tilsvarende måde. Vi kan for eksempel prøve at tilpasse et tredjegradspolynomium\n\\[\nf(x) = a_0 + a_1x + a_2x^2 +a_3x^3.\n\\]\nDet bedste tredjegradspolynomium er igen det, der minimerer kvadratsummen \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2 = \\sum_{i=1}^n \\left(y_i - (a_0 + a_1x_i + a_2x_i^2 + a_3x_i^3 )\\right)^2.\\] Grafen for det bedste tredjegradspolynomium er indtegnet med grøn for vores dataeksempel i figur 4. Andengradspolynomiet er indtegnet med rød til sammenligning.\n\n\n\n\n\n\n\n\nFigur 4: Et andengradspolynomium (rød) og et tredjegradspolynomium (grøn) fittet til data.\n\n\n\n\n\nDet er ikke så let at se forskel. De to polynomier ser ud til at passe nogenlunde lige godt på vores data. Men i figur 5 har vi zoomet ud på figuren ovenfor, og her er der en klar forskel:\n\n\n\n\n\n\n\n\nFigur 5: Plottet fra figur 4, men hvor der nu er zoomet lidt ud. Her ses det tydeligt, at der i “enderne” bliver stor forskel på anden- og tredjegradspolynomiet.\n\n\n\n\n\nSelv om der ikke var stor forskel på anden- og tredjegradspolynomiet på intervallet \\([0;2,5]\\) hvor alle \\(x\\)-værdierne i vores datasæt lå, så er der stor forskel, når vi kommer uden for dette interval. Man skal derfor passe på med at drage konklusioner om \\(x\\)-værdier uden for intervallet, hvor \\(x\\)-værdierne i vores datasæt ligger (det kaldes at ekstrapolere), da disse kan være meget følsomme over for, hvilken grad vi har valgt for vores polynomium. En fornuftig ekstrapolation vil derfor ofte kræve et forudgående kendskab til den sammenhæng, man modellerer ved valget af graden af polynomiet."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#overfitting",
    "href": "materialer/krydsvalidering/krydsvalidering.html#overfitting",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Overfitting",
    "text": "Overfitting\nDet er altså svært at afgøre med det blotte øje, om anden- eller tredjegradspolynomiet passer bedst til punkterne. Hvordan vælger vi så, hvad der er bedst? Som mål for, hvor tæt polynomiet er på data, kan vi kigge på kvadratsummen af afvigelserne \\(y_i - f(x_i)\\), altså \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2.\\] For andengradspolynomiet får vi en kvadratsum på \\(E=1.14\\), mens vi får \\(E=1.10\\) for tredjegradspolynomiet. Tredjegradspolynomiet kommer altså tættere på data end andengradspolynomiet. Det er på den anden side ikke så overraskende, for ved at sætte \\(a_3=0\\) i et tredjegradspolynomium fås et andengradspolynomium. Andengradspolynomier er altså specialtilfælde af tredjegradspolynomier. Vi vil derfor altid kunne tilpasse data mindst lige så godt med et tredjegradspolynomium som med et andengradspolynomium.\nKan det så altid betale sig at bruge et polynomium af højere grad? Lad os prøve med et syvendegradspolynomium. Vi søger \\[f(x) = a_0 + a_1x + a_2x^2 +a_3x^3 + a_4x^4 + a_5x^5 +a_6x^6 +a_7x^7,\\] der minimerer kvadratsummen \\[E=\\sum_{i=1}^n (y_i - f(x_i))^2 .\\] Det bedste syvendegradspolynomium i vores lille dataeksempel er indtegnet med blå på figur 6 nedenfor:\n\n\n\n\n\n\n\n\nFigur 6: Et andengradspolynomium (rød) og et syvendegradspolynomium (blå) fittet til data.\n\n\n\n\n\nKvadratsummen er på kun \\(E=0.90\\), så umiddelbart virker det til at være en meget bedre model. Der er dog visse problemer. Det ses, at grafen bugter sig meget for at komme så tæt som muligt på datapunkterne. Dels virker det urealistisk, at den faktiske sammenhæng mellem \\(x\\) og \\(y\\) skulle være så kompliceret. Dels opstår der et problem, hvis vi kommer med nye datapunkter. I figur 7 er polynomierne fra før tegnet sammen med 20 nye datapunkter i grøn (som stammer fra den samme underliggende fordeling). Nu beskriver syvendegradspolynomiet pludselig ikke datapunkterne så godt længere.\n\n\n\n\n\n\n\n\nFigur 7: Andengradspolynomiet (rød) og syvendegradspolynomiet (blå) fra figur 6 sammen med 20 nye datapunkter (grøn), som kommer fra den samme underliggende fordeling, som de sorte datapunkter fra figur 6.\n\n\n\n\n\nDet, der sker her, er et eksempel på det fænomen, der kaldes overfitting: syvendegradspolynomiet havde tilpasset sig for godt til lige netop de sorte datapunkter. Når graden bliver for høj, begynder polynomiet at tilpasse sig nogle strukturer i data, som i virkeligheden bare skyldes tilfældigheder. Det fungerer rigtig godt til at beskrive det oprindelige data, men til gengæld er det dårligt til at forudsige nye dataværdier.\nJo højere grad man vælger, at polynomiet skal have, desto bedre kan man tilnærme data. Med \\(n\\) datapunkter (som alle have forskellige \\(x\\)-værdier), kan man faktisk altid finde et polynomium af grad \\(n-1\\), der går igennem alle datapunkterne, men nye datapunkter vil ikke nødvendigvis følger dette polynomium særlig godt.\n\nModelfleksibilitet\nDet, vi så ovenfor, var, at vi havde forskellige modeller for data (polynomier af forskellig grad). Modellerne havde forskellig fleksibilitet (høj grad gjorde polynomiet meget fleksibelt). Når vi brugte en model med for lav fleksibilitet (lineær regression), kunne vi ikke tilpasse modellen godt nok til data. Når vi valgte en model med for høj fleksibilitet (polynomium af grad syv), opstod der problemer med overfitting, og modellen var ikke god til at beskrive nye data.\nDet tilsvarende problem opstår også i andre sammenhænge, når man har flere forskellige modeller at vælge imellem. Nogle vil være for ufleksible til at beskrive data ordentligt. Andre vil være for fleksible og føre til overfitting. Så hvordan finder vi et godt kompromis? Det handler det følgende om."
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#trænings--og-testdata",
    "href": "materialer/krydsvalidering/krydsvalidering.html#trænings--og-testdata",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Trænings- og testdata",
    "text": "Trænings- og testdata\nNår vi har et datasæt og prøver at tilpasse en polynomiel regressionsmodel, siger vi, at vi træner modellen. Datasættet, vi bruger til at træne modellen, kaldes træningsdata. Som vi så ovenfor, indebærer det en risiko for overfitting, når vi træner modellen. Hvis vi kommer med et nyt datasæt af samme type, passer modellen ikke nødvendigvis særlig godt.\nFor at vurdere hvilken grad af polynomiet der passer bedst, kan vi se på, hvilken model der er bedst til at forudsige (også kaldet prædiktere) \\(y\\)-værdierne i et nyt datasæt. Det nye datasæt kaldes testdata. Lad os kalde testdatapunkterne for \\((x_i^{test},y^{test}_i)\\), hvor \\(i=1,\\ldots,m\\). Man kan måle, hvor godt modellen forudsiger testdata ved at se på forskellene \\(y_i^{test}-f(x_i^{test})\\) mellem de observerede værdier \\(y_i^{test}\\) og dem, der forudsiges af polynomiet \\(f(x_i^{test})\\). Som samlet mål for, hvor godt modellen forudsiger testdata, beregner vi kvadratsummen af disse forskelle \\[E^{test} = \\sum_{i=1}^{m} \\left(y_i^{test} - {f}\\left(x_i^{test}\\right)\\right)^2.\\] Man kalder \\(E^{test}\\) for tabsfunktionen.\nI praksis har man typisk kun et datasæt til rådighed, og man er derfor nødt til først at dele data i to. Hele processen med at inddele data og først træne modellen og derefter teste den er, som følger:\n\nVælg en polynomiumsgrad \\(p\\).\nDatasættet inddeles i to dele, én del der bruges som træningsdata, og én del der bruges som testdata. Vi vil betegne punkterne i træningsdata med \\((x_i^{træn},y_i^{træn})\\), \\(i=1,\\ldots,n\\), og punkterne i testdata med \\((x_i^{test},y_i^{test})\\), \\(i=1,\\ldots,m\\).\nVi træner modellen på træningsdatasættet og finder det \\(p\\)’te-gradspolynomium \\[f(x)=a_0 + a_1 x + \\dotsm + a_px^p\\] der passer bedst på data. Mindste kvadraters metode benyttes til at bestemme \\(a_0,\\ldots,a_p\\) som de tal, der minimerer \\[E^{træn}(p)=\\sum_{i=1}^{n} (y_i^{træn} - {f}(x_i^{træn}))^2.\\] Det bedste polynomium kalder vi \\(\\hat{f}\\).\nNår vi har valgt funktionen \\(\\hat{f}\\) på baggrund af træningsdataet, tester vi den på testdataet ved at beregne \\[E^{test}(p)=\\sum_{i=1}^{m} (y_i^{test} - \\hat{f}(x_i^{test}))^2.\\] Jo mindre \\(E^{test}(p)\\) er, des bedre passer \\(\\hat{f}\\) på testdata.\n\nDenne procedure kan gentages for forskellige værdier af polynomiumsgraden \\(p\\). Det \\(p\\), der giver den mindste værdi af \\(E^{test}(p)\\) svarer altså til den model, der er bedst til at forudsige værdierne i vores testdata, og vi vælger derfor at bruge dette \\(p\\).\nI vores eksempel ovenfor får vi \\(E^{test}(2)=1.82\\) og \\(E^{test}(7)=2.29\\), når vi bruger de sorte datapunkter som træningsdata og de grønne datapunkter som testdata. Andengradspolynomiet er altså bedre end syvendegradspolynomiet til at forudsige testdata. Bemærk, at i begge tilfælde er \\(E^{test}\\) langt større end \\(E^{træn}\\), fordi modellen kun er tilpasset til træningsdata.\nNår det bedst mulige \\(p\\) er valgt, kan man så træne modellen igen på alt dataet, både test- og træningsdata, for at få et mere præcist bud på det bedste polynomium. Dette er så vores endelige model for data. I vores eksempel finder man, at \\(p=2\\) giver lavest \\(E^{test}\\). Vi slår så de sorte og grønne datapunkter sammen til et datasæt og bruger dem til at finde det bedste andengradspolynomium. Det giver vores endelige model for sammenhængen mellem \\(x\\) og \\(y\\), som bliver \\[\nf(x) = 1.36 + 1.72x - 0.87x^2.\n\\]"
  },
  {
    "objectID": "materialer/krydsvalidering/krydsvalidering.html#sec-krydsvalidering",
    "href": "materialer/krydsvalidering/krydsvalidering.html#sec-krydsvalidering",
    "title": "Overfitting, modeludvælgelse og krydsvalidering",
    "section": "Krydsvalidering",
    "text": "Krydsvalidering\nDer er et problem med tilgangen ovenfor. Når man træner en model, er det altid en fordel at have så meget data som muligt, da man så har mulighed for at træne modellen meget præcist. Problemet er, at hvis man bruger det meste af data som træningsdata, er der ikke meget tilbage til at teste på, og vi risikerer overfitting.\nKrydsvalidering løser dette problem på snedig vis ved at gentage trænings- og testproceduren flere gange. For at lave \\(k\\)-fold krydsvalidering deler man data op i \\(k\\) lige store og tilfældige dele. I første fold træner man modellen på alt data undtagen den første del og bruger første del som testdata. Det given en tabsfunktion \\(E_1(p)\\). Dette gentages så \\(k\\) gange, hvor man i den \\(i\\)’te fold bruger den \\(i\\)’te del af data som testdata og resten som træningsdata og får en tabsfunktion \\(E_i(p)\\). Idéen er illustreret i figur 8.\n\n\n\n\n\n\n\n\nFigur 8: Illustration af idéen ved \\(5\\)-fold krydsvalidering.\n\n\n\n\n\nSom et samlet mål for, hvor god modellen er, bruges summen af tabsfunktionerne fra de \\(k\\) fold \\[E(p)=E_1(p) + E_2(p) + \\dotsm + E_k(p).\\] Man vælger så den model, der giver den mindste værdi af \\(E(p)\\).\nFordelen ved krydsvalidering er, at man i hver fold bruger det meste af data til at træne modellen på. Samtidig bliver hvert datapunkt alt i alt brugt præcis én gang til at teste på. På den måde får man udnyttet data bedre end, hvis man bare laver en enkelt opdeling af data. Typisk vælger man \\(k=5\\) eller \\(k=10\\).\n\nKrydsvalidering i andre sammenhænge\nKrydsvalidering kan bruges i et væld af andre sammenhænge, hvor der skal vælges mellem flere forskellige prædiktionsmodeller.\nHvis det, der skal prædikteres, er en talværdi, kan man gøre som ovenfor. Algoritmen trænes på træningsdataet og bruges derefter til lave prædiktioner \\(\\hat{y}_i^{test}\\), \\(i=1,\\ldots ,m\\), af værdierne i testdatasættet. Disse sammenlignes med de faktiske værdier \\(y_i^{test}\\) ved at se på forskellene \\(y_i^{test} - \\hat{y}_i^{test}\\) og beregne tabsfunktionen \\[E^{test} = \\sum_{i=1}^m(y_i^{test}-\\hat{y}_i^{test})^2.\\] Modellen med lavest \\(E^{test}\\) er bedst til at lave nye prædiktioner.\nHvis der derimod er tale om et klassifikationsproblem, hvor der skal prædikteres en klasse (fx mand/kvinde, rød blok/blå blok, almindelig mail/spam), skal man definere tabsfunktionen lidt anderledes. Som før trænes algoritmen på træningsdataet og derefter bruges den til lave prædiktioner af klasserne \\(\\hat{y}_i^{test}\\), \\(i=1,\\ldots ,m\\), i testdatasættet. Disse sammenholdes med de faktiske klasser, og vi bruger så fejlraten som tabsfuntion. Fejlraten angiver andelen af observationerne i testdataet, der bliver klassificeret forkert, det vil sige\n\\[\nE^{test} =  \\frac{1}{m}\\cdot (\\text{antal fejlklassifikationer i testdata}).\n\\tag{1}\\]\nModellen med lavest \\(E^{test}\\) har færrest fejlklassifikationer og vælges derfor som den bedste.\nEksempler her fra siden, hvor krydsvalidering kan benyttes:\n\nI forløbet Hvem ligner du mest sammenligner man et gråt punkt med alle punkter inden for en radius \\(r\\) for at forudsige farven. Det er ikke oplagt, hvordan man skal vælge denne radius. En mulighed er at komme med nogle gode bud \\(r_1,\\ldots, r_N\\) på radier og så bruge krydsvalidering til at vælge den bedste. Én mulighed er at vælge \\(k=n\\). Så får man det, der kaldes leave-one-out krydsvalidering. I hver fold bliver der så kun et datapunkt i testdata, mens resten bruges som træningsdata. Det ene testdatapunkt farves gråt, og farven prædikteres ud fra de øvrige datapunkter, der ligger inden for den valgte radius. Prædiktionen sammenlignes med punktets rigtige farve. Dette gentages for alle datapunkter og fejlraten (1) beregnes til sidst. Vi vælger så den radius, der har lavest fejlrate.\nI noten om Kunstige neurale nerværk beskrives det, hvordan man træner et kunstigt neuralt netværk. Men når man gør det, skal man på forhånd have besluttet sig for, hvor mange skjulte lag der skal være i netværket, og hvor mange neuroner, der skal være i hvert skjult lag. Jo flere skjulte lag og jo flere neuroner – desto større fleksibilitet. Her vil krydsvalidering være oplagt til at afgøre, hvor fleksibelt netværket skal være samtidig med, at man undgår overfitting."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html",
    "title": "Funktioner af flere variable",
    "section": "",
    "text": "En funktion kan godt afhænge af flere forskellige variable, og i det tilfælde taler man om en funktion af flere variable. Denne type af funktioner viser sig at spille en helt central rolle i rigtig mange metoder inden for kunstig intelligens. Derfor vil vi i denne note behandle de vigtigste begreber i forbindelse med funktioner af flere variable."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-én-variabel",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-én-variabel",
    "title": "Funktioner af flere variable",
    "section": "Funktioner af én variabel",
    "text": "Funktioner af én variabel\nFra gymnasiematematikken kender vi lineære funktioner, eksponentialfunktioner, potensfunktioner og en hel masse andre typer af funktioner. Fælles for dem er, at de alle afhænger af én variabel \\(x\\). For eksempel de lineære funktioner:\n\\[\nf(x)=a \\cdot x+b.\n\\] Grafen for \\(f\\) består af alle de punkter \\((x,y)\\), hvor \\(y=f(x)\\). Det er illustreret på figur 1.\n\n\n\n\n\n\nFigur 1: Grafen for en lineær funktion \\(f(x)=ax+b\\), hvor det er illustreret at et punkt \\((x,y)\\) ligger på grafen for \\(f\\), hvis \\(y=f(x)\\).\n\n\n\nHvis funktionen \\(f\\) tager et reelt tal som input og giver et reelt tal som output1, så skriver man\n1 Hverken definitions- eller værdimængden for funktionen behøver ikke at være hele \\(\\mathbb{R}\\), men kan godt bare være en delmængde af \\(\\mathbb{R}\\).\\[\nf: \\mathbb{R} \\rightarrow \\mathbb{R}.\n\\] Du har måske også været vant til at se en \"maskine-metafor\", som illustreret på figur 2.\n\n\n\n\n\n\nFigur 2: Funktionen \\(f\\) illustreret som en maskine.\n\n\n\nHer er tanken, at man sender et \\(x\\) ind i funktionsmaskinen, som så ved hjælp af forskriften for \\(f\\) beregner funktionsværdi \\(y=f(x)\\), som herefter bliver sendt ud af maskinen2.\n2 Faktisk er det ikke alle funktioner, som har en forskrift. For eksempel er der ikke nødvendigvis en forskrift for den funktion, hvis graf ses til venstre i figur 3. Her vil man i stedet kunne aflæse en funktionsværdi for en given værdi af \\(x\\). En anden mulighed er, at funktionsværdien skal findes i en tabel.For at der overhovedet er tale om en funktion, skal det være sådan, at der til enhver værdi af \\(x\\) svarer én og kun én funktionsværdi \\(f(x)\\). Så hvis man for eksempel sender \\(x=2\\) ind i maskinen, så må funktionen ikke nogle gange sende \\(y=5\\) ud og andre gange \\(y=-3\\). Hvis \\(x=2\\) kommer ind, så skal det altid være den samme funktionsværdi, der kommer ud.\nGrafisk er det illustreret på figur 3.\n\n\n\n\n\n\nFigur 3: Til venstre ses grafen for en funktion. Til højre ses en kurve, som ikke kan være grafen for en funktion. Ved den grønne linje ses for eksempel en \\(x\\)-værdi hvortil der svarer ikke kun én, men tre \\(y\\)-værdier."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-to-variable",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-to-variable",
    "title": "Funktioner af flere variable",
    "section": "Funktioner af to variable",
    "text": "Funktioner af to variable\nIdéen med funktioner af to variable er en funktion \\(f\\), som skal bruge to tal som input for at give et output. Vi kalder her de to inputværdier for \\(x\\) og \\(y\\). Her er et eksempel:\n\\[\nf(x,y)= 2x^2-y^2+3xy+1.\n\\]\nGrafen for \\(f\\) består nu af alle de punkter \\((x,y,z)\\) i et tre-dimensionelt koordinatsystem, hvor \\(z=f(x,y)\\). For eksempel er\n\\[\n\\begin{aligned}\nf(1,-2)&=2\\cdot 1^2-(-2)^2+3 \\cdot 1 \\cdot (-2)+1 \\\\\n&=2-4-6+1=-7\n\\end{aligned}\n\\] Det betyder, at punktet \\(P(1,-2,-7)\\) ligger på grafen for \\(f\\). Grafen for \\(f\\) og punktet \\(P\\) ses i figur 4 herunder.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFigur 4: Grafen for funktionen \\(f\\) med forskrift \\(f(x,y)=2x^2-y^2+3xy+1\\) samt punktet \\(P(1,-2,-7)\\).\n\n\n\nFaktisk kender du allerede en særlig type af funktioner af to variable. Nemlig den slags funktioner, hvis graf er en plan. Som du måske husker, kan en plan gennem punktet \\((x_0,y_0,z_0)\\) og med normalvektor\n\\[\n\\vec n =\n\\begin{pmatrix}\na \\\\\nb \\\\\nc\n\\end{pmatrix}\n\\]\nbeskrives ved ligningen\n\\[\na(x-x_0)+b(y-y_0)+c(z-z_0)=0.\n\\]\nEn alternativ skrivemåde er\n\\[\nax+by+cz+d=0.\n\\] Hvis \\(c \\neq 0\\) kan vi i denne ligning isolere \\(z\\):\n\\[\nz = -\\frac{a}{c}x -\\frac{b}{c}y-\\frac{d}{c}.\n\\]\nEn ikke-lodret plan i rummet er derfor graf for en funktion af to variable med en forskrift på formen\n\\[\nf(x,y)= -\\frac{a}{c}x -\\frac{b}{c}y-\\frac{d}{c}.\n\\] Og skrevet lidt simplere:\n\\[\nf(x,y) = Ax+By+C,\n\\]\nhvor \\(A=-a/c, B=-b/c\\) og \\(C=-d/c\\).\nVi kan igen bruge \"maskine-metaforen\" for funktioner af to variable, som illustreret i figur 5.\n\n\n\n\n\n\nFigur 5: Funktionen \\(f\\) af to variable illustreret som en maskine.\n\n\n\nFor at vi kan tale om, at det er en funktion, kræver vi igen, at der til enhver værdi af \\((x,y)\\) svarer én og kun én funktionsværdi \\(z=f(x,y).\\) Maskinen skal altså altid returnere den samme funktionsværdi for en given værdi af \\((x,y)\\).\nHvis en funktion \\(f\\), som input kan tage en \\((x,y)\\)-værdi, og som output giver en funktionsværdi \\(z\\), skriver vi\n\\[\nf: \\mathbb{R}^2 \\rightarrow \\mathbb{R}.\n\\]\nHer indikerer \\(2\\)-tallet altså, at der er tale om en funktion af to variable.\n\nSnitfunktioner og snitkurver\nVi vil nu for en funktion af to variable tage udgangspunkt i et konkret punkt \\(P(x_0, y_0, f(x_0,y_0))\\). Forestil dig at vi i \\(P\\) laver et lodret snit ned gennem grafen for \\(f\\) med en plan, som er parallel med \\(x\\)-aksen. Det er lidt ligesom, at lave et snit ned gennem en lagkage! Et eksempel er vist i figur 6. Den lyseblå plan svarer til den lagkagekniv, vi har skåret med, og den skærer altså lodret og er samtidig parallel med \\(x\\)-aksen.\nNår man laver sådan et lodret snit med grafen for \\(f\\), så kalder man skæringen mellem den lodrette plan (lagkagekniven) og grafen for \\(f\\) for en snitkurve. Snitkurven er markeret med sort på figur 6. Den funktion, hvis graf svarer til snitkurven, kaldes for en snitfunktion. Forskriften for snitfunktionen fås ved, at vi fastholder \\(y\\)-værdien på \\(y_0\\) og lader \\(x\\) varierer:\n\\[\ng(x)=f(x,y_0).\n\\] Vi kan også lave et lodret snit gennem \\(P(x_0,y_0,f(x_0,y_0))\\), men hvor snittet i stedet er parallel med \\(y\\)-aksen – se figur 7. Det svarer til, at vi fastholder \\(x\\) på værdien \\(x_0\\) og lader \\(y\\) variere. Gør vi det fås snitfunktionen\n\\[\nh(y)=f(x_0,y).\n\\]\nLad os se på eksemplet fra tidligere \\[\nf(x,y)= 2x^2-y^2+3xy+1.\n\\]\nFastholder vi for eksempel \\(y\\) på \\(-2\\), får vi snitfunktionen\n\\[\n\\begin{aligned}\ng(x) &=f(x,-2)=2x^2-(-2)^2+3 \\cdot x \\cdot (-2)+1 \\\\\n&=2x^2-6x-3.\n\\end{aligned}\n\\] Den tilhørende snitkurve svarer til skæringskurven mellem grafen for \\(f\\) og planen med ligning \\(y=-2\\), som ses i figuren herunder. Bemærk, at snitfunktionen \\(g\\) er et andengradspolynomium, hvis graf er en parabel med grene, som vender opad, idet koefficienten til andengradsleddet er positiv.\n\n\n\n\n\n\n\n\nFigur 6: Grafen for snitfunktionen \\(g\\) med forskrift \\(g(x)=2x^2-6x-3\\) markeret med sort. Den lyseblå plan er planen med ligning \\(y=-2\\).\n\n\n\nFastholder vi derimod \\(x\\) på \\(1\\), får vi snitfunktionen\n\\[\n\\begin{aligned}\nh(y)&=f(1,y)=2 \\cdot 1^2 -y^2 +3 \\cdot 1 \\cdot y +1 \\\\\n&=-y^2+3y+3.\n\\end{aligned}\n\\] Her ser vi igen, at snitfunktionen er et andengradspolynomium, og grafen vil være en parabel med grene, der vender nedad. Snitkurven svarer til skæringskurven mellem grafen for \\(f\\) og planen med ligning \\(x=1\\), som vist herunder.\n\n\n\n\n\n\n\n\nFigur 7: Grafen for snitfunktionen \\(h\\) med forskrift \\(h(y)=-y^2+3y+3\\) markeret med sort. Den lyseblå plan er planen med ligning \\(x=1\\).\n\n\n\n\n\nPartielle afledede\nFra funktioner af én variabel ved vi, at nogle funktioner er differentiable. Det kan funktioner af to variable også være. Her defineres de såkaldte partielle afledede ved simpelthen af differentiere de to forskellige typer af snitfunktioner, som vi definerede ovenfor.\nLad os forklare det lidt nærmere. Snitfunktionen \\(g(x)=f(x,y_0)\\) er jo en \"almindelig\" funktion af én variabel \\(x\\). Hvis \\(g\\) er differentiabel, så kalder man \\(g'(x)\\) for den partielle afledede af \\(f\\) med hensyn til \\(x\\). Notationen for den partielle afledede af \\(f\\) med hensyn til \\(x\\) er som regel en af følgende:\n\\[\ng'(x)=f_x(x,y_0)=\\frac{\\partial f}{\\partial x}=\\frac{\\partial}{\\partial x}f(x,y_0),\n\\]\nhvor \\(y_0\\) her er en konstant.\nDefinitionen af den partielle afledede kan også skrives med den vante \"grænseværdi-notation\". Gør man det kommer det til at se sådan her ud:\n\\[\nf_x(x,y_0) = \\lim_{h \\rightarrow 0} \\frac{f(x+h,y_0)-f(x,y_0)}{h}\n\\]\nSer vi igen på vores eksempel, får vi\n\\[\nf(x,y_0)= 2x^2-y_0^2+3xy_0+1.\n\\] Så vil den partielle afledede med hensyn til \\(x\\) være\n\\[\nf_x(x,y_0)=2 \\cdot 2x-0 + 3 \\cdot 1 \\cdot y_0 + 0 = 4x+3y_0.\n\\] Bemærk her, at \\(y_0^2\\) differentieret bliver \\(0\\), fordi \\(y_0\\) er en konstant, og en konstant, som er lagt til, bliver som bekendt \\(0\\), når vi differentierer. Når vi skal differentiere udtrykket \\(3xy_0\\), så er \\(y_0\\) en konstant, som er ganget på, og derfor lader vi den stå, når vi differentierer (ligesom vi lader \\(3\\)-tallet stå og differentierer \\(x\\), som giver \\(1\\)).\nNormalvis gider man ikke slæbe rundt på \\(y_0\\) i ovenstående udtryk, fordi \\(y_0\\) jo kan være en hvilken som helst værdi svarende til, at vi flytter det lodrette snit. Derfor skriver man som oftest bare\n\\[\nf_x(x,y)=4x+3y.\n\\]\nNår vi finder den partielle afledede med hensyn til \\(x\\), kan vi altså gøre det helt generelt, hvor vi bare tænker på \\(y\\) som en konstant.\nTidligere fastholdt vi \\(y\\) på værdien \\(-2\\). Indsætter vi \\(y=-2\\) i ovenstående udtryk for \\(f_x(x,y)\\) får vi\n\\[\nf_x(x,-2)=4x+3 \\cdot (-2)=4x-6.\n\\] Men vi kunne lige så godt have differentieret snitfunktionen\n\\[\ng(x)=f(x,-2)=2x^2-6x-3.\n\\] Gør vi det, får vi \\[\ng'(x)=4x-6,  \n\\] der heldigvis svarer til udtrykket for \\(f_x(x,-2)\\), som vi netop har fundet.\nHelt tilsvarende definerer vi den partielle afledede af \\(f\\) med hensyn til \\(y\\) ved at differentiere snitfunktionen \\(h(y)\\) (såfremt denne snitfunktion er differentiabel):\n\\[\nh'(y)=f_y(x_0,y)=\\frac{\\partial f}{\\partial y}=\\frac{\\partial}{\\partial y}f(x_0,y)\n\\]\nog med \"grænseværdi-notationen\" bliver det\n\\[\nf_y(x_0,y) =\n\\lim_{h \\rightarrow 0} \\frac{f(x_0,y+h)-f(x_0,y)}{h}.\n\\] $$\nSer vi igen på \\[\nf(x_0,y)= 2x_0^2-y^2+3x_0y+1,\n\\] så vil den partielle afledede med hensyn til \\(y\\) være\n\\[\nf_y(x_0,y)=0-2y+3x_0\\cdot 1+0=3x_0-2y.\n\\]\nHer er \\(x_0\\) en konstant, og derfor er \\(2x_0^2\\) differentieret \\(0\\), og \\(3x_0y\\) differentieret med hensyn til \\(y\\) bliver \\(3x_0\\).\nIgen vil vi som oftest bare skrive\n\\[\nf_y(x,y)=3x-2y.\n\\]\n\n\nGrafisk betydning af de partielle afledede\nFor en funktion \\(f\\) af én variabel ved vi, at hvis \\(f\\) er differentiabel i \\(x_0\\), så vil \\(f'(x_0)\\) svarer til hældningen for tangenten til grafen for \\(f\\) i punktet \\((x_0,f(x_0))\\).\nVi kan nu udlede en tilsvarende grafisk betydning af de partielle afledede. Vi ser igen på snitfunktionen \\(g(x)\\), hvor \\(y\\) er fastholdt på \\(y_0\\):\n\\[\ng(x)=f(x,y_0)\n\\]\nDen partielle afledede med hensyn til \\(x\\) er så\n\\[\ng'(x)=f_x(x,y_0).\n\\] Men nu må \\(g'(x_0)\\) være hældningen for tangenten til grafen for snitfunktionen \\(g\\) i punktet \\((x_0,g(x_0))\\).\nLad os illustrere det med vores eksempel hvor \\(f(x,y)= 2x^2-y^2+3xy+1\\). Her er\n\\[\nf_x(x,y)=4x+3y.\n\\] Vi fandt tidligere, at \\(P(1,-2,-7)\\) ligger på grafen for \\(f\\). Ser vi på snitfunktionen \\(g(x)=f(x,-2)\\), så ligger \\(P\\) altså også på den tilsvarende snitkurve.  Udregner vi \\(g'(1)=f_x(1,-2)\\), får vi\n\\[\nf_x(1,-2)=4 \\cdot 1 + 3 \\cdot (-2) = 4-6=-2\n\\]\nDet betyder, at hvis vi tegner tangenten til snitkurven i \\(P\\), så vil denne tangent have en hældning på \\(-2\\), som illustreret i figuren herunder.\n\n\n\n\n\n\n\n\nFigur 8: Tangenten (stiplet linje) til grafen for snitfunktionen \\(g\\) med forskrift \\(g(x)=2x^2-6x-3\\) i punktet \\(P(1,-2,-7)\\) har en hældning på \\(-2\\).\n\n\n\nHelt tilsvarende kan vi fortolke den partielle afledede af \\(f\\) med hensyn til \\(y\\) i punktet \\(P\\). Vi fandt, at\n\\[\nf_y(x,y)=3x-2y.\n\\]\nSå i \\((1,-2)\\) har vi\n\\[\nf_y(1,-2)= 3 \\cdot 1 - 2 \\cdot (-2)=3+4=7\n\\] Altså vil tangenten til snitkurven hørende til snitfunktionen \\(h(y)=f(1,y)\\) have en tangenthældning på \\(7\\) i punktet \\((-2,h(-2))\\). Det er vist i figuren herunder.\n\n\n\n\n\n\n\n\nFigur 9: Tangenten (stiplet linje) til grafen for snitfunktionen \\(h\\) med forskrift \\(h(y)=-y^2+3y+3\\) i punktet \\(P(1,-2,-7)\\) har en hældning på \\(7\\).\n\n\n\nDe partielle afledede svarer altså til tangenthældninger på snitkurver, som er fremkommet ved at finde skæringskurven mellem grafen for \\(f\\) og en plan med ligning \\(x=x_0\\) eller grafen for \\(f\\) og en plan med ligning \\(y=y_0\\).\nMan kan også bestemme tangenthældninger for mere generelle snitkurver, som fremkommer ved, at man finder skæringskurven mellem grafen for \\(f\\) og en plan med ligning \\(ax+by+c=0\\) (som står vinkelret på \\(xy\\)-planen). Differentierer man de tilhørende snitfunktioner, kalder man de afledede for retningsafledede. Det kan du læse meget mere om her.\nFor funktioner af flere variable kan man også bestemme en ligning for en såkaldt tangentplan. Det kan du læse mere om her.\n\n\nGradienten og betydningen af denne\nMan definerer gradienten for en funktion \\(f\\) af to variable, som den vektor hvis koordinater svarer til de partielle afledede. Gradienten skrives \\(\\nabla f (x,y)\\). Det vil sige, at\n\\[\n\\nabla f(x,y) =\n\\begin{pmatrix}\nf_x(x,y) \\\\ f_y(x,y)\n\\end{pmatrix}.\n\\]\nVi ser her, at gradienten er en to-dimensionel vektor. Det betyder, at man kan tegne en repræsentant for vektoren i \\(xy\\)-planen.\nLad os regne lidt på det i vores eksempel. Vi husker, at \\(f(x,y)=2x^2-y^2+3xy+1\\) og vi fandt ovenfor, at \\[\nf_x(1,-2)=-2\n\\] og\n\\[\nf_y(1,-2)=7.\n\\] Det vil sige, at \\[\n\\nabla f(1,-2) =\n\\begin{pmatrix}\n-2 \\\\ 7\n\\end{pmatrix}\n\\]\nTegner vi en repræsentant for denne vektor i \\(xy\\)-planen med udgangspunkt i punktet \\(Q(1,-2,0)\\) (som er projektionen af \\(P(1,-2,-7)\\) op på \\(xy\\)-planen) ses resultatet i figur 10 herunder. Hvis du drejer lidt rundt på grafen, kan du se, at gradienten angiver en retning i \\(xy\\)-planen. Laver man et snit med en lodret plan gennem \\(P\\), som peger i gradientens retning fås den snitkurve, som er indtegnet med sort.\n\n\n\n\n\n\n\n\nFigur 10: En repræsentant for vektoren \\(\\nabla f(1,-2)\\) er tegnet med udgangspunkt i \\(P(1,-2,7)\\)’s projektion på \\(xy\\)-planen.\n\n\n\nDet er jo alt sammen fint nok, men hvad skal man mon bruge det til? Det er nemmest at forklare, hvis du forestiller dig, at grafen for \\(f\\) er et landskab, hvor du står i punktet \\(P(x_0,y_0,f(x_0,y_0))\\). Så viser det sig, at gradienten \\(\\nabla f(x_0,y_0)\\) peger i den retning, hvor funktionsværdien vokser mest3. Det vil altså sige, at hvis du står i \\(P\\) og gerne vil gå allermest opad bakke, så skal du gå i gradientens retning. Det svarer derfor til at følge den snitkurve, som er markeret på app’en ovenfor. Hvis du drejer rundt på grafen i app’en, kan du måske få en fornemmelse af, at snitkurven netop angiver den \"sti\", man skal følge, hvis man i punktet \\(P\\) vil gå mest opad bakke.\n3 Argumentet for at det er rigtigt, kan du læse om her.Omvendt vil det også være sådan, at hvis du vil bevæge dig allermest nedad bakke, så skal du gå i retningen \\(-\\nabla f(x_0,y_0)\\) (det svarer til, at du lige har vendt dig rundt \\(180^{\\circ}\\) i forhold til den retning, som gradienten peger i). Beviset for at det forholder sig sådan, kan du læse her.\nDet er vigtigt her at bemærke, at det med at gå i gradientens positive eller negative retning for at gå allermest opad eller nedad bakke kun gælder i nærheden af punktet \\(P\\). Man kalder det derfor også for en \"lokal\" egenskab. Det betyder, at hvis man er kommet lidt væk fra punktet \\(P\\), så må man beregne en ny gradient i det nye punkt, man står i, og denne gradient vil nu formentlig pege i en ny retning. Det vil sige, at vi i dette nye punkt nu skal gå langs en ny \"sti\" for at gå allermest opad eller nedad bakke.\nFint nok tænker du måske, men hvem gider at gå allermest opad bakke? Se det er her, at det fine kommer ind i billedet og grunden til, at vi overhovedet gider tale om funktioner er flere variable i forbindelse med kunstig intelligens. I rigtig mange metoder inden for kunstig intelligens skal \"den kunstige intelligens\" trænes for at blive god4. Eksempler er generelle neurale netværk, perceptroner og simple neurale netværk, som du kan læse meget mere om senere.\n4 Og nu tænker du nok, at det er derfor, at man skal gå opad bakke, men det er alligevel ikke helt sådan det forholder sig 😊.5 Når et ekstremum for en funktion bestemmes på denne måde, kalder man det for en numerisk metode. Det står i modsætning til at bestemme ekstrema for en funktion analytisk. Bestemmes ekstrema analytisk sættes den afledede funktion (eller de partielle afledede funktioner) lig med \\(0\\), og herefter finder man ud af, om der er tale om et maksimum eller minimum (eller eventuelt ingen af delene). Nogle gange er det enten beregningsmæssigt tungt eller helt umuligt at løse de ligninger, som det kræves for at finde ekstrema analytisk. Derfor er de numeriske metoder smarte, også selvom man ikke nødvendigvis finder det præcise ekstrema, men kun et punkt som er tæt på. Du kender faktisk allerede en anden numeriske metode nemlig Newton-Raphsons metode, som bruges til at bestemme en funktions nulpunkter (det vil sige, at løse ligningen \\(f(x)=0\\)).Ser vi for eksempel på et kunstigt neuralt netværk, så kan det grundlæggende ingenting til at starte med. Men så giver man netværket nogle træningsdata, så det gradvist kan blive bedre. Det er her, at man siger, at man træner netværket. Det foregår ved, at man definerer en såkaldt tabsfunktion. Den måler basalt set, hvor godt netværket er lige nu. Man ønsker at tabsfunktionen skal minimeres (lille tab = godt netværk). Det kan være en meget kompliceret opgave, hvis man analytisk skal bestemme minimum for en sådan tabsfunktion, og det er lige præcis her, at gradienten kommer ind i billedet. Man starter nemlig et tilfældigt sted på grafen for tabsfunktionen (svarende til at man stiller sig i et punkt \\(P\\) på grafen for en funktion \\(f\\)). Så udregner man gradienten, og da man gerne vil finde minimum for tabsfunktionen, så går man et lille skridt i den negative gradients retning. For vi ved jo netop, at det er den retning, vi skal gå i, hvis vi gerne vil gå i den retning, hvor funktionsværdien falder mest (og det er jo smart, hvis man gerne vil ende i et minimum). Så står man i et nyt punkt på grafen, udregner gradienten i det nye punkt og går så et lille skridt i denne gradients negative retning. Sådan fortsætter man, indtil man har fundet minimum eller noget, der er tæt på (eller måske bare \"godt nok\" – det kan nemlig godt være et lokalt minimum, man rammer ind i)5. Se det er faktisk the backbone i nogle af de mest populære og moderne metoder inden for kunstig intelligens, som anvendes i dag!"
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-flere-variable",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#funktioner-af-flere-variable",
    "title": "Funktioner af flere variable",
    "section": "Funktioner af flere variable",
    "text": "Funktioner af flere variable\nVi har lige redegjort for, at gradienten er helt central i forbindelse med minimering af tabsfunktioner. Men faktisk vil det være sådan, at tabsfunktioner i virkeligheden ikke kun afhænger af to, men derimod af millioner af variable! Derfor har man helt generelt brug for at se på funktioner af flere variable end to. Vi kalder input-værdierne til funktionen \\((x_1, x_2, \\dots , x_n)\\), og man taler så om en funktion af \\(n\\) variable, hvis der for enhver værdi af \\((x_1, x_2, \\dots , x_n)\\) svarer én og kun én funktionsværdi: \\[\ny = f(x_1, x_2, \\dots, x_n).\n\\]\nMan skriver derfor\n\\[\nf: \\mathbb{R}^n \\rightarrow \\mathbb{R},\n\\] hvor \\(n\\)’et her tydeliggør, at der er tale om en funktion af \\(n\\) variable.\nDet er faktisk ikke helt så svært at forestille sig funktioner af flere variable end to, hvis nedenstående eksempel illustrerer.\n\nEksempel 1 En virksomhed producerer en bestem vare. Virksomhedens fortjeneste afhænger af en række faktorer. Fx antal solgte varer, løn til medarbejdere, elprisen, prisen på en bestemt råvarer (som bruges i produktionen) og antal sygedage blandt med arbejderne. Virksomheden har fundet ud af, at fortjenesten tilnærmelsesvist kan udregnes på følgende måde6:\n6 Bemærk, at eksemplet er fiktivt og tjener kun som en illustration.\\[\n\\begin{aligned}\n\\textrm{fortjeneste } = 7.2 \\cdot \\sqrt{\\textrm{( antal solgte varer )}}- \\textrm{( løn )} -0.9 \\cdot \\textrm{( elprisen )} \\\\ -1.4 \\cdot \\textrm{( pris på råvarer )} -0.5 \\cdot \\textrm{( antal sygedage )}^2\n\\end{aligned}\n\\]\nDet kan skrives som en funktion af fem variable \\[\nf(x_1, x_2, x_3, x_4,x_5) = 7.2 \\cdot \\sqrt{x_1}-x_2 -0.9 \\cdot x_3 - 1.4 \\cdot x_4 - 0.5 \\cdot (x_5)^2,\n\\] hvor \\(f(x_1,x_2,x_3,x,x_4,x_5)\\) betegner fortjeneste, \\(x_1\\) er antal solgte varer, \\(x_2\\) er løn til medarbejderne, \\(x_3\\) er elprisen, \\(x_4\\) er prisen på råvarer og \\(x_5\\) er antal sygedage.\n\nGrafen for en funktion \\(f\\) af \\(n\\) variable består af alle de punkter \\((x_1, x_2, \\dots, x_n,y)\\) i et \\((n+1)\\)-dimensionalt koordinatsystem, hvor \\(y = f(x_1, x_2, \\dots, x_n)\\). Koordinatsystemer på \\(4\\) dimensioner eller flere er svære at rumme i vores \\(3\\)-dimensionelle verden, så af den grund behøver vi ikke at bekymre os om, hvordan grafen for \\(f\\) ser ud.\nDe partielle afledede defineres helt som før. Når man for eksempel skal finde den partielle afledede med hensyn \\(x_1\\), så betragtes \\(x_2, x_3, \\dots, x_n\\) som konstanter, og man differentierer den tilsvarende snitfunktion med hensyn til \\(x_1\\). De partielle afledede betegnes med\n\\[\n\\frac{\\partial f}{\\partial x_1}, \\frac{\\partial f}{\\partial x_2}, \\dots, \\frac{\\partial f}{\\partial x_n}.\n\\] Gradienten defineres som en naturlig udvidelse af den tidligere definition\n\\[\n\\nabla f(x,y) =\n\\begin{pmatrix}\n\\frac{\\partial f}{\\partial x_1} \\\\\n\\frac{\\partial f}{\\partial x_2} \\\\\n\\vdots \\\\\n\\frac{\\partial f}{\\partial x_n}\n\\end{pmatrix}.\n\\]\nHelt analogt til før viser det sig, at gradienten peger i den retning, hvor funktionsværdien vokser mest. Og minus gradienten peger så altså i den retning, hvor funktionsværdien aftager mest.\nDerfor kan vi igen gå i den negative gradients retning, når vi gerne vil minimere en tabsfunktion. Denne metode kaldes for øvrigt for gradientnedstigning eller på engelsk gradient descent."
  },
  {
    "objectID": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#videre-læsning",
    "href": "materialer/funktioner_af_flere_variable/funktioner_af_flere_variable.html#videre-læsning",
    "title": "Funktioner af flere variable",
    "section": "Videre læsning",
    "text": "Videre læsning\n\nForberedelsesmaterialet om \"Funktioner af to variable\" fra 2013. Ministeriet for børn og undervisning."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html",
    "href": "materialer/naivbayes/NaivBayes.html",
    "title": "Naiv Bayes klassifier",
    "section": "",
    "text": "Denne note handler om klassifikation ved hjælp af den metode, som kaldes for naiv Bayes."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-klassifikation",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-klassifikation",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes klassifikation",
    "text": "Bayes klassifikation\nFor at introducere teorien om Bayes naive klassifikation, vil vi starte med at se på et eksempel for at få en idé om, hvad Bayes klassifikation går ud på.\nVi vil se på en person, og vi ønsker at give et bud på, om vedkommende stemmer på rød eller blå blok. Vi har på forhånd oplysninger om en del andre personer og ønsker at bruge den viden til at give det bedste bud på, om personen stemmer på rød eller blå blok.\nHer har vi følgende data, der viser, hvem der stemmer på rød og blå blok.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlle\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\n\nRød\n\\(51.85 \\%\\)\n\\(48.00 \\%\\)\n\\(55.00 \\%\\)\n\\(65.00 \\%\\)\n\\(47.47 \\%\\)\n\\(54.00 \\%\\)\n\\(49.90 \\%\\)\n\\(52.78 \\%\\)\n\n\nBlå\n\\(48.15 \\%\\)\n\\(52.00 \\%\\)\n\\(45.00 \\%\\)\n\\(35.00 \\%\\)\n\\(52.53 \\%\\)\n\\(46.00 \\%\\)\n\\(50.10 \\%\\)\n\\(47.22 \\%\\)\n\n\nAntal\n\\(10000\\)\n\\(4500\\)\n\\(5500\\)\n\\(2500\\)\n\\(7500\\)\n\\(3000\\)\n\\(4500\\)\n\\(2500\\)\n\n\n\n\n\n\n\n\n\nOpgave\n\n\n\n\n\nBrug tabellen ovenfor og giv det bedste bud på hvilken blok en person stemmer på:\n\nHvis det er en tilfældig person.\nHvis det er en mand.\n\n\n\n\nFra skemaet med oplysninger kan det være svære at give et bud på, hvad en ældre kvinde fra Sjælland vil stemme på, da oplysningen om køn tyder på personen vil stemme på rød, mens information om, at det er en ældre person, tyder på, at personen vil stemme på blå. Endelig vil oplysningen om, at kvinden bor på Sjælland igen få os til at tænke, at hun stemmer på rød blok.\nHer kunne vi selvfølgelig løse problemet ved at få information for hver kombination af køn, aldersgruppe og bopæl. Men det viser sig ikke at være en helt gangbar fremgangsmåde. Forklaringen følger her: Hvis vi ser på kombinationer af køn, aldersgruppe og bopæl vil det i dette eksempel give \\(2\\cdot 2\\cdot 3=12\\) kombinationer, og hvis vi i stedet havde set på, om man svarer ja eller nej til \\(50\\) spørgsmål, vil man kunne få \\(2^{50}\\) forskellige kombinationer af svar. Hvis man ser på en person, der har svaret på de \\(50\\) spørgsmål, kan man her forvente, at man i ens data kun har ganske få eller måske slet ingen personer, der har svaret på fuldstændig samme måde, og der vil ikke være meget at basere ens bud på.\nDerfor ønsker vi en metode, hvor vores bud, på hvad en ny person vil stemme på, udelukkende baseres på information svarende til det fra skemaet ovenfor, hvor vi ikke ser på alle de forskellige kombinationer. Det er det Naive Bayes klassifikation kan."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-klassifier",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-klassifier",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes klassifier",
    "text": "Bayes klassifier\nI det følgende indfører vi det nødvendige matematik og notation til Naive Bayes klassifikation. Først og fremmest indfører vi en stokastisk variabel \\(Y\\), som kan antage de værdier, der svarer til vores forskellige forudsigelser/bud. I vores eksempel vil \\[Y\\in\\{blå, rød\\}.\\]\nLidt mere generelt siger man, at \\(Y\\) skal være en diskret stokastisk variabel med et bestemt antal mulige udfald, og der behøver altså ikke nødvendigvis kun at være to udfald.\nDerudover indfører vi en stokastisk variabel \\(\\mathbf{X}\\), hvor de mulige udfald er alle kombinationer af informationer. Her kan vi tænke \\(\\mathbf{X}\\) som en stokastisk vektor \\(\\mathbf{X} =(X_1,X_2,…,X_q)\\), hvor man ved eksemplet kunne sige \\(X_1\\):køn, \\(X_2\\):aldersgruppe og \\(X_3\\):bopæl, og et udfald kunne være \\(\\mathbf{x}=(kvinde,ældre,Sjælland)\\).\nFor hvert udfald af \\(Y\\) ønsker vi, at bestemme sandsynligheden for at værdien \\(y\\) antages, når vi allerede har observeret, at \\(\\mathbf{X}=\\mathbf{x}\\).\nSandsynligheden vil vi skrive som \\[P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\]\nDenne notation og betydningen deraf ser vi snart på.\nVi kalder \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\) en posterior sandsynlighed, fordi den udtrykker sandsynligheden for \\(Y\\) efter (post), vi har informationen \\(\\mathbf{x}\\).\nDet mest sandsynlige udfald for \\(Y\\), når vi har informationen \\(\\mathbf{x}\\), betegnes \\(C(\\mathbf{x})\\) og kaldes Bayes klassifikation."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#betinget-sandsynlighed-og-uafhængighed",
    "href": "materialer/naivbayes/NaivBayes.html#betinget-sandsynlighed-og-uafhængighed",
    "title": "Naiv Bayes klassifier",
    "section": "Betinget sandsynlighed og uafhængighed",
    "text": "Betinget sandsynlighed og uafhængighed\nFørst vender vi dog lige tilbage til notationen \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\), som vi kaldte en posterior sandsynlighed. I sandsynlighedsregningen kalder vi det også for en betinget sandsynlighed, hvilket er grunden til notationen \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\).\nGivet to hændelser \\(A\\) og \\(B\\) så benyttes notationen \\(P(A\\mid B)\\) som sandsynligheden for, at \\(A\\) sker, når det er givet, at \\(B\\) er sket. Det læses derfor også som sandsynligheden for \\(A\\) givet \\(B\\).\nSå \\(P(Y = y \\mid \\mathbf{X} = \\mathbf{x})\\) er derved sandsynligheden for \\(Y = y\\), når det er givet, at \\(\\mathbf{X} = \\mathbf{x}\\).\nEt banalt eksempel kunne være at \\(Y\\) angiver antal ben på et givent dyr, mens \\(\\mathbf{X}\\) angiver dyrearten. Her er det oplagt, at sandsynligheden for fire eller to ben afhænger af hvilken dyreart, der er tale om.\nFormelt defineres betinget sandsynlighed for to hændelser \\(A\\) og \\(B\\) som: \\[P(A\\mid B) = \\frac{P(A \\cap B)}{P(B)} \\tag{1}\\]\nUdtrykket \\(P(A \\cap B)\\) i tælleren er sandsynligheden for fælleshændelsen mellem \\(A\\) og \\(B\\) – det vil sige hændelsen, at både \\(A\\) og \\(B\\) indtræffer – og i nævneren sørger vi for, at man kun ser på de udfald, hvor \\(B\\) er givet1.\n1 Man siger også, at nævneren normaliserer sandsynligheden i forhold til sandsynligheden for hændelsen \\(B\\).\nEksempel med betinget sandsynlighed\nLad os fokusere på en almindelig terning med seks sider. Lad \\(B\\) være hændelsen at antal øjne er mindre eller lig med \\(3\\). Det vil sige, at hændelsen \\(B\\) består af udfaldene: \\(B\\) = {⚀, ⚁, ⚂}. Lad hændelsen \\(A\\) være udfald med ulige antal øjne: \\(A\\) = {⚀, ⚂, ⚄}.\nDa kan vi nemt indse, at \\[P(A) = 3/6 = 1/2\\] samt ligeledes at \\[P(B) = 1/2\\] på grund af det symmetriske udfaldsrum.\nSer vi imidlertid på den betingede sandsynlighed for at \\(A\\) indtræffer givet, at \\(B\\) allerede er indtruffet, får vi \\(P(A\\mid B)\\). Det svarer til sandsynligheden for at slå et ulige antal øjne, hvis vi allerede ved at antallet af øjne er mindre end eller lig med \\(3\\).\nFørst ser vi, at \\(A\\cap B\\) = {⚀, ⚂, ⚄} \\(\\cap\\) {⚀, ⚁, ⚂} = {⚀, ⚂}, hvilket igen på grund af det symmetriske sandsynlighedsfelt betyder, at \\[P(A\\cap B) = 2/6 = 1/3\\] Efter at vi normaliserer sandsynligheden ud fra betingelsen om at \\(B\\) er indtruffet får vi \\[P(A\\mid B) =  \\frac{P(A \\cap B)}{P(B)} = \\frac{1/3}{1/2}  = \\frac{2}{3}.\\] At betinge med hændelsen \\(B\\) svarer i dette simple eksempel til at indskrænke udfaldet for \\(A\\) fra alle ulige øjne til dem, som er mindre end eller lig med \\(3\\). Der er således tre mulige udfald i vores “\\(B\\)-verden”, hvoraf to er ulige."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#stokastisk-uafhængighed",
    "href": "materialer/naivbayes/NaivBayes.html#stokastisk-uafhængighed",
    "title": "Naiv Bayes klassifier",
    "section": "Stokastisk uafhængighed",
    "text": "Stokastisk uafhængighed\nMan siger, at to hændelser \\(A\\) og \\(B\\) er uafhængige af hinanden, hvis \\[P(A \\cap B) = P(A) \\cdot P(B)\\] Hvis vi ser på udtrykket for \\(P(A\\mid B)\\) i (1) og antager, at \\(A\\) og \\(B\\) er uafhængige, ser vi at \\[\nP(A\\mid B) = \\frac{P(A\\cap B)}{P(B)} \\stackrel{\\text{uafh.}}{=} \\frac{P(A) \\cdot P(B)}{P(B)} = P(A)\n\\] Med andre ord betyder det, at sandsynligheden for \\(A\\) givet \\(B\\) er den samme som sandsynligheden for \\(A\\). Det vil sige, at oplysningen om, at \\(B\\) allerede er indtruffet, ikke ændrer på sandsynligheden for \\(A\\). Information om \\(B\\) tilfører altså ikke noget nyt i forhold til information om \\(A\\), og det giver derfor mening af sige, at \\(A\\) og \\(B\\) er uafhængige af hinanden."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-sætning",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-sætning",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes’ sætning",
    "text": "Bayes’ sætning\nEn meget vigtig matematisk egenskab ved betinget sandsynlighed er muligheden for at ombytte rollerne i formlen, således vi kan udtrykke \\(P(B\\mid A)\\) ud fra vores viden om \\(P(A\\mid B)\\). Sætningen kaldes Bayes’ sætning (eller formel) og kan let vises ved først at bestemme \\(P(A\\cap B)\\) ved at isolere denne sandsynlighed. Fra (1) får vi\n\\[P(A\\cap B)=P(A\\mid B)\\cdot P(B)\\] På helt tilsvarende vis må der også gælde, at\n\\[P(B\\cap A)=P(B\\mid A)\\cdot P(A)\\] Og da \\(A\\cap B=B\\cap A\\) må også \\(P(A\\cap B)=P(B\\cap A)\\). De to ovenfor udledte sandsynligheder, må derfor være ens:\n\\[P(A\\mid B)\\cdot P(B)=P(B\\mid A)\\cdot P(A)\\] Her Kan \\(P(A\\mid B)\\) isoleres \\[\nP(A\\mid B)=  \\frac{P(B\\mid A)\\cdot P(A)}{P(B)}\n\\] Dette resultat er netop Bayes’ sætning:\n\n\nSætning 1 (Bayes’ sætning) Lad \\(A\\) og \\(B\\) være hændelser, hvor \\(P(B) \\neq 0\\). Da gælder, at \\[\nP(A\\mid B)=  \\frac{P(B\\mid A)\\cdot P(A)}{P(B)}\n\\]\n\n\nVi kan altså ved at kende \\(P(B\\mid A)\\), \\(P(B)\\) og \\(P(A)\\) udtrykke den betingede sandsynlighed \\(P(A\\mid B)\\). Vi vender lige om lidt tilbage til, hvad vi kan bruge det til.\nSom sidste bemærkning er det væsentligt at understrege, at \\(P(A\\mid B) \\neq P(B\\mid A)\\) med mindre \\(P(A) = P(B)\\) jævnfør (1) ovenfor. F.eks. er sandsynligheden for et tilfældigt dyr er en elefant, givet dyret har fire ben ikke den samme som sandsynligheden for, at dyret har fire ben givet, at dyret er en elefant!"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#binær-bayes-klassifier",
    "href": "materialer/naivbayes/NaivBayes.html#binær-bayes-klassifier",
    "title": "Naiv Bayes klassifier",
    "section": "Binær Bayes klassifier",
    "text": "Binær Bayes klassifier\nAntag nu at \\(Y\\) kun kan antage to tilstande som ved eksemplet med rød eller blå. I dette tilfælde oversætter man ofte de to udfald til henholdsvis \\(0\\) og \\(1\\), eller i visse sammenhænge til \\(-1\\) og \\(+1\\). Husk på at Bayes klassifikationen \\(C(\\mathbf{x})\\) er det mest sandsynlige udfald for \\(Y\\), når vi har informationen \\(\\mathbf{x}\\). I det tilfælde hvor \\(Y\\) kun kan antage to tilstande, får vi derfor\n\\[ C(\\mathbf{x}) = \\begin{cases}\n0 & \\textrm{hvis } P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x}) &gt; P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x}) \\\\\n1 & \\textrm{ellers} \\\\\n\\end{cases} \\tag{2}\\]\nDette kan også udtrykkes på anden vis: \\[\n\\begin{aligned}\nP(Y = 0 \\mid \\mathbf{X} = \\mathbf{x}) &gt; P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x}) \\Leftrightarrow\n\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} &gt; 1.\n\\end{aligned}\n\\] Her er vi dog nødt til at antage, at \\[P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})\\neq 0,\\] så vi ikke kommer til at dividere med \\(0\\).\nBruger vi denne omskrivning, kan vi udtrykke den binære Bayes klassifikation i (2) på denne måde:\n\\[ C(\\mathbf{x}) = \\begin{cases}\n0 & \\textrm{hvis } \\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} &gt; 1 \\\\\n1 & \\textrm{ellers} \\\\\n\\end{cases} \\tag{3}\\]\nI det følgende vil vi benytte os af Bayes’ sætning til at se på, hvordan ovenstående brøk kan beregnes."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#bayes-sætning-i-anvendelse",
    "href": "materialer/naivbayes/NaivBayes.html#bayes-sætning-i-anvendelse",
    "title": "Naiv Bayes klassifier",
    "section": "Bayes’ sætning i anvendelse",
    "text": "Bayes’ sætning i anvendelse\nVi bruger først Bayes’ sætning til at udtrykke \\(P(A\\mid C)\\) og \\(P(B\\mid C)\\). \\[\nP(A\\mid C) = \\frac{P(C\\mid A)P(A)}{P(C)} \\quad\\text{og}\\quad\nP(B\\mid C) = \\frac{P(C\\mid B)P(B)}{P(C)},\n\\] Når vi bestemmer forholdet mellem \\(P(A\\mid C)\\) og \\(P(B\\mid C)\\) vil vi kunne slippe af med nævneren, som de har til fælles:\n\\[\n\\begin{aligned}\n\\frac{P(A\\mid C)}{P(B\\mid C)} &= \\frac{\\frac{P(C\\mid A)P(A)}{P(C)}}{\\frac{P(C\\mid B)P(B)}{P(C)}}  \n= \\frac{P(C\\mid A)P(A)}{P(C)} \\cdot \\frac{P(C)}{P(C\\mid B)P(B)} \\\\\n&= \\frac{P(C\\mid A)P(A)}{P(C\\mid B)P(B)},\n\\end{aligned}\n\\] hvor vi har udnyttet, at man dividerer med en brøk ved at gange med den omvendte brøk.\nI den binære Bayes klassifikation i (3) indgår brøken \\(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\), som vi ved at benytte ovenstående kan omskrive til: \\[\n\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} =\n\\frac{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)P(Y = 0)}{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 1)P(Y = 1)}.\n\\tag{4}\\]"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#naiv-bayes-klassifier",
    "href": "materialer/naivbayes/NaivBayes.html#naiv-bayes-klassifier",
    "title": "Naiv Bayes klassifier",
    "section": "Naiv Bayes klassifier",
    "text": "Naiv Bayes klassifier\nUd fra udtrykket for forholdet mellem de to posterior sandsynligheder \\(P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})\\) og \\(P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})\\) som indgår i (4) kan vi se, at der indgår to typer af sandsynligheder:\n\\[P(\\mathbf{X} = \\mathbf{x}\\mid Y = y) \\quad \\textrm{og} \\quad P(Y = y)\\]\nDisse benævnes henholdsvis likelihood og prior sandsynlighed, idet \\(P(\\mathbf{X} = \\mathbf{x}\\mid Y = y)\\) udtrykker likelihooden (troligheden) for at observere \\(\\mathbf{X} = \\mathbf{x}\\) givet \\(Y = y\\). Omvendt er prior sandsynligheden \\(P(Y = y)\\) et udtryk for forhåndsandsynligheden for at \\(Y = y\\). Altså bruger vi disse betegnelser:\n\\[\n\\begin{aligned}\n&\\textrm{Likelihood: }  &P(\\mathbf{X} = \\mathbf{x}\\mid Y = y) \\\\\n&\\textrm{Prior sandsynlighed: } &P(Y = y)\n\\end{aligned}\n\\]\nVi kan sammenfatte udtrykket i (4) til det såkaldte posterior forhold: \\[\n\\underbrace{\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}}_\\text{Posterior forhold} =\n\\underbrace{\\frac{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)}{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 1)}}_\\text{Likelihood forhold} \\cdot\n\\underbrace{\\frac{P(Y = 0)}{P(Y = 1)}}_\\text{Prior forhold}\n\\]\nHvis vi vender tilbage til vores spørgsmål om at stemme på blå eller rød blok og så kan vi sige, at \\[ Y=\n\\begin{cases}\n0 & \\textrm {hvis der stemmes på rød blok} \\\\\n1 & \\textrm {hvis der stemmes på blå blok} \\\\\n\\end{cases}\n\\] Hvis \\(x=(kvinde, ung, Sjælland)\\), så udtrykker \\(P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)\\) således sandsynligheden for, at en person er en ung kvinde fra Sjælland givet, at personen stemmer på rød blok. Når man skal bestemme den sandsynlighed skal vi huske, at det er sandsynligheden for det samlede udsagn med køn, alder og bopæl.\nFor at kunne beregne ovenstående sandsynligheder bliver vi nødt til at antage et eller andet, der gør det muligt. Man siger, at vi opstiller en model.\nÉn af de simpleste modeller er at antage at køn, alder og bopæl er uafhængige af hinanden givet \\(Y = y\\). Denne forsimplende antagelse har medvirket til metodens navn: Naiv Bayes eller Uafhængig Bayes klassifikation.\nDet betyder ifølge vores tidligere definition af uafhængighed at \\[\n\\begin{aligned}\nP(\\mathbf{X} = \\mathbf{x} \\mid Y = y) &=\nP(X_1 = x_1, X_2 = x_2, \\dots, X_q = x_q \\mid Y = y)\\\\\n&= P(X_1 = x_1\\mid Y = y)P(X_2 = x_2\\mid Y = y)\\cdots P(X_q = x_q \\mid Y = y)\\\\\n&= \\prod_{i=1}^q P(X_i = x_i\\mid Y = y),\n\\end{aligned}\n\\] hvor \\(\\prod\\)-symbolet i sidste linje betyder, at vi tager produktet af alle faktorerne på formen \\(P(X_i = x_i\\mid Y = y)\\) fra \\(i=1\\) op til \\(q\\) – altså præcist det, som står i linjen over. Det minder således om sum-tegnet \\[\\sum_{i=1}^n x_i = x_1 + x_2 + \\cdots + x_n,\\] men blot for multiplikation i stedet for addition."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#posterior-forholdet-score-og-vægte",
    "href": "materialer/naivbayes/NaivBayes.html#posterior-forholdet-score-og-vægte",
    "title": "Naiv Bayes klassifier",
    "section": "Posterior forholdet, score og vægte",
    "text": "Posterior forholdet, score og vægte\nSamler vi nu udtrykkene, som indgår i vores posterior forhold i (4), samtidig med at vi antager, at \\(X_1, X_2, \\cdots, X_q\\) er uafhængige af hinanden givet \\(Y\\), får vi nedenstående:\n\\[\n\\begin{aligned}\n\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})} &=\n\\frac{P(Y=0)}{P(Y=1)}\\cdot \\frac{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 0)}{P(\\mathbf{X} = \\mathbf{x} \\mid Y = 1)} \\\\\n&= \\frac{P(Y = 0)}{P(Y = 1)}\n\\prod_{i=1}^q\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)},\n\\end{aligned}\n\\]\nhvor hver faktor på højre siden bidrager ligeligt til, om observationen \\(\\mathbf{x}\\) skal klassificeres som \\(Y=0\\) eller \\(Y=1\\).\nNår vi skal lave beregninger på computer baseret på data, er det ofte væsentligt at tage højde for numerisk præcision. Alle tal på en computer skal repræsenteres af et endelig antal bits. Det betyder, at visse tal (f.eks. \\(1/3\\)) bliver afrundet efter et vist antal decimaler. Derfor kan der opstå problemer, når man enten ganger eller adderer meget små (eller store) tal sammen. For at undgå dette i udtrykket ovenfor, er det derfor tit en god idé at benytte sig af (den naturlige) logaritme på begge sider af lighedstegnet:\n\\[\n\\begin{aligned}\n\\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right) &=\n\\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right) +\n\\sum_{i=1}^q \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right),\n\\end{aligned}\n\\tag{5}\\]\nhvor vi har brugt logaritmeregnereglen \\[\\ln(a\\cdot b) = \\ln(a) + \\ln(b)\\] gentagende gange.\nVi minder om, at forholdet mellem \\(P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})\\) og \\(P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})\\) er af særlig interesse omkring værdien 1 – se (3). Når forholdet er \\(1\\) betyder det, at de to klasser er lige sandsynlige givet \\(\\mathbf{x}\\). Endvidere, når forholdet er over \\(1\\), er \\(Y=0\\) mere sandsynlig end \\(Y=1\\), og når det er under \\(1\\), er det omvendte tilfældet.\nLad os nu se på hvilken effekt det får, at vi ikke længere ser direkte på det posterior forhold \\[ \\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\] men i stedet på logaritmen af det posterior forhold \\[ \\ln \\left ( \\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right )\\]\nI figur 1 nedenfor er grafen for logaritmefunktionen tegnet for \\(x\\in ]0, 10].\\)\n\n\n\n\n\n\nFigur 1: Grafen for \\(f(x)=\\ln (x)\\).\n\n\n\nVi ved, at \\(\\ln(1) = 0\\) (hvilket også kan ses på grafen i figur 1), samt at for \\(x&lt;1\\) er \\(\\ln(x)&lt;0\\), mens for \\(x&gt;1\\) er \\(\\ln(x)&gt;0\\).\nSå når vi ser på \\[\\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right)\\] bliver det vigtige nu, om denne størrelse er positiv eller negativ.\nLad os derfor indføre \\(S\\) som en score, der er lig med logaritmen til posterior forholdet:\n\\[\nS = \\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right)\n\\tag{6}\\]\nDen binære Bayes klassifikation i (3) kan derfor i stedet skrives ved hjælp af scoren \\(S\\) på denne måde:\n\\[ C(\\mathbf{x}) = \\begin{cases}\n0 & \\textrm{hvis } \\ S&gt;0  \\\\\n1 & \\textrm{ellers} \\\\\n\\end{cases} \\tag{7}\\]\nVi ved således, at hvis \\(S&gt;0\\), så klassificerer vi \\(\\mathbf{x}\\), som \\(C(x)=0\\) og ellers \\(C(x)=1\\).\nSammenholder vi definitionen af \\(S\\) i (6) med udtrykket i (5), ser vi, at \\(S\\) også kan skrives som\n\\[\n\\begin{aligned}\nS &= \\ln \\left(\\frac{P(Y = 0 \\mid \\mathbf{X} = \\mathbf{x})}{P(Y = 1 \\mid \\mathbf{X} = \\mathbf{x})}\\right) \\\\&=\n\\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right) +\n\\sum_{i=1}^q \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right),\n\\end{aligned}\n\\tag{8}\\]\nIndfører vi nu bidragene til \\(S\\) som \\(w_0\\) og \\(w_i(x_i)\\) således \\[\nw_0 = \\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right)\n\\quad\\text{og}\\quad\nw_i(x_i) = \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right)\n\\] kan vi skrive udtrykket for \\(S\\) i (8) som \\[\nS = w_0 + \\sum_{i = 1}^q w_i(x_i),\n\\tag{9}\\] hvor det tydeliggøres, at hvis \\(w_i(x_i)&gt;0\\), så understøtter bidraget fra den \\(i\\)’te oplysning \\(x_i\\), at \\(Y=0\\) og ellers hvis \\(w_i(x_i)&lt;0\\) at \\(Y=1\\). Denne egenskab gør, at man også kan omtale \\(w_i(x_i)\\) som en slags “bevismæssig” vægt.\n\nVægten \\(w_0\\)\nVi har altså set i (5) og (9), hvordan vi kan omskrive forholdet mellem posterior sandsynlighederne for de to klasser \\(Y=0\\) og \\(Y=1\\) til en sum af bidrag.\nDet første led \\(w_0\\) afhænger ikke af nogen information \\(x_i\\), og vi har tidligere omtalt disse sandsynligheder som prior sandsynligheder. Man kan sige, at det er vores umiddelbare bud på hvad \\(Y\\) er, uden at vi kender noget som helst til informationerne i \\(\\mathbf{x}\\).\nNår vi går fra vores model, som vi har udledt i det foregående, til at skulle implementere den i en specifik anvendelse, bliver vi derfor nødt til at estimere de parametre, som indgår i modellen. For \\(w_0\\) betyder det, at vi skal estimere både \\(P(Y=0)\\) og \\(P(Y=1)\\). Her vil det være oplagt blot at estimere \\(P(Y=0)\\) og \\(P(Y=1)\\) ud fra træningsdata ved helt simpelt at bestemme andelen, som stemmer på henholdsvis rød og blå, hvorefter vi kan beregne \\[\nw_0 = \\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right)\\]\nHvis du vil se en mere teoretisk begrundelse for dette valg, kan du folde boksen nedenfor ud.\n\n\n\n\n\n\nTeoretisk begrundelse for hvordan \\(P(Y=0)\\) kan estimeres\n\n\n\n\n\nVi ønsker at bestemme det bedst mulige estimat for \\(p=P(Y=0)\\) ud fra vores træningsdata. Vi vil her tænke på resultaterne fra datasættet som kommende fra et binomialforsøg med sandsynligheds-parameter \\(p\\) og antalsparameter \\(n\\). I eksemplet kan vi derfor lade \\(Z\\) være en stokastisk variabel, der betegner antallet, som stemmer på rød blok. Det vil sige, at\n\\[ Z \\sim bin(n,p) \\]\nog fra binomialfordelingen ved vi, at\n\\[\nP(Z = r) = {n \\choose r}p^r(1-p)^{n-r} = \\frac{n!}{(n-r)!r!}p^r(1-p)^{n-r}\n\\] Når vi skal estimere \\(p\\) (altså sandsynligheden for at stemme på rød blok – det vil sige \\(P(Y=0)\\)) ud fra data benyttes en metode, som kaldes for maksimum likelihood estimation. Den går i al sin enkelhed ud på at bestemme den værdi af \\(p\\), som gør de data, vi har set, mest sandsynlige. Altså vil vi maksimere udtrykket ovenfor med hensyn til \\(p\\). Dette kan vi gøre ved at differentiere udtrykket og sætte det lig med \\(0\\). I stedet for at arbejde direkte med \\(P(Z = r)\\) er det nemmere at arbejde med udtrykket for \\(\\ln\\bigl(P(Z = r)\\bigr)\\), idet der gælder, at \\(f(p)=P(Z = r)\\) og \\(\\ln\\bigl(f(p) \\bigr)\\) har maksimum ved samme \\(p\\) (fordi logaritmefunktionen er voksende).\nVi finder derfor først et udtryk for \\(\\ln\\bigl(P(Z = r)\\bigr)\\):\n\\[ \\ln\\bigl(P(Z = r)\\bigr) = \\ln {n \\choose r} + r \\cdot \\ln(p) + (n-r) \\cdot \\ln(1-p)\\] hvor vi har brugt logaritmeregnereglerne \\[\\ln(a\\cdot b) = \\ln(a) + \\ln(b) \\quad \\textrm{og} \\quad \\ln(a^x)=x \\cdot \\ln(a)\\] Derfor bliver den afledede med hensyn til \\(p\\) \\[\n\\frac{d}{dp} \\left ( \\ln\\bigl(P(Z = r)\\bigr) \\right ) = \\frac{r}{p} - \\frac{n-r}{1-p}\n\\] Sætter vi ovenstående lig \\(0\\) og isolerer for \\(p\\), får vi, at\n\\[\\hat{p} = \\frac{r}{n}\\]\nhvilket svarer til den andel af de \\(n\\) observationer, som har \\(Y=0\\). Vi sætter en “hat” på \\(p\\) for at tydeliggøre, at det er et estimat af \\(p\\) – og altså ikke den ukendte, sande værdi af \\(p\\).\nBemærk, at man også kan vise, at denne værdi af \\(p\\) rent faktisk svarer til et maksimumssted.\n\n\n\n\n\nVægtene \\(w_i\\)\nDe øvrige bidrag til \\(S\\) afhænger af den specifikke værdi af \\(x_i\\). Det er altså her data for observationen, vi ønsker at klassificere, kommer ind i billedet. Her vil vægten \\(w_i(x_i)\\), som bidrager til den samlede score \\(S\\), afhænge af informationen2 \\(x_i\\).\n2 Hvis \\(w_i(x_i)\\) er mere eller mindre konstant for forskellige værdier af \\(X_i\\), betyder det, at den \\(i\\)’te information ikke er særlig informativ (og måske bør udelades fra modellen).Ved hver information \\(X_i\\) estimeres \\(P(X_i = x_i \\mid Y = y)\\) ved at se på andelen af \\(x_i\\) blandt alle træningsdata med \\(Y = y\\). Vægtene \\(w_i\\) estimeres således på tilsvarende måde som for \\(w_0\\).\nNår disse estimater er fundet, kan man bestemme \\[w_i(x_i) = \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right)\n\\]"
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#eksempel-med-rødblå-blok",
    "href": "materialer/naivbayes/NaivBayes.html#eksempel-med-rødblå-blok",
    "title": "Naiv Bayes klassifier",
    "section": "Eksempel med rød/blå blok",
    "text": "Eksempel med rød/blå blok\nLad os se på eksemplet fra tidligere med at stemme på rød eller blå blok, hvor vi tænker på \\(Y=0\\) som en stemme på rød blok og \\(Y=1\\) som en stemme på blå blok.\nVi havde allerede følgende information fra træningsdata:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nAlle\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\n\nRød\n\\(51.85 \\%\\)\n\\(48.00 \\%\\)\n\\(55.00 \\%\\)\n\\(65.00 \\%\\)\n\\(47.47 \\%\\)\n\\(54.00 \\%\\)\n\\(49.90 \\%\\)\n\\(52.78 \\%\\)\n\n\nBlå\n\\(48.15 \\%\\)\n\\(52.00 \\%\\)\n\\(45.00 \\%\\)\n\\(35.00 \\%\\)\n\\(52.53 \\%\\)\n\\(46.00 \\%\\)\n\\(50.10 \\%\\)\n\\(47.22 \\%\\)\n\n\nAntal\n\\(10000\\)\n\\(4500\\)\n\\(5500\\)\n\\(2500\\)\n\\(7500\\)\n\\(3000\\)\n\\(4500\\)\n\\(2500\\)\n\n\n\nFra dette bestemmes først vægten \\(w_0\\) ved \\[w_0 = \\ln \\left(\\frac{P(Y = 0)}{P(Y = 1)}\\right)=\\ln\\left(\\frac{51.85\\%}{48.15\\%}\\right)=0.074\\]\nFor at kunne beregne vores vægte \\[w_i(x_i) = \\ln \\left(\\frac{P(X_i = x_i \\mid Y = 0)}{P(X_i = x_i \\mid Y = 1)}\\right)\n\\]\nskal vi for at beregne tælleren i ovenstående brøk have fat på hvor stor en andel af de stemmer, der går til rød blok, som kommer fra henholdsvis mænd, kvinder, unge, ældre og så videre.\nVi tager beregningen for kvinder og starter med at finde \\(P(X_1 = kvinde \\mid Y = 0)\\). Her ved vi at \\(55 \\%\\) af de i alt \\(5500\\) kvinder stemte på rød blok. Samtidig ved vi, at der var \\(51.85 \\%\\) ud af i alt \\(10000\\) adspurgte (det vil sige \\(5185\\) pesroner), som stemte på rød blok. Derfor får vi \\[P(X_1 = kvinde \\mid Y = 0)=\\frac{55\\% \\cdot 5500}{5185}=58.34 \\%\\] Da \\(X_1\\) kun kan antage værdierne kvinde og mand, ved vi også, at\n\\[P(X_1 = mand \\mid Y = 0)=100\\%-58.34 \\%=41.66\\%.\\] På tilsvarende måde kan vi finde \\(P(X_1 = kvinde \\mid Y = 1)\\). Her ved vi, at \\(45 \\%\\) af de \\(5500\\) kvinder stemte på blå blok, og samtidig ved vi, at der var \\(4815\\) stemmer på blå blok i alt (igen \\(48.15 \\%\\) af \\(10000\\)). Derfor får vi \\[P(X_1 = kvinde \\mid Y = 1)=\\frac{45\\%\\cdot 5500}{4815}= 51.40 \\%\\] og \\[P(X_1 = mand \\mid Y = 1)=100\\%-51.40 \\%=48.60\\%\\] Alle tilsvarende sandsynligheder kan beregnes, så man kan se hvor stor en andel af stemmerne på de to blokke, der kommer fra hver gruppe. Resultatet ses i nedenstående tabel:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\n\nRød\n\\(41.66 \\%\\)\n\\(58.34 \\%\\)\n\\(31.34 \\%\\)\n\\(68.66 \\%\\)\n\\(31.24 \\%\\)\n\\(43.31 \\%\\)\n\\(25.45 \\%\\)\n\n\nBlå\n\\(48.60 \\%\\)\n\\(51.40 \\%\\)\n\\(18.17 \\%\\)\n\\(81.83 \\%\\)\n\\(28.66 \\%\\)\n\\(46.82 \\%\\)\n\\(24.52 \\%\\)\n\n\n\nNu kan vi bestemme vægtene \\(w_i(x_i)\\). Her findes \\(w_1(kvinde)\\) ved\n\\[w_1(kvinde) = \\ln \\left(\\frac{P(X_1 = kvinde \\mid Y = 0)}{P(X_1 = kvinde \\mid Y = 1)}\\right)=\\ln \\left(\\frac{58.34\\%}{51.40\\%}\\right)=0.1267\\] Herunder ses vægtene for alle grupper:\n\n\n\n\n\n\n\n\n\n\n\n\n\n\\(w_0\\)\n\\(w_1\\)\n\n\\(w_2\\)\n\n\\(w_3\\)\n\n\n\n\n\n\n\nMænd\nKvinder\nUnge\nÆldre\nSjælland\nJylland\nAnden bopæl\n\n\n\\(0.074\\)\n\\(-0.154\\)\n\\(0.127\\)\n\\(0.545\\)\n\\(-0.175\\)\n\\(0.086\\)\n\\(-0.078\\)\n\\(0.037\\)\n\n\n\nTidligere havde vi indset, at når \\(w_i(x_i)&gt;0\\), så understøtter bidraget fra den \\(i\\)’te oplysning \\(x_i\\), at \\(Y=0\\) (altså at stemme på rød blok). I tabellen ovenfor ses det derfor, at oplysningerne kvinde, ung, Sjælland og anden bopæl gør det mere sandsynligt med en stemme på rød blok, mens oplysningerne mand, ældre og Jylland gør det mere sandsynligt med en stemme på blå blok.\nVi kan nu beregne scoren \\(S\\) for en kvinde, som er ældre og fra Sjælland, altså hvor \\(x=(kvinde,ældre,Sjælland)\\). \\[\\begin{equation}\n\\begin{split}\nS &  = w_0 + \\sum_{i = 1}^q w_i(x_i)=w_0+w_1(kvinde)+w_2(ældre)+w_3(Sjælland) \\\\\n& =0.074+0.127+(-0.175)+0.086=0.112\n\\end{split}\n\\end{equation}\\]\nDerved bliver forudsigelsen ud fra Bayes Naive metode, at en ældre kvinde, der bor på Sjælland, med størst sandsynlighed stemmer på rød blok."
  },
  {
    "objectID": "materialer/naivbayes/NaivBayes.html#opgave-ham-or-spam",
    "href": "materialer/naivbayes/NaivBayes.html#opgave-ham-or-spam",
    "title": "Naiv Bayes klassifier",
    "section": "Opgave: Ham or Spam?",
    "text": "Opgave: Ham or Spam?\nI denne opgave skal vi se på, hvordan man kan lave et simpelt spamfilter. Vi har et datasæt med \\(35000\\) mails med oplysninger om emailens oprindelse (Danmark, Europa uden Danmark, USA og anden oprindelse), afsenders mailadresse (firma, Google, Hotmail og anden) samt indhold (dating, spil og andet). Målet er, at man gerne ud fra disse oplysninger gerne automatisk vil kunne afgøre, om det er spam og derved at mailen ikke skal vises i mail-boxen, eller om det er Ham (non-spam). For hver af de \\(35000\\) mails er det også noteret om, der er tale om spam eller ham.\nTræningsdata består af\n\n\n\n\nOprindelse\n\n\n\n\n\n\n\n\nDK\nEuropa\nUSA\nAndet\n\n\nSpam\n\\(20 \\%\\)\n\\(30 \\%\\)\n\\(35 \\%\\)\n\\(55 \\%\\)\n\n\nHam\n\\(80 \\%\\)\n\\(70 \\%\\)\n\\(65 \\%\\)\n\\(45\\%\\)\n\n\nAntal\n\\(10000\\)\n\\(12000\\)\n\\(8000\\)\n\\(5000\\)\n\n\n\nog\n\n\n\n\nMail\n\n\n\nIndhold\n\n\n\n\n\n\n\nFirma\nGoogle\nHotmail\nAndet\nDating\nSpil\nAndet\n\n\nSpam\n\\(10 \\%\\)\n\\(20 \\%\\)\n\\(60 \\%\\)\n\\(80 \\%\\)\n\\(80 \\%\\)\n\\(90 \\%\\)\n\\(12.5 \\%\\)\n\n\nHam\n\\(90 \\%\\)\n\\(80 \\%\\)\n\\(40 \\%\\)\n\\(20 \\%\\)\n\\(20\\%\\)\n\\(10\\%\\)\n\\(87.5\\%\\)\n\n\nAntal\n\\(17000\\)\n\\(6450\\)\n\\(5400\\)\n\\(6150\\)\n\\(4325\\)\n\\(4975\\)\n\\(25700\\)\n\n\n\n\n\n\n\n\n\nOpgave 1\n\n\n\n\n\n\nHvis man blot modtager en mail fra en Hotmail-konto, vil man da tænke, at det er spam eller ham?\nHvis man blot modtager en tilfældig mail, vil man da tænke, at det er spam eller ham?\nForklar hvorfor det kan være svært at afgøre, om det er spam, hvis man modtager en mail fra Danmark, som er sendt fra en firma-mail og hvor indhold er relateret til dating.\n\n\n\n\n\n\n\n\n\n\nOpgave 2\n\n\n\n\n\nIndfør selv stokastiske variable \\(X1\\), \\(X2\\), \\(X3\\) og \\(Y\\) og angiv udfaldsrum for hver af dem.\n\n\n\n\n\n\n\n\n\nOpgave 3\n\n\n\n\n\n\nOpstil posterior forholdet\n\n\\[ \\frac{P(Y = 0 \\mid X_1=x_1, X_2=x_2, X_3=x_3)}{P(Y = 1 \\mid X_1=x_1, X_2=x_2, X_3=x_3)}\\]\nog forklar det smarte, der er sket ved at bruge Bayes formel.\n\nRedegør for betydningen af forholdet og forklar hvorfor man ser på, om det er over eller under \\(1\\).\n\n\n\n\n\n\n\n\n\n\nOpgave 4\n\n\n\n\n\nAngiv den antagelse (modelforudsætning), som anvendes ved Bayes Naive klassifikation, og forklar hvad det gør for beregningen af sandsynlighederne fra opgave 3.\n\n\n\n\n\n\n\n\n\nOpgave 5\n\n\n\n\n\nBestem prior forholdet\n\\[\\frac{P(Y=0)}{P(Y=1)}\\]\nog beregn på den baggrund vægten\n\\[w_0 = \\ln \\left ( \\frac{P(Y=0)}{P(Y=1)} \\right )\\]\n\n\n\n\n\n\n\n\n\nOpgave 6\n\n\n\n\n\nBestem alle betingede sandsynligheder\n\\[P(X_i=x_i \\mid Y=0) \\quad \\textrm{og} \\quad P(X_i=x_i \\mid Y=1)\\]\nfor hver enkelt information, givet at det er henholdsvis spam og ham (i alt 22 sandsynligheder) og forklar idéen bag én af disse udregninger.\n\n\n\n\n\n\n\n\n\nOpgave 7\n\n\n\n\n\nFor hver af de 11 informationer bestemmes forholdet mellem sandsynlighederne\n\\[ \\frac{P(X_i=x_i \\mid Y=0)}{P(X_i=x_i \\mid Y=1)}\\]\n\n\n\n\n\n\n\n\n\nOpgave 8\n\n\n\n\n\nForklar hvordan man kommer fra resultaterne i opgave 7 til vægte og udregn vægtene hørende til hver af informationerne (i alt 11).\n\n\n\n\n\n\n\n\n\nOpgave 9\n\n\n\n\n\nForklar hvad der sker ved at benytte logaritmen på udtrykket fra opgave 3 og 4, hvor man ellers ganger faktorer sammen.\n\n\n\n\n\n\n\n\n\nOpgave 10\n\n\n\n\n\nAfgør ud fra de vægte, som du har beregnet i opgave 8, hvilke informationer der taler for spam, og hvilke der taler for ham.\n\n\n\n\n\n\n\n\n\nOpgave 11\n\n\n\n\n\nAfgør ved at beregne scoren \\(S\\), om man vil tænke at en mail er ham eller spam i følgende to situationer:\n\nMailens oprindelse er andet, den er sendt fra en hotmail-konto og omhandler ikke dating eller spil.\nMailen er en firma-mail fra Danmark med indhold relateret til dating."
  },
  {
    "objectID": "referencer.html",
    "href": "referencer.html",
    "title": "Referencer",
    "section": "",
    "text": "Websider\n\nDTU har lavet et undervisningsmateriale, som handler om, hvordan kunstig intelligens kan bruges til at genkende lyde: Regn lyden ud\nOnline kursus hvor man lærer helt grundlæggende om kunstig intelligens (men ikke så matematisk som materialet her på siden): Elements of AI\nDanske Gymnasier har afholdt en konference om betydningen af AI og ChatGPT. Her på siden kan man genhøre oplæg fra blandt andet Vincent Hendricks, Stefan Herman m.fl.\nDen Store Danske har skrevet lidt om, hvad kunstig intelligens er - herunder også et historisk oprids af udviklingen inden for kunstig intelligens. Kunstig intelligens\nPå siden dataekspeditioner findes en række forløb hvoraf flere omhandler AI.\n\n\n\nVideoer\n\n3Blue1Brown har lavet en række fine videoer, som forklarer, hvad et kunstigt neuralt netværk er, og hvordan det trænes (på engelsk): Neural networks\n\n\n\nBøger\n\nOnline bog om kunstige neurale netværk af Michael Nielsen (på engelsk): Neural networks and deep learning"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Om os",
    "section": "",
    "text": "Projektet Aalborg Intelligence, som er finansieret af Novo Nordisk Fonden, er forankret på Institut for Matematiske Fag på Aalborg Universitet (AAU), og inkluderer en repræsentant fra de fem gymnasier i Aalborg."
  },
  {
    "objectID": "about.html#gymnasielærere",
    "href": "about.html#gymnasielærere",
    "title": "Om os",
    "section": "Gymnasielærere",
    "text": "Gymnasielærere\n\nMalene Cramer Engebjerg (Aalborghus Gymnasium)\nAllan Frendrup (Nørresundby Gymnasium)\nNikolaj Hess-Nielsen (Aalborg Katedralskole)\nMette Kristensen (Hasseris Gymnasium)\nJan B. Sørensen (Aalborg City Gymnasium)"
  }
]